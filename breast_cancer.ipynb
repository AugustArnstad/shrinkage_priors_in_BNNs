{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_relu = \"results/classification/single_layer/relu/breastcancer\"\n",
    "results_dir_tanh = \"results/classification/single_layer/tanh/breastcancer\"\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "\n",
    "full_config_path = \"breast_cancer_N455_p30\"\n",
    "\n",
    "relu_fits = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fits = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_breast_cancer_data\n",
    "X_train, X_test, y_train, y_test, *_ = load_breast_cancer_data(\n",
    "    test_size=0.2, standardize=False, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_names = list(tanh_fits.keys())\n",
    "results = []\n",
    "\n",
    "for model in model_names:\n",
    "    posterior = tanh_fits[model]['posterior']\n",
    "    \n",
    "    # Get predicted class labels (shape: [n_samples, n_test])\n",
    "    pred_samples = posterior.stan_variable(\"pred_test\")\n",
    "    majority_preds = mode(pred_samples, axis=0, keepdims=False).mode.flatten()\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = accuracy_score(y_test, majority_preds)\n",
    "\n",
    "    # Get predicted probabilities (shape: [n_samples, n_test, n_classes])\n",
    "    pred_probs = posterior.stan_variable(\"prob_test\")  # e.g., shape (4000, 114, 2)\n",
    "    mean_probs = pred_probs.mean(axis=0)  # shape: [n_test, 2]\n",
    "\n",
    "    # Adjust y_test to 0-based indexing for log_loss\n",
    "    y_test_adj = y_test - 1\n",
    "    nll = log_loss(y_test_adj, mean_probs, labels=[0, 1])\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model,\n",
    "        \"Accuracy\": acc,\n",
    "        \"NLL\": nll\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, float_format=\"%.4f\", column_format=\"lcc\", caption=\"Accuracy and NLL per model.\", label=\"tab:accuracy_nll\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from utils.robust_utils import estimate_robustness_over_test_set\n",
    "# === Settings ===\n",
    "epsilons = [0.01, 0.05, 0.1, 0.25]\n",
    "scales = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0]\n",
    "sample_indices = range(0, 4000, 800)\n",
    "input_dim = X_test.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "p_norm = 2\n",
    "\n",
    "# === Subset test set ===\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_s = pd.Series(y_test) - 1  # Ensure labels in {0,1}\n",
    "test_subset = X_test_df.sample(frac=1.0, random_state=42)\n",
    "subset_indices = test_subset.index\n",
    "y_subset = y_test_s.loc[subset_indices]\n",
    "\n",
    "# === Run robustness for each model ===\n",
    "all_results = []\n",
    "\n",
    "for model_name, fit_entry in tanh_fits.items():\n",
    "    for epsilon in epsilons:\n",
    "        for scale in scales:\n",
    "            delta = scale * epsilon\n",
    "\n",
    "            df_result = estimate_robustness_over_test_set(\n",
    "                x_test=test_subset,\n",
    "                y_test=y_subset,\n",
    "                fits_dict={model_name: fit_entry},  # Wrap as dict\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                sample_indices=sample_indices,\n",
    "                epsilon=epsilon,\n",
    "                delta=delta,\n",
    "                p_norm=p_norm,\n",
    "            )\n",
    "\n",
    "            df_result[\"epsilon\"] = epsilon\n",
    "            df_result[\"delta\"] = delta\n",
    "            df_result[\"scale\"] = round(scale, 2)\n",
    "            df_result[\"model\"] = model_name\n",
    "            all_results.append(df_result.copy())\n",
    "\n",
    "# === Combine results ===\n",
    "df_robust = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# === Unpack 'robustness' dictionary column into separate columns ===\n",
    "df_flat = pd.concat(\n",
    "    [df_robust.drop(columns=[\"robustness\"]),\n",
    "     df_robust[\"robustness\"].apply(pd.Series)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Add derived columns ===\n",
    "df_flat[\"1-p1\"] = (1.0 - df_flat[\"p1\"]).round(5)\n",
    "df_flat[\"1-p2\"] = (1.0 - df_flat[\"p2\"]).round(5)\n",
    "\n",
    "# Resulting DataFrame: df_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure model name consistency and ordering\n",
    "model_order = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "#Ns = sorted(df_flat[\"N\"].unique())\n",
    "\n",
    "# Global color scale (consistent across all plots)\n",
    "vmin = df_flat[\"1-p1\"].min()\n",
    "vmax = df_flat[\"1-p1\"].max()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "for j, model in enumerate(model_order):\n",
    "    row, col = divmod(j, 2)\n",
    "    ax = axes[row, col]\n",
    "    df_model = df_flat[df_flat[\"model\"] == model]\n",
    "\n",
    "    # Use pivot_table to handle duplicates\n",
    "    heatmap_df = df_model.pivot_table(\n",
    "        index=\"scale\", columns=\"epsilon\", values=\"1-p1\", aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_df.sort_index(ascending=False),\n",
    "        annot=True, fmt=\".2f\", cmap=\"RdYlGn\", ax=ax,\n",
    "        cbar=False, vmin=vmin, vmax=vmax\n",
    "    )\n",
    "\n",
    "    ax.set_title(model, fontsize=13)\n",
    "    ax.set_xlabel(r\"$\\varepsilon$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$\\delta / \\varepsilon$\", fontsize=12)\n",
    "\n",
    "# Adjust layout to leave space for colorbar\n",
    "plt.tight_layout(rect=[0, 0, 0.93, 0.95])\n",
    "\n",
    "# Add colorbar on the right\n",
    "cbar_ax = fig.add_axes([0.94, 0.25, 0.015, 0.5])  # [left, bottom, width, height]\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdYlGn\", norm=norm)\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm, cax=cbar_ax, label='$1 - p_1$')\n",
    "\n",
    "fig.suptitle(f\"Softmax Shift Robustness (1 - $p_1$)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "entropy_data = {}  # store outputs\n",
    "\n",
    "for model in model_names:\n",
    "    probs = relu_fits[model][\"posterior\"].stan_variable(\"prob_test\")  # shape: (S, N_test, 2)\n",
    "\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    predictive_entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-12), axis=1)\n",
    "\n",
    "    sample_entropies = -np.sum(probs * np.log(probs + 1e-12), axis=2)\n",
    "    expected_entropy = np.mean(sample_entropies, axis=0)\n",
    "\n",
    "    mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "    y_pred = np.argmax(mean_probs, axis=1) + 1  # add 1 only if y_test is 1/2\n",
    "    correct = (y_pred == y_test)\n",
    "\n",
    "    # Store everything\n",
    "    entropy_data[model] = {\n",
    "        \"entropy\": predictive_entropy,\n",
    "        \"mutual_info\": mutual_information,\n",
    "        \"correct\": correct\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    entropy = entropy_data[model][\"entropy\"]\n",
    "    mi = entropy_data[model][\"mutual_info\"]\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "\n",
    "    ax.scatter(entropy[correct], mi[correct], color='green', alpha=0.5, label='Correct')\n",
    "    ax.scatter(entropy[~correct], mi[~correct], color='red', alpha=0.5, label='Incorrect')\n",
    "\n",
    "    ax.set_title(model)\n",
    "    ax.set_xlabel(\"Predictive Entropy\")\n",
    "    ax.set_ylabel(\"Mutual Information\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Legend only once\n",
    "axs[0].legend()\n",
    "plt.suptitle(\"Mutual Information vs Entropy Colored by Prediction Correctness\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "    acc = np.mean(correct)\n",
    "    avg_entropy = np.mean(entropy_data[model][\"entropy\"])\n",
    "    avg_mi = np.mean(entropy_data[model][\"mutual_info\"])\n",
    "    print(f\"{model}: Accuracy={acc:.3f}, Avg Entropy={avg_entropy:.3f}, Avg MI={avg_mi:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "entropy_data = {}  # store outputs\n",
    "\n",
    "for model in model_names:\n",
    "    probs = tanh_fits[model][\"posterior\"].stan_variable(\"prob_test\")  # shape: (S, N_test, 2)\n",
    "\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    predictive_entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-12), axis=1)\n",
    "\n",
    "    sample_entropies = -np.sum(probs * np.log(probs + 1e-12), axis=2)\n",
    "    expected_entropy = np.mean(sample_entropies, axis=0)\n",
    "\n",
    "    mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "    y_pred = np.argmax(mean_probs, axis=1) + 1  # add 1 only if y_test is 1/2\n",
    "    correct = (y_pred == y_test)\n",
    "\n",
    "    # Store everything\n",
    "    entropy_data[model] = {\n",
    "        \"entropy\": predictive_entropy,\n",
    "        \"mutual_info\": mutual_information,\n",
    "        \"correct\": correct\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    entropy = entropy_data[model][\"entropy\"]\n",
    "    mi = entropy_data[model][\"mutual_info\"]\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "\n",
    "    ax.scatter(entropy[correct], mi[correct], color='green', alpha=0.5, label='Correct')\n",
    "    ax.scatter(entropy[~correct], mi[~correct], color='red', alpha=0.5, label='Incorrect')\n",
    "\n",
    "    ax.set_title(model)\n",
    "    ax.set_xlabel(\"Predictive Entropy\")\n",
    "    ax.set_ylabel(\"Mutual Information\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Legend only once\n",
    "axs[0].legend()\n",
    "plt.suptitle(\"Mutual Information vs Entropy Colored by Prediction Correctness\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "    acc = np.mean(correct)\n",
    "    avg_entropy = np.mean(entropy_data[model][\"entropy\"])\n",
    "    avg_mi = np.mean(entropy_data[model][\"mutual_info\"])\n",
    "    print(f\"{model}: Accuracy={acc:.3f}, Avg Entropy={avg_entropy:.3f}, Avg MI={avg_mi:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame first\n",
    "df = pd.DataFrame({\n",
    "    \"Entropy\": entropy_data[\"Dirichlet Horseshoe tanh\"][\"entropy\"],\n",
    "    \"MI\": entropy_data[\"Dirichlet Horseshoe tanh\"][\"mutual_info\"],\n",
    "    \"Correct\": entropy_data[\"Dirichlet Horseshoe tanh\"][\"correct\"]\n",
    "})\n",
    "\n",
    "# Plot\n",
    "sns.jointplot(\n",
    "    data=df,\n",
    "    x=\"Entropy\",\n",
    "    y=\"MI\",\n",
    "    hue=\"Correct\",\n",
    "    kind=\"scatter\",\n",
    "    palette={True: \"green\", False: \"red\"},\n",
    "    alpha=0.5,\n",
    "    marginal_kws=dict(fill=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_wine_quality_data\n",
    "\n",
    "X_train, X_test, y_train, y_test, _, _ = load_wine_quality_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
