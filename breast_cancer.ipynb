{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_relu = \"results/classification/single_layer/relu/breastcancer\"\n",
    "results_dir_tanh = \"results/classification/single_layer/tanh/breastcancer\"\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "\n",
    "full_config_path = \"breast_cancer_N455_p30\"\n",
    "\n",
    "relu_fits = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fits = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_breast_cancer_data\n",
    "X_train, X_test, y_train, y_test, *_ = load_breast_cancer_data(\n",
    "    test_size=0.2, standardize=False, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_names = list(tanh_fits.keys())\n",
    "results = []\n",
    "\n",
    "for model in model_names:\n",
    "    posterior = tanh_fits[model]['posterior']\n",
    "    \n",
    "    # Get predicted class labels (shape: [n_samples, n_test])\n",
    "    pred_samples = posterior.stan_variable(\"pred_test\")\n",
    "    majority_preds = mode(pred_samples, axis=0, keepdims=False).mode.flatten()\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = accuracy_score(y_test, majority_preds)\n",
    "\n",
    "    # Get predicted probabilities (shape: [n_samples, n_test, n_classes])\n",
    "    pred_probs = posterior.stan_variable(\"prob_test\")  # e.g., shape (4000, 114, 2)\n",
    "    mean_probs = pred_probs.mean(axis=0)  # shape: [n_test, 2]\n",
    "\n",
    "    # Adjust y_test to 0-based indexing for log_loss\n",
    "    y_test_adj = y_test - 1\n",
    "    nll = log_loss(y_test_adj, mean_probs, labels=[0, 1])\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model,\n",
    "        \"Accuracy\": acc,\n",
    "        \"NLL\": nll\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, float_format=\"%.4f\", column_format=\"lcc\", caption=\"Accuracy and NLL per model.\", label=\"tab:accuracy_nll\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Of 114 observations,\", np.round(114*results_df['Accuracy'][0], 3), \"were classified correctly by the\", results_df['Model'][0], \"model \\n\")\n",
    "print(\"Of 114 observations,\", np.round(114*results_df['Accuracy'][1], 3), \"were classified correctly by the\", results_df['Model'][1], \"model \\n\")\n",
    "print(\"Of 114 observations,\", np.round(114*results_df['Accuracy'][2], 3), \"were classified correctly by the\", results_df['Model'][2], \"model \\n\")\n",
    "print(\"Of 114 observations,\", np.round(114*results_df['Accuracy'][3], 3), \"were classified correctly by the\", results_df['Model'][3], \"model \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "W_1 = tanh_fits['Gaussian tanh']['posterior'].stan_variable(\"W_1\")[0, :, :]   # (30, 16)\n",
    "W_2 = tanh_fits['Gaussian tanh']['posterior'].stan_variable(\"W_L\")[0, :, :]   # (16, 2)\n",
    "b_1 = tanh_fits['Gaussian tanh']['posterior'].stan_variable(\"hidden_bias\")[0, :]  # (16,)\n",
    "b_2 = tanh_fits['Gaussian tanh']['posterior'].stan_variable(\"output_bias\")[0, :]  # (2,)\n",
    "\n",
    "# Konverter DataFrame til tensor\n",
    "X = torch.tensor(X_test_df.to_numpy(), dtype=torch.float32)  # (114, 30)\n",
    "\n",
    "# Stan-vekter til tensor\n",
    "W1 = torch.tensor(W_1, dtype=torch.float32)   # (30, 16)\n",
    "b1 = torch.tensor(b_1.squeeze(), dtype=torch.float32)  # (16,)\n",
    "W2 = torch.tensor(W_2, dtype=torch.float32)   # (16, 2)\n",
    "b2 = torch.tensor(b_2, dtype=torch.float32)   # (2,)\n",
    "\n",
    "# Definer nettverket\n",
    "class StanNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, activation=torch.tanh):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.activation(self.linear1(x))\n",
    "        logits = self.linear2(h)\n",
    "        return logits  # matcher Stan sin `output`\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits, dim=1)  # matcher Stan sin `prob_test`\n",
    "\n",
    "    def predict(self, x):\n",
    "        probs = self.predict_proba(x)\n",
    "        return torch.argmax(probs, dim=1)  # matcher Stan sin `pred_test`\n",
    "\n",
    "# Bygg og kopier vektene\n",
    "model = StanNNClassifier(input_dim=30, hidden_dim=16, output_dim=2, activation=torch.tanh)\n",
    "with torch.no_grad():\n",
    "    model.linear1.weight.copy_(W1.T)   # (16, 30)\n",
    "    model.linear1.bias.copy_(b1)       # (16,)\n",
    "    model.linear2.weight.copy_(W2.T)   # (2, 16)\n",
    "    model.linear2.bias.copy_(b2)       # (2,)\n",
    "\n",
    "# === Test forward ===\n",
    "logits = model(X)                # (114, 2), Stan: `output_test`\n",
    "probs = model.predict_proba(X)   # (114, 2), Stan: `prob_test`\n",
    "preds = model.predict(X)         # (114,),   Stan: `pred_test`\n",
    "\n",
    "#print(\"logits shape:\", logits.shape)\n",
    "#print(\"probs shape :\", probs)\n",
    "#print(\"preds shape :\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_probs = tanh_fits['Gaussian tanh']['posterior'].stan_variable(\"prob_test\")[0, :, :]\n",
    "stan_probs_torch = torch.tensor(stan_probs, dtype=torch.float32)\n",
    "\n",
    "print(\"Max diff:\", (probs - stan_probs_torch).abs().max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from utils.robust_utils import estimate_robustness_over_test_set\n",
    "import torch\n",
    "# === Settings ===\n",
    "epsilons = [0.01, 0.05, 0.1, 0.25]\n",
    "#epsilons = [0.1, 0.5, 1.0, 2.5]\n",
    "scales = [0.01, 0.05, 0.1, 0.5, 1.0, 5.0]\n",
    "sample_indices = range(0, 4000, 800)\n",
    "input_dim = X_test.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 2\n",
    "p_norm = 2\n",
    "\n",
    "# === Subset test set ===\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_s = pd.Series(y_test) - 1  # Ensure labels in {0,1}\n",
    "test_subset = X_test_df.sample(frac=1.0, random_state=42)\n",
    "subset_indices = test_subset.index\n",
    "y_subset = y_test_s.loc[subset_indices]\n",
    "\n",
    "# === Run robustness for each model ===\n",
    "all_results = []\n",
    "\n",
    "for model_name, fit_entry in relu_fits.items():\n",
    "    for epsilon in epsilons:\n",
    "        for scale in scales:\n",
    "            delta = scale * epsilon\n",
    "\n",
    "            df_result = estimate_robustness_over_test_set(\n",
    "                x_test=test_subset,\n",
    "                y_test=y_subset,\n",
    "                fits_dict={model_name: fit_entry},  # Wrap as dict\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim,\n",
    "                sample_indices=sample_indices,\n",
    "                epsilon=epsilon,\n",
    "                delta=delta,\n",
    "                p_norm=p_norm,\n",
    "                activation=F.relu\n",
    "            )\n",
    "\n",
    "            df_result[\"epsilon\"] = epsilon\n",
    "            df_result[\"delta\"] = delta\n",
    "            df_result[\"scale\"] = round(scale, 2)\n",
    "            df_result[\"model\"] = model_name\n",
    "            all_results.append(df_result.copy())\n",
    "\n",
    "# === Combine results ===\n",
    "df_robust = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# === Unpack 'robustness' dictionary column into separate columns ===\n",
    "df_flat = pd.concat(\n",
    "    [df_robust.drop(columns=[\"robustness\"]),\n",
    "     df_robust[\"robustness\"].apply(pd.Series)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === Add derived columns ===\n",
    "df_flat[\"1-p1\"] = (1.0 - df_flat[\"p1\"]).round(5)\n",
    "df_flat[\"1-p2\"] = (1.0 - df_flat[\"p2\"]).round(5)\n",
    "\n",
    "# Resulting DataFrame: df_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure model name consistency and ordering\n",
    "#model_order = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "model_order = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "#Ns = sorted(df_flat[\"N\"].unique())\n",
    "\n",
    "# Global color scale (consistent across all plots)\n",
    "vmin = df_flat[\"1-p1\"].min()\n",
    "vmax = df_flat[\"1-p1\"].max()\n",
    "\n",
    "short_names = {\n",
    "    \"Gaussian\": \"Gauss\",\n",
    "    \"Regularized Horseshoe\": \"RHS\",\n",
    "    \"Dirichlet Horseshoe\": \"DHS\",\n",
    "    \"Dirichlet Student T\": \"DS-T\",\n",
    "}\n",
    "\n",
    "# short_names = {\n",
    "#     \"Gaussian tanh\": \"Gauss\",\n",
    "#     \"Regularized Horseshoe tanh\": \"RHS\",\n",
    "#     \"Dirichlet Horseshoe tanh\": \"DHS\",\n",
    "#     \"Dirichlet Student T tanh\": \"DS-T\",\n",
    "# }\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "\n",
    "for j, model in enumerate(model_order):\n",
    "    row, col = divmod(j, 2)\n",
    "    ax = axes[row, col]\n",
    "    df_model = df_flat[df_flat[\"model\"] == model]\n",
    "\n",
    "    # Use pivot_table to handle duplicates\n",
    "    heatmap_df = df_model.pivot_table(\n",
    "        index=\"scale\", columns=\"epsilon\", values=\"1-p1\", aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_df.sort_index(ascending=False),\n",
    "        annot=True, fmt=\".2f\", cmap=\"RdYlGn\", ax=ax,\n",
    "        cbar=False, vmin=vmin, vmax=vmax\n",
    "    )\n",
    "\n",
    "    #ax.set_title(model, fontsize=13)\n",
    "    ax.set_title(short_names[model], fontsize=13)\n",
    "    ax.set_xlabel(r\"$\\varepsilon$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$\\delta / \\varepsilon$\", fontsize=12)\n",
    "\n",
    "# Adjust layout to leave space for colorbar\n",
    "plt.tight_layout(rect=[0, 0, 0.93, 0.95])\n",
    "\n",
    "# Add colorbar on the right\n",
    "cbar_ax = fig.add_axes([0.94, 0.25, 0.015, 0.5])  # [left, bottom, width, height]\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdYlGn\", norm=norm)\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm, cax=cbar_ax, label='$1 - p_1$')\n",
    "\n",
    "fig.suptitle(f\"Softmax Shift Robustness (1 - $p_1$)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming df is your big dataframe\n",
    "summary = (\n",
    "    df_flat.groupby(\"model\")[\"1-p2\"]\n",
    "      .agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "      .reset_index()\n",
    "      .round(3)\n",
    ")\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure correct model order for consistency\n",
    "model_order = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "palette = sns.color_palette(\"Set2\", n_colors=4)\n",
    "\n",
    "# # Optional: choose one N (or loop if needed)\n",
    "# N_select = 100\n",
    "# df_plot = df_flat[df_flat[\"N\"] == N_select]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(\n",
    "    data=df_flat,\n",
    "    x=\"epsilon\",\n",
    "    y=\"1-p2\",\n",
    "    hue=\"model\",\n",
    "    hue_order=model_order,\n",
    "    palette=palette,\n",
    "    cut=0,\n",
    "    inner=\"quartile\",\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "plt.title(f\"Label Invariance Probability ($1 - p_2$) across models\")\n",
    "plt.xlabel(r\"Adversarial strength $\\varepsilon$\")\n",
    "plt.ylabel(r\"$1-p_2$\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(0.02, 0.05))\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "entropy_data = {}  # store outputs\n",
    "\n",
    "for model in model_names:\n",
    "    probs = relu_fits[model][\"posterior\"].stan_variable(\"prob_test\")  # shape: (S, N_test, 2)\n",
    "\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    predictive_entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-12), axis=1)\n",
    "\n",
    "    sample_entropies = -np.sum(probs * np.log(probs + 1e-12), axis=2)\n",
    "    expected_entropy = np.mean(sample_entropies, axis=0)\n",
    "\n",
    "    mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "    y_pred = np.argmax(mean_probs, axis=1) + 1  # add 1 only if y_test is 1/2\n",
    "    correct = (y_pred == y_test)\n",
    "\n",
    "    # Store everything\n",
    "    entropy_data[model] = {\n",
    "        \"entropy\": predictive_entropy,\n",
    "        \"mutual_info\": mutual_information,\n",
    "        \"correct\": correct\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    entropy = entropy_data[model][\"entropy\"]\n",
    "    mi = entropy_data[model][\"mutual_info\"]\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "\n",
    "    ax.scatter(entropy[correct], mi[correct], color='green', alpha=0.5, label='Correct')\n",
    "    ax.scatter(entropy[~correct], mi[~correct], color='red', alpha=0.5, label='Incorrect')\n",
    "\n",
    "    ax.set_title(model)\n",
    "    ax.set_xlabel(\"Predictive Entropy\")\n",
    "    ax.set_ylabel(\"Mutual Information\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Legend only once\n",
    "axs[0].legend()\n",
    "plt.suptitle(\"Mutual Information vs Entropy Colored by Prediction Correctness\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "    acc = np.mean(correct)\n",
    "    avg_entropy = np.mean(entropy_data[model][\"entropy\"])\n",
    "    avg_mi = np.mean(entropy_data[model][\"mutual_info\"])\n",
    "    print(f\"{model}: Accuracy={acc:.3f}, Avg Entropy={avg_entropy:.3f}, Avg MI={avg_mi:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "entropy_data = {}  # store outputs\n",
    "\n",
    "for model in model_names:\n",
    "    probs = tanh_fits[model][\"posterior\"].stan_variable(\"prob_test\")  # shape: (S, N_test, 2)\n",
    "\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    predictive_entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-12), axis=1)\n",
    "\n",
    "    sample_entropies = -np.sum(probs * np.log(probs + 1e-12), axis=2)\n",
    "    expected_entropy = np.mean(sample_entropies, axis=0)\n",
    "\n",
    "    mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "    y_pred = np.argmax(mean_probs, axis=1) + 1  # add 1 only if y_test is 1/2\n",
    "    correct = (y_pred == y_test)\n",
    "\n",
    "    # Store everything\n",
    "    entropy_data[model] = {\n",
    "        \"entropy\": predictive_entropy,\n",
    "        \"mutual_info\": mutual_information,\n",
    "        \"correct\": correct\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, model in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    entropy = entropy_data[model][\"entropy\"]\n",
    "    mi = entropy_data[model][\"mutual_info\"]\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "\n",
    "    ax.scatter(entropy[correct], mi[correct], color='green', alpha=0.5, label='Correct')\n",
    "    ax.scatter(entropy[~correct], mi[~correct], color='red', alpha=0.5, label='Incorrect')\n",
    "\n",
    "    ax.set_title(model)\n",
    "    ax.set_xlabel(\"Predictive Entropy\")\n",
    "    ax.set_ylabel(\"Mutual Information\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Legend only once\n",
    "axs[0].legend()\n",
    "plt.suptitle(\"Mutual Information vs Entropy Colored by Prediction Correctness\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    correct = entropy_data[model][\"correct\"]\n",
    "    acc = np.mean(correct)\n",
    "    avg_entropy = np.mean(entropy_data[model][\"entropy\"])\n",
    "    avg_mi = np.mean(entropy_data[model][\"mutual_info\"])\n",
    "    print(f\"{model}: Accuracy={acc:.3f}, Avg Entropy={avg_entropy:.3f}, Avg MI={avg_mi:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame first\n",
    "df = pd.DataFrame({\n",
    "    \"Entropy\": entropy_data[\"Dirichlet Student T tanh\"][\"entropy\"],\n",
    "    \"MI\": entropy_data[\"Dirichlet Student T tanh\"][\"mutual_info\"],\n",
    "    \"Correct\": entropy_data[\"Dirichlet Student T tanh\"][\"correct\"]\n",
    "})\n",
    "\n",
    "# Plot\n",
    "sns.jointplot(\n",
    "    data=df,\n",
    "    x=\"Entropy\",\n",
    "    y=\"MI\",\n",
    "    hue=\"Correct\",\n",
    "    kind=\"scatter\",\n",
    "    palette={True: \"green\", False: \"red\"},\n",
    "    alpha=0.5,\n",
    "    marginal_kws=dict(fill=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
