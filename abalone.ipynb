{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/abalone\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/abalone\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/abalone\"\n",
    "#model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "full_config_path = \"abalone_N3341_p8\"\n",
    "relu_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_entry in tanh_fit.items():\n",
    "    posterior = model_entry[\"posterior\"]\n",
    "\n",
    "    # Get posterior predictive samples for the test set (shape: [n_draws, n_test])\n",
    "    y_pred_samples = posterior.stan_variable(\"output_test\").squeeze(-1)  # shape: (n_draws, n_test)\n",
    "\n",
    "    # Compute posterior mean predictions\n",
    "    y_pred_mean = np.mean(y_pred_samples, axis=0)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_mean))\n",
    "\n",
    "    # Compute CRPS\n",
    "    #crps = np.mean(crps_ensemble(y_test, y_pred_samples.T))  # crps_ensemble wants shape (n_test, n_draws)\n",
    "    \n",
    "    #max_draws = 500\n",
    "    #idx = np.random.choice(y_pred_samples.shape[0], max_draws, replace=False)\n",
    "    #y_pred_samples_sub = y_pred_samples[idx, :]\n",
    "    #crps = np.mean(crps_ensemble(y_test, y_pred_samples.T))\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "    #    \"CRPS\": crps\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "y_preds = relu_fit['Gaussian']['posterior'].stan_variable(\"output_test\").squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_draws = 10\n",
    "idx = np.random.choice(y_preds.shape[0], max_draws, replace=False)\n",
    "y_pred_samples_sub = y_preds[idx, :]\n",
    "crps = np.mean(crps_ensemble(y_test, y_preds.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = results_df.to_latex(index=False, float_format=\"%.4f\", column_format=\"lcc\", caption=\"RMSE and CRPS per model.\", label=\"tab:rmse_crps\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_abalone_regression_data\n",
    "def compute_sparse_rmse_results_abalone(models, all_fits, forward_pass,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found:\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        rmses = np.zeros(S)\n",
    "        #print(y_test.shape)\n",
    "        _, X_test, _, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            # Apply pruning mask if requested\n",
    "            if prune_fn is not None and sparsity > 0.0:\n",
    "                masks = prune_fn([W1, W2], sparsity)\n",
    "                W1 = W1 * masks[0]\n",
    "                #W2 = W2 * masks[1]\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "            y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "            rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "            \n",
    "        posterior_mean = np.mean(y_hats, axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "        posterior_means.append({\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'posterior_mean_rmse': posterior_mean_rmse\n",
    "        })\n",
    "\n",
    "        for i in range(S):\n",
    "            results.append({\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'rmse': rmses[i]\n",
    "            })\n",
    "\n",
    "    df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    return df_rmse, df_posterior_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "df_rmse_relu, df_posterior_rmse_relu = {}, {}\n",
    "df_rmse_tanh, df_posterior_rmse_tanh = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    df_rmse_relu[sparsity], df_posterior_rmse_relu[sparsity] = compute_sparse_rmse_results_abalone(\n",
    "        models = model_names_relu,\n",
    "        all_fits = relu_fit, \n",
    "        forward_pass = forward_pass_relu,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n",
    "\n",
    "    df_rmse_tanh[sparsity], df_posterior_rmse_tanh[sparsity] = compute_sparse_rmse_results_abalone(\n",
    "        models = model_names_tanh,\n",
    "        all_fits = tanh_fit, \n",
    "        forward_pass = forward_pass_tanh,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "df_rmse_full_relu = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_tanh = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_tanh.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Plot (simplified version)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "custom_palette = {\n",
    "    \"Gaussian\": \"C0\",\n",
    "    \"Regularized Horseshoe\": \"C1\",\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Student T\": \"C3\",\n",
    "}\n",
    "# Clean names\n",
    "df_rmse_full_relu[\"model\"] = df_rmse_full_relu[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "df_rmse_full_tanh[\"model\"] = df_rmse_full_tanh[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "activation_data = [(\"ReLU\", df_rmse_full_relu), (\"tanh\", df_rmse_full_tanh)]\n",
    "\n",
    "for ax, (name, df) in zip(axes, activation_data):\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x='sparsity', y='rmse',\n",
    "        hue='model', marker='o', errorbar=None, ax=ax,\n",
    "        palette=custom_palette,\n",
    "    )\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Sparsity level\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(title=\"Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Combine only ReLU\n",
    "df_rmse_full_relu = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Clean model names\n",
    "df_rmse_full_relu[\"model\"] = df_rmse_full_relu[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "# Custom colors\n",
    "custom_palette = {\n",
    "    \"Gaussian\": \"C0\",\n",
    "    \"Regularized Horseshoe\": \"C1\",\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Student T\": \"C3\",\n",
    "}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.lineplot(\n",
    "    data=df_rmse_full_relu,\n",
    "    x='sparsity', y='rmse',\n",
    "    hue='model', marker='o', errorbar=None,\n",
    "    palette=custom_palette,\n",
    ")\n",
    "plt.title(\"ReLU\")\n",
    "plt.xlabel(\"Sparsity level\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "\n",
    "model_preds = {}\n",
    "for model_name in model_names:\n",
    "    preds = relu_fit[model_name]['posterior'].stan_variable(\"output_test_rng\")\n",
    "    model_preds[model_name] = {\n",
    "        \"mean\": np.mean(preds, axis=0).squeeze(-1),\n",
    "        \"std\": np.std(preds, axis=0).squeeze(-1),\n",
    "        \"lower_95\": np.percentile(preds, 2.5, axis=0).squeeze(-1),\n",
    "        \"upper_95\": np.percentile(preds, 97.5, axis=0).squeeze(-1),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Get global limits for consistent scaling\n",
    "all_preds = np.concatenate([model_preds[m][\"mean\"] for m in model_names])\n",
    "y_min = min(y_test.min(), all_preds.min())\n",
    "y_max = max(y_test.max(), all_preds.max())\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    sc = ax.scatter(\n",
    "        y_test, model_preds[model_name][\"mean\"],\n",
    "        c=model_preds[model_name][\"std\"], cmap='viridis', alpha=0.7\n",
    "    )\n",
    "    ax.plot([y_min, y_max], [y_min, y_max], 'k--', lw=1)\n",
    "    ax.set_title(f\"{model_name}\")\n",
    "    ax.set_xlabel(\"True y\")\n",
    "    ax.set_ylabel(\"Predicted mean\")\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(y_min, y_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "cbar = fig.colorbar(sc, ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label(\"Predictive Std Dev\")\n",
    "plt.suptitle(\"Regression Predictions with Uncertainty\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = {}\n",
    "for model_name in model_names:\n",
    "    lower = model_preds[model_name][\"lower_95\"]\n",
    "    upper = model_preds[model_name][\"upper_95\"]\n",
    "    inside = (y_test >= lower) & (y_test <= upper)\n",
    "    coverage[model_name] = np.mean(inside)\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(coverage.keys(), coverage.values())\n",
    "plt.axhline(0.95, color='red', linestyle='--', label='Ideal Coverage (95%)')\n",
    "plt.ylabel(\"Proportion Covered\")\n",
    "plt.title(\"Coverage of 95% Predictive Intervals\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for model_name in model_names:\n",
    "    errors = np.abs(model_preds[model_name][\"mean\"] - y_test)\n",
    "    stds = model_preds[model_name][\"std\"]\n",
    "    plt.scatter(stds, errors, label=model_name, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Predictive Std Dev\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.title(\"Error vs. Uncertainty\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    pred = model_preds[model_name][\"mean\"]\n",
    "    mae = np.mean(np.abs(pred - y_test))\n",
    "    rmse = np.sqrt(np.mean((pred - y_test) ** 2))\n",
    "    width = np.mean(model_preds[model_name][\"upper_95\"] - model_preds[model_name][\"lower_95\"])\n",
    "    print(f\"{model_name}: MAE = {mae:.3f}, RMSE = {rmse:.3f}, Avg Interval Width = {width:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "model_preds = {}\n",
    "for model_name in model_names:\n",
    "    preds = tanh_fit[model_name]['posterior'].stan_variable(\"output_test_rng\")\n",
    "    model_preds[model_name] = {\n",
    "        \"mean\": np.mean(preds, axis=0).squeeze(-1),\n",
    "        \"std\": np.std(preds, axis=0).squeeze(-1),\n",
    "        \"lower_95\": np.percentile(preds, 2.5, axis=0).squeeze(-1),\n",
    "        \"upper_95\": np.percentile(preds, 97.5, axis=0).squeeze(-1),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    ax = axs[i]\n",
    "    sc = ax.scatter(y_test, model_preds[model_name][\"mean\"],\n",
    "                    c=model_preds[model_name][\"std\"], cmap='viridis', alpha=0.7)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=1)\n",
    "    ax.set_title(f\"{model_name}\")\n",
    "    ax.set_xlabel(\"True y\")\n",
    "    ax.set_ylabel(\"Predicted mean\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "cbar = fig.colorbar(sc, ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label(\"Predictive Std Dev\")\n",
    "plt.suptitle(\"Regression Predictions with Uncertainty\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = {}\n",
    "for model_name in model_names:\n",
    "    lower = model_preds[model_name][\"lower_95\"]\n",
    "    upper = model_preds[model_name][\"upper_95\"]\n",
    "    inside = (y_test >= lower) & (y_test <= upper)\n",
    "    coverage[model_name] = np.mean(inside)\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(coverage.keys(), coverage.values())\n",
    "plt.axhline(0.95, color='red', linestyle='--', label='Ideal Coverage (95%)')\n",
    "plt.ylabel(\"Proportion Covered\")\n",
    "plt.title(\"Coverage of 95% Predictive Intervals\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for model_name in model_names:\n",
    "    errors = np.abs(model_preds[model_name][\"mean\"] - y_test)\n",
    "    stds = model_preds[model_name][\"std\"]\n",
    "    plt.scatter(stds, errors, label=model_name, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Predictive Std Dev\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.title(\"Error vs. Uncertainty\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    pred = model_preds[model_name][\"mean\"]\n",
    "    mae = np.mean(np.abs(pred - y_test))\n",
    "    rmse = np.sqrt(np.mean((pred - y_test) ** 2))\n",
    "    width = np.mean(model_preds[model_name][\"upper_95\"] - model_preds[model_name][\"lower_95\"])\n",
    "    print(f\"{model_name}: MAE = {mae:.3f}, RMSE = {rmse:.3f}, Avg Interval Width = {width:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY FULL REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/abalone\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/abalone/full_regularization\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/abalone/full_regularization\"\n",
    "#model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "full_config_path = \"abalone_N3341_p8\"\n",
    "relu_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_entry in tanh_fit.items():\n",
    "    posterior = model_entry[\"posterior\"]\n",
    "\n",
    "    # Get posterior predictive samples for the test set (shape: [n_draws, n_test])\n",
    "    y_pred_samples = posterior.stan_variable(\"output_test\").squeeze(-1)  # shape: (n_draws, n_test)\n",
    "\n",
    "    # Compute posterior mean predictions\n",
    "    y_pred_mean = np.mean(y_pred_samples, axis=0)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_mean))\n",
    "\n",
    "    # Compute CRPS\n",
    "    #crps = np.mean(crps_ensemble(y_test, y_pred_samples.T))  # crps_ensemble wants shape (n_test, n_draws)\n",
    "    \n",
    "    #max_draws = 500\n",
    "    #idx = np.random.choice(y_pred_samples.shape[0], max_draws, replace=False)\n",
    "    #y_pred_samples_sub = y_pred_samples[idx, :]\n",
    "    #crps = np.mean(crps_ensemble(y_test, y_pred_samples.T))\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE\": rmse,\n",
    "    #    \"CRPS\": crps\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
