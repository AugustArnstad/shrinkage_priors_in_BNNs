{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/friedman\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/friedman\"\n",
    "\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\"]#, \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\"]#, \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "relu_fits = {}\n",
    "tanh_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # → \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=model_names_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh,\n",
    "        models=model_names_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "    relu_fits[base_config_name] = relu_fit  # use clean key\n",
    "    tanh_fits[base_config_name] = tanh_fit  # use clean key\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def mean_abs(arr):  # arr: (S, ...)\n",
    "    return np.mean(np.abs(np.asarray(arr)), axis=0)\n",
    "\n",
    "def nid_single_hidden(posterior, W1_name=\"W_1\", WL_name_candidates=(\"W_L\",\"W_2\")):\n",
    "    \"\"\"\n",
    "    posterior: CmdStanMCMC-objekt\n",
    "    W_1: shape (S, P, H)  (input -> hidden), som du har\n",
    "    W_L: shape (S, H) eller (S, H, O)  (hidden -> output)\n",
    "    \"\"\"\n",
    "    W1_samps = posterior.stan_variable(W1_name)          # (S, P, H)\n",
    "    # Finn navn for siste lag\n",
    "    for nm in WL_name_candidates:\n",
    "        try:\n",
    "            WL_samps = posterior.stan_variable(nm)       # (S, H) eller (S, H, O)\n",
    "            break\n",
    "        except Exception:\n",
    "            WL_samps = None\n",
    "    if WL_samps is None:\n",
    "        raise ValueError(\"Fant ikke siste-lag-vekter (prøv å angi riktig navn i WL_name_candidates).\")\n",
    "\n",
    "    # Posterior plug-in: gjennomsnitt av absoluttverdier\n",
    "    W1_abs = mean_abs(W1_samps)                          # (P, H)\n",
    "    WL_abs = mean_abs(WL_samps)                          # (H,) eller (H, O)\n",
    "\n",
    "    # z^(1): aggregert node-innflytelse (sum over outputs hvis flere)\n",
    "    if WL_abs.ndim == 1:\n",
    "        z1 = WL_abs                                      # (H,)\n",
    "    else:\n",
    "        z1 = WL_abs.sum(axis=1)                          # (H,)\n",
    "\n",
    "    P, H = W1_abs.shape\n",
    "\n",
    "    # Main effects: ω({j}) = Σ_i z_i * |W1[j,i]|\n",
    "    omega_main = (W1_abs * z1[None, :]).sum(axis=1)      # (P,)\n",
    "\n",
    "    # Pairwise: ω({j,k}) = Σ_i z_i * min(|W1[j,i]|, |W1[k,i]|)\n",
    "    omega_pair = np.zeros((P, P))\n",
    "    for j, k in combinations(range(P), 2):\n",
    "        mins = np.minimum(W1_abs[j, :], W1_abs[k, :])    # (H,)\n",
    "        omega = np.dot(z1, mins)                         # skalar\n",
    "        omega_pair[j, k] = omega_pair[k, j] = omega\n",
    "\n",
    "    return z1, omega_main, omega_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = relu_fits['Friedman_N100_p10_sigma1.00_seed1']['Gaussian']['posterior'] \n",
    "z1, omega_main, omega_pair = nid_single_hidden(post) # W_1=(S,P,H), W_L/(W_2)=(S,H[,O]) # Eksempler: # - topp 10 viktigste noder etter z1: \n",
    "top_nodes = np.argsort(-z1) # - topp 10 viktigste features (main effects): \n",
    "top_feats = np.argsort(-omega_main) # - sterkeste parvise interaksjoner: \n",
    "P = omega_pair.shape[0] \n",
    "pairs = [(j, k, omega_pair[j, k]) for j in range(P) for k in range(j+1, P)] \n",
    "top_pairs = sorted(pairs, key=lambda t: -t[2])[:10]\n",
    "\n",
    "res = np.array(omega_main/(np.sum(omega_main)))\n",
    "print(np.round(res, 3))\n",
    "\n",
    "print(np.round(top_pairs, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
