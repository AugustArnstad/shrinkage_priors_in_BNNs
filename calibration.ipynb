{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman_correlated\"\n",
    "#results_dir_relu = \"results/regression/single_layer/relu/friedman\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/friedman_correlated\"\n",
    "\n",
    "#model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Pred CP tanh\"]\n",
    "\n",
    "\n",
    "#relu_fits = {}\n",
    "tanh_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # → \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    # relu_fit = get_model_fits(\n",
    "    #     config=full_config_path,\n",
    "    #     results_dir=results_dir_relu,\n",
    "    #     models=model_names_relu,\n",
    "    #     include_prior=False,\n",
    "    # )\n",
    "    \n",
    "    tanh_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh,\n",
    "        models=model_names_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "    #relu_fits[base_config_name] = relu_fit  # use clean key\n",
    "    tanh_fits[base_config_name] = tanh_fit  # use clean key\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Inputs you already have ---\n",
    "path = f\"datasets/friedman_correlated/Friedman_N500_p10_sigma1.00_seed11.npz\"\n",
    "data = np.load(path)\n",
    "X_test, y_test = data[\"X_test\"], data[\"y_test\"]\n",
    "rows = []\n",
    "\n",
    "\n",
    "def compute_ppll(y_test, mu_draws, sigma_draws):\n",
    "    \"\"\"\n",
    "    y_test: (n,)\n",
    "    mu_draws: (S, n) predictive means per draw (your 'output_test')\n",
    "    sigma_draws: (S,) homoskedastic noise per draw\n",
    "    returns:\n",
    "      lppd_n: (n,) per-point log posterior predictive density\n",
    "      ppll_total, ppll_mean\n",
    "    \"\"\"\n",
    "    S, n = mu_draws.shape\n",
    "    # log p(y_n | draw s) for Gaussian: -0.5*log(2π) - log σ_s - 0.5*((y - μ_s)^2/σ_s^2)\n",
    "    resid2 = (mu_draws - y_test[None, :])**2                   # (S, n)\n",
    "    loglik_sn = (\n",
    "        -0.5 * np.log(2 * np.pi)\n",
    "        - np.log(sigma_draws)[:, None]\n",
    "        - 0.5 * resid2 / (sigma_draws[:, None] ** 2)\n",
    "    )  # (S, n)\n",
    "    # lppd_n = log( (1/S) * Σ_s exp(loglik_sn) ) = logsumexp - log S\n",
    "    lppd_n = logsumexp(loglik_sn, axis=0) - np.log(S)\n",
    "    return lppd_n, float(lppd_n.sum()), float(lppd_n.mean())\n",
    "\n",
    "def predictive_mean_and_ci(mu_draws, sigma_draws, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Normal-mixture approx via total variance:\n",
    "      E[Y|x] ≈ mean_s mu_s\n",
    "      Var[Y|x] ≈ mean_s (sigma_s^2 + (mu_s - E[mu])^2)\n",
    "    returns:\n",
    "      y_mean: (n,), y_std: (n,), (low, high) CIs\n",
    "    \"\"\"\n",
    "    y_mean = mu_draws.mean(axis=0)  # (n,)\n",
    "    var_total = (sigma_draws**2)[:, None] + (mu_draws - y_mean[None, :])**2\n",
    "    y_var = var_total.mean(axis=0)\n",
    "    y_std = np.sqrt(y_var)\n",
    "    z = 1.959963984540054  # ~95%\n",
    "    return y_mean, y_std, (y_mean - z * y_std, y_mean + z * y_std)\n",
    "\n",
    "def smoothness_along_pc1(X, y_mean):\n",
    "    \"\"\"\n",
    "    Project X onto PC1, sort, compute a simple 'total variation' roughness.\n",
    "    Returns:\n",
    "      z (sorted PC1), y_sorted, tv (mean |Δy|)\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=1).fit(X)\n",
    "    z = pca.transform(X).ravel()\n",
    "    idx = np.argsort(z)\n",
    "    z_sorted = z[idx]\n",
    "    y_sorted = y_mean[idx]\n",
    "    dy = np.diff(y_sorted)\n",
    "    tv = float(np.mean(np.abs(dy)))  # simple roughness score\n",
    "    return z_sorted, y_sorted, tv\n",
    "\n",
    "dataset_key = \"Friedman_N500_p10_sigma1.00_seed11\"\n",
    "for model_name, model_entry in tanh_fits[dataset_key].items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    # Predictive means (S, n_test). You already store 'output_test' as deterministic means.\n",
    "    mu_draws = post.stan_variable(\"output_test\").squeeze(-1)  # (S, n)\n",
    "    sigma_draws = post.stan_variable(\"sigma\").reshape(-1)     # (S,)\n",
    "\n",
    "    # ---- Metrics: PPLL ----\n",
    "    lppd_n, ppll_total, ppll_mean = compute_ppll(y_test, mu_draws, sigma_draws)\n",
    "\n",
    "    # For reference: posterior mean predictions (also used in smoothness)\n",
    "    y_mean, y_std, (ci_lo, ci_hi) = predictive_mean_and_ci(mu_draws, sigma_draws)\n",
    "\n",
    "    # ---- Smoothness proxy: variation along PC1 of X_test ----\n",
    "    z_sorted, y_sorted, tv = smoothness_along_pc1(X_test, y_mean)\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"PPLL_total\": ppll_total,\n",
    "        \"PPLL_mean\": ppll_mean,\n",
    "        \"TV_PC1\": tv,  # lower is smoother along dominant direction\n",
    "        \"n_draws\": mu_draws.shape[0]\n",
    "    })\n",
    "\n",
    "    # ---- Minimal visuals ----\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "    # (A) Per-point log posterior predictive density distribution\n",
    "    axes[0].hist(lppd_n, bins=30, edgecolor=\"k\")\n",
    "    axes[0].set_title(f\"{model_name} — per-point log p(y|x,data)\")\n",
    "    axes[0].set_xlabel(\"lppd (per point)\")\n",
    "    axes[0].set_ylabel(\"count\")\n",
    "\n",
    "    # (B) Function profile along PC1 with ~95% predictive band (Normal-mixture approx)\n",
    "    # Reorder to match z_sorted\n",
    "    order = np.argsort(PCA(n_components=1).fit(X_test).transform(X_test).ravel())\n",
    "    axes[1].plot(z_sorted, y_sorted, lw=2, label=\"posterior mean\")\n",
    "    axes[1].fill_between(z_sorted, ci_lo[order], ci_hi[order], alpha=0.2, label=\"~95% pred. band\")\n",
    "    axes[1].set_title(f\"{model_name} — profile along PC1 (TV={tv:.3g})\")\n",
    "    axes[1].set_xlabel(\"PC1 score (X_test)\")\n",
    "    axes[1].set_ylabel(\"prediction\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results_ppll_df = pd.DataFrame(rows).sort_values(\"PPLL_mean\", ascending=False)\n",
    "print(results_ppll_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = f\"datasets/friedman_correlated/Friedman_N500_p10_sigma1.00_seed11.npz\"\n",
    "data = np.load(path)\n",
    "X_test, y_test = data[\"X_test\"], data[\"y_test\"]\n",
    "rows = []\n",
    "for model_name, model_entry in tanh_fits['Friedman_N500_p10_sigma1.00_seed11'].items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    # (S, n_test)\n",
    "    y_samps = post.stan_variable(\"output_test\").squeeze(-1)\n",
    "\n",
    "    # Posterior-mean predictions and RMSE\n",
    "    y_mean = y_samps.mean(axis=0)                                   # (n_test,)\n",
    "    rmse_post_mean = float(np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "\n",
    "    # Per-draw RMSEs and their mean\n",
    "    per_draw_rmse = np.sqrt(((y_samps - y_test[None, :])**2).mean(axis=1))  # (S,)\n",
    "    rmse_draw_mean = float(per_draw_rmse.mean())\n",
    "\n",
    "    # CRPS across the ensemble (expects shape (n_test, S))\n",
    "    crps = float(np.mean(crps_ensemble(y_test, y_samps.T)))\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE_posterior_mean\": rmse_post_mean,\n",
    "        \"RMSE_mean_over_draws\": rmse_draw_mean,\n",
    "        \"CRPS\": crps,\n",
    "        \"n_draws\": y_samps.shape[0]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE_posterior_mean\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Config / inputs you already have\n",
    "# -------------------------------------------------\n",
    "rng = np.random.default_rng(12345)\n",
    "dataset_key = \"Friedman_N500_p10_sigma1.00_seed11\"  # adjust if needed\n",
    "path = f\"datasets/friedman_correlated/{dataset_key}.npz\"\n",
    "\n",
    "data = np.load(path)\n",
    "X_test = np.asarray(data[\"X_test\"])\n",
    "y_test = np.asarray(data[\"y_test\"]).reshape(-1)  # ensure 1-D (n,)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Utilities\n",
    "# -------------------------------------------------\n",
    "def _to_Sn(a):\n",
    "    \"\"\"Ensure array is (S, n): flatten any trailing dims, add leading dim if needed.\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 1:\n",
    "        return a[None, :]\n",
    "    return a.reshape(a.shape[0], -1)\n",
    "\n",
    "def predictive_samples(mu_draws, sigma_draws, rng, S_pred=None):\n",
    "    mu_draws = _to_Sn(mu_draws)     # (S, n)\n",
    "    sigma_draws = np.asarray(sigma_draws).reshape(-1)\n",
    "    S, n = mu_draws.shape\n",
    "    if S_pred is None or S_pred >= S:\n",
    "        eps = rng.standard_normal(size=(S, n))\n",
    "        return mu_draws + sigma_draws[:, None] * eps\n",
    "    idx = rng.choice(S, size=S_pred, replace=False)\n",
    "    eps = rng.standard_normal(size=(S_pred, n))\n",
    "    return mu_draws[idx] + sigma_draws[idx, None] * eps\n",
    "\n",
    "def coverage_and_width(y_test, y_pred, levels=(0.5, 0.8, 0.95)):\n",
    "    y_pred = _to_Sn(y_pred)\n",
    "    out = {}\n",
    "    for lev in levels:\n",
    "        alpha = (1.0 - lev) / 2.0\n",
    "        lo = np.quantile(y_pred, alpha, axis=0)\n",
    "        hi = np.quantile(y_pred, 1 - alpha, axis=0)\n",
    "        cov = float(np.mean((y_test >= lo) & (y_test <= hi)))\n",
    "        width = float(np.mean(hi - lo))\n",
    "        out[f\"cov_{int(lev*100)}\"] = cov\n",
    "        out[f\"width_{int(lev*100)}\"] = width\n",
    "    return out\n",
    "\n",
    "def predictive_mean_std(mu_draws, sigma_draws):\n",
    "    mu_draws = _to_Sn(mu_draws)\n",
    "    sigma_draws = np.asarray(sigma_draws).reshape(-1)\n",
    "    y_mean = mu_draws.mean(axis=0)\n",
    "    y_var = (sigma_draws**2)[:, None].mean(axis=0) + mu_draws.var(axis=0, ddof=0)\n",
    "    return y_mean, np.sqrt(y_var)\n",
    "\n",
    "def pit_values(y_test, y_pred):\n",
    "    y_pred = _to_Sn(y_pred)\n",
    "    return np.mean(y_pred <= y_test[None, :], axis=0)  # (n,)\n",
    "\n",
    "def quantile_calibration(y_test, y_pred, q_grid=None, debug=False, tag=\"\"):\n",
    "    \"\"\"\n",
    "    y_test: (n,)\n",
    "    y_pred: (S, n) or (S, n, 1)\n",
    "    Returns (q_grid (Q,), emp (Q,), ece (float))\n",
    "    \"\"\"\n",
    "    y_pred = _to_Sn(y_pred)                         # (S, n)\n",
    "    n = y_pred.shape[1]\n",
    "    if q_grid is None:\n",
    "        q_grid = np.linspace(0.05, 0.95, 19)        # (Q,)\n",
    "\n",
    "    # Predictive quantiles per x: (Q, n)\n",
    "    # IMPORTANT: pass q_grid as 1-D → output shape (Q, n)\n",
    "    qtile = np.quantile(y_pred, q_grid, axis=0)     # (Q, n)\n",
    "\n",
    "    # Explicit broadcast y_test to (Q, n), then compare\n",
    "    y_ref = np.broadcast_to(y_test.reshape(1, n), qtile.shape)  # (Q, n)\n",
    "    comp = (y_ref <= qtile)                                     # (Q, n)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[{tag}] y_test.shape  = {y_test.shape}\")\n",
    "        print(f\"[{tag}] y_pred.shape  = {y_pred.shape}\")\n",
    "        print(f\"[{tag}] q_grid.shape  = {q_grid.shape}\")\n",
    "        print(f\"[{tag}] qtile.shape   = {qtile.shape}\")\n",
    "        print(f\"[{tag}] comp.shape    = {comp.shape}\")\n",
    "\n",
    "    emp = comp.mean(axis=1)                          # (Q,)\n",
    "    ece = float(np.mean(np.abs(emp - q_grid)))\n",
    "    max_ece = float(np.max(np.abs(emp - q_grid)))\n",
    "    return q_grid, emp, ece, max_ece\n",
    "\n",
    "def compute_ppll(y_test, mu_draws, sigma_draws):\n",
    "    mu_draws = _to_Sn(mu_draws)\n",
    "    sigma_draws = np.asarray(sigma_draws).reshape(-1)\n",
    "    S, n = mu_draws.shape\n",
    "    resid2 = (mu_draws - y_test[None, :])**2  # (S, n)\n",
    "    loglik_sn = (\n",
    "        -0.5 * np.log(2 * np.pi)\n",
    "        - np.log(sigma_draws)[:, None]\n",
    "        - 0.5 * resid2 / (sigma_draws[:, None] ** 2)\n",
    "    )  # (S, n)\n",
    "    lppd_n = logsumexp(loglik_sn, axis=0) - np.log(S)  # (n,)\n",
    "    return lppd_n, float(lppd_n.sum()), float(lppd_n.mean())\n",
    "\n",
    "def smoothness_along_pc1(X, y_mean):\n",
    "    pca = PCA(n_components=1).fit(X)\n",
    "    z = pca.transform(X).ravel()\n",
    "    idx = np.argsort(z)\n",
    "    z_sorted = z[idx]\n",
    "    y_sorted = y_mean[idx]\n",
    "    tv = float(np.mean(np.abs(np.diff(y_sorted))))\n",
    "    return z_sorted, y_sorted, tv\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Loop models: PPLL + UQ diagnostics\n",
    "# -------------------------------------------------\n",
    "rows = []\n",
    "first = False\n",
    "for model_name, model_entry in tanh_fits[dataset_key].items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    mu_draws = _to_Sn(post.stan_variable(\"output_test\")).squeeze()\n",
    "    mu_draws = _to_Sn(mu_draws)  # enforce (S, n)\n",
    "    sigma_draws = np.asarray(post.stan_variable(\"sigma\")).reshape(-1)  # (S,)\n",
    "\n",
    "    # -------- PPLL --------\n",
    "    lppd_n, ppll_total, ppll_mean = compute_ppll(y_test, mu_draws, sigma_draws)\n",
    "\n",
    "    # -------- Smoothness (PC1) --------\n",
    "    y_mean, y_std = predictive_mean_std(mu_draws, sigma_draws)\n",
    "    z_sorted, y_sorted, tv_pc1 = smoothness_along_pc1(X_test, y_mean)\n",
    "\n",
    "    # -------- Predictive samples for UQ --------\n",
    "    y_pred = predictive_samples(mu_draws, sigma_draws, rng)  # (S, n)\n",
    "\n",
    "    # Coverage & widths\n",
    "    cov_info = coverage_and_width(y_test, y_pred, levels=(0.5, 0.8, 0.95))\n",
    "\n",
    "    # PIT + quantile calibration (print shapes for first model)\n",
    "    pit = pit_values(y_test, y_pred)  # (n,)\n",
    "    q_grid, emp, ece, max_ece = quantile_calibration(y_test, y_pred, debug=first, tag=model_name)\n",
    "    first = False\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"PPLL_total\": ppll_total,\n",
    "        \"PPLL_mean\": ppll_mean,\n",
    "        \"TV_PC1\": tv_pc1,\n",
    "        **cov_info,\n",
    "        \"sharpness_mean_sd\": float(y_std.mean()),\n",
    "        \"ECE_quantile\": ece,\n",
    "        \"max_ECE\": max_ece,\n",
    "        \"n_draws\": mu_draws.shape[0],\n",
    "    })\n",
    "\n",
    "    # -------- Minimal visuals per model --------\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(17, 3.8))\n",
    "\n",
    "    # (A) Per-point lppd histogram\n",
    "    axes[0].hist(lppd_n, bins=30, edgecolor=\"k\")\n",
    "    axes[0].set_title(f\"{model_name} — per-point log p(y|x,data)\")\n",
    "    axes[0].set_xlabel(\"lppd (per point)\")\n",
    "    axes[0].set_ylabel(\"count\")\n",
    "\n",
    "    # (B) Function profile along PC1 with ~95% predictive band (Normal-mixture approx)\n",
    "    order = np.argsort(PCA(n_components=1).fit(X_test).transform(X_test).ravel())\n",
    "    z_plot = z_sorted\n",
    "    ci_lo = y_mean - 1.96 * y_std\n",
    "    ci_hi = y_mean + 1.96 * y_std\n",
    "    axes[1].plot(z_plot, y_sorted, lw=2, label=\"posterior mean\")\n",
    "    axes[1].fill_between(z_plot, ci_lo[order], ci_hi[order], alpha=0.2, label=\"~95% pred. band\")\n",
    "    axes[1].set_title(f\"{model_name} — profile PC1 (TV={tv_pc1:.3g})\")\n",
    "    axes[1].set_xlabel(\"PC1 score (X_test)\")\n",
    "    axes[1].set_ylabel(\"prediction\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # (C) PIT histogram\n",
    "    axes[2].hist(pit, bins=20, range=(0, 1), edgecolor=\"k\")\n",
    "    axes[2].axhline(len(pit) / 20, ls=\"--\")\n",
    "    axes[2].set_title(f\"{model_name} — PIT\")\n",
    "    axes[2].set_xlabel(\"PIT\")\n",
    "    axes[2].set_ylabel(\"count\")\n",
    "\n",
    "    # (D) Quantile calibration curve\n",
    "    axes[3].plot(q_grid, q_grid, ls=\"--\", label=\"ideal\")\n",
    "    axes[3].plot(q_grid, emp, marker=\"o\", lw=1.5, label=f\"empirical (ECE={ece:.3f})\")\n",
    "    axes[3].set_title(f\"{model_name} — quantile calibration\")\n",
    "    axes[3].set_xlabel(\"nominal quantile q\")\n",
    "    axes[3].set_ylabel(\"empirical P(Y ≤ q̂_q)\")\n",
    "    axes[3].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values([\"PPLL_mean\"], ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
