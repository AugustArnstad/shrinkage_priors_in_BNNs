{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/mutual_information\"\n",
    "results_dir_tanh = \"results/mutual_information\"\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "#full_config_path = \"correlated_N400_p6_sigma_0.5\"\n",
    "\n",
    "tanh_fit_sigma_00 = get_model_fits(\n",
    "    config=\"mutual_information_N80_p6_sigma_0.0\",\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit_sigma_05 = get_model_fits(\n",
    "    config=\"mutual_information_N80_p6_sigma_0.5\",\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit_sigma_1 = get_model_fits(\n",
    "    config=\"mutual_information_N80_p6_sigma_1.0\",\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit_sigma_2 = get_model_fits(\n",
    "    config=\"mutual_information_N80_p6_sigma_2.0\",\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.special import digamma\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Data generator with σ\n",
    "# ---------------------------\n",
    "def generate_correlated_data_sigma(\n",
    "    n, p=6, random_state=42, test_size=0.2,\n",
    "    rho_strong=0.92, rho_weak=0.5, sigma=0.5,\n",
    "    standardize_X=True, standardize_y=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Nonlinear Y = g(X) + N(0, sigma^2).\n",
    "    Keep standardize_y=False so MI varies with sigma.\n",
    "    \"\"\"\n",
    "    if p != 6:\n",
    "        raise ValueError(\"This generator is designed for p=6.\")\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # latent factors -> correlated features\n",
    "    h1 = rng.normal(size=n); h2 = rng.normal(size=n)\n",
    "    def make_block(h, m, rho):\n",
    "        eps = rng.normal(size=(n, m))\n",
    "        return rho * h[:, None] + np.sqrt(max(1e-12, 1 - rho**2)) * eps\n",
    "\n",
    "    X_strong = make_block(h1, 4, rho_strong)  # X1..X4\n",
    "    X_weak   = make_block(h2, 2, rho_weak)    # X5..X6\n",
    "    X = np.concatenate([X_strong, X_weak], axis=1)\n",
    "\n",
    "    if standardize_X:\n",
    "        X = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-12)\n",
    "\n",
    "    X1, X2, X3, X4, X5, X6 = [X[:, j] for j in range(6)]\n",
    "    strong_lin = 0.6*X1 + 0.4*X2 - 0.2*X3 + 0.1*X4\n",
    "    strong_int = 1.2*(X1*X2) + 0.8*(X3*X4) - 0.6*(X1*X4)\n",
    "    weak_part  = 0.15*(0.7*X5 + 0.3*X6) + 0.12*(X5*X6)\n",
    "    g = np.tanh(strong_lin + strong_int) + 0.3*np.sin(0.5*X2 - 0.25*X3) + weak_part\n",
    "\n",
    "    y = g + rng.normal(scale=sigma, size=n)  # ADD noise with std = sigma\n",
    "\n",
    "    # do NOT standardize y; we want MI to depend on sigma\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# ------------------------------------\n",
    "# 2) KSG (k-NN) MI estimator for X,Y\n",
    "# ------------------------------------\n",
    "def ksmi_xy(X, y, k=5):\n",
    "    \"\"\"\n",
    "    Kraskov–Stögbauer–Grassberger MI estimator (type I).\n",
    "    X: (n, d), y: (n,)\n",
    "    Returns MI in nats.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float).reshape(-1, 1)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # joint space with Chebyshev (L∞) norm\n",
    "    Z = np.hstack([X, y])\n",
    "    nn_z = NearestNeighbors(n_neighbors=k+1, metric=\"chebyshev\").fit(Z)\n",
    "    dists, _ = nn_z.kneighbors(Z)\n",
    "    eps = dists[:, k] - 1e-12  # distance to k-th neighbor (exclude self)\n",
    "\n",
    "    # counts in marginal spaces within same eps (Chebyshev balls)\n",
    "    nx = NearestNeighbors(metric=\"chebyshev\").fit(X)\\\n",
    "         .radius_neighbors_graph(X, eps, mode=\"distance\").sum(axis=1) - 1\n",
    "    ny = NearestNeighbors(metric=\"chebyshev\").fit(y)\\\n",
    "         .radius_neighbors_graph(y, eps, mode=\"distance\").sum(axis=1) - 1\n",
    "\n",
    "    mi = digamma(k) + digamma(n) - np.mean(digamma(nx + 1) + digamma(ny + 1))\n",
    "    return float(mi)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3) Sweep over σ and compute KSG MI(X;Y)\n",
    "# ------------------------------------------\n",
    "def sweep_sigma_ksg(sigmas, n=1500, p=6, k=5, seed=7):\n",
    "    \"\"\"\n",
    "    Returns DataFrame with columns: sigma, mi.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sigma in sigmas:\n",
    "        X_tr, X_te, y_tr, y_te = generate_correlated_data_sigma(\n",
    "            n=n, p=p, random_state=seed, sigma=sigma,\n",
    "            standardize_X=True, standardize_y=False\n",
    "        )\n",
    "        mi = ksmi_xy(X_tr, y_tr, k=k)\n",
    "        rows.append({\"sigma\": float(sigma), \"mi\": mi})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------\n",
    "# 4) Example + plotting\n",
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.linspace(0.0, 2.0, 15)   # sweep noise up\n",
    "df = sweep_sigma_ksg(sigmas, n=2000, k=5, seed=11)\n",
    "print(df)\n",
    "\n",
    "# Plot like your sketch: x = MI(X;Y), y = performance proxy (1/σ)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot(df[\"sigma\"], df[\"mi\"])\n",
    "ax.set_xlabel(\"Estimated I(X;Y)\")\n",
    "ax.set_ylabel(\"σ\")\n",
    "ax.set_title(\"As σ increases, I(X;Y) decreases (KSG)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "from scipy.special import digamma\n",
    "\n",
    "# ---------------------------\n",
    "# KSG MI estimator (multivariate X, multivariate Y)\n",
    "# ---------------------------\n",
    "\n",
    "def ksmi_xy_multi(X, Y, k=5, jitter=0.0, random_state=0):\n",
    "    \"\"\"\n",
    "    KSG MI estimator (type I) for multivariate X and Y.\n",
    "    Uses KDTree with Minkowski p=∞ (Chebyshev).\n",
    "    X: (n, dx)\n",
    "    Y: (n, dy)\n",
    "    Returns MI in nats.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    Y = np.asarray(Y, float)\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    if jitter and jitter > 0:\n",
    "        X = X + jitter * rng.normal(size=X.shape)\n",
    "        Y = Y + jitter * rng.normal(size=Y.shape)\n",
    "\n",
    "    # Joint space distances to k-th neighbor\n",
    "    Z = np.hstack([X, Y])\n",
    "    tree_Z = KDTree(Z, metric='minkowski', p=np.inf)\n",
    "    dists, _ = tree_Z.query(Z, k=k+1)         # includes self at position 0\n",
    "    eps = dists[:, k] - 1e-12                 # per-sample radius\n",
    "\n",
    "    # Counts in marginals within same eps (Chebyshev balls)\n",
    "    tree_X = KDTree(X, metric='minkowski', p=np.inf)\n",
    "    tree_Y = KDTree(Y, metric='minkowski', p=np.inf)\n",
    "\n",
    "    # query_radius supports a vector of radii\n",
    "    nx = tree_X.query_radius(X, r=eps, count_only=True) - 1\n",
    "    ny = tree_Y.query_radius(Y, r=eps, count_only=True) - 1\n",
    "\n",
    "    # KSG type-I estimate\n",
    "    mi = digamma(k) + digamma(n) - np.mean(digamma(nx + 1) + digamma(ny + 1))\n",
    "    return float(mi)\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def _choose_sample_indices(S, K):\n",
    "    K = min(K, S)\n",
    "    return np.linspace(0, S-1, K, dtype=int)\n",
    "\n",
    "def _standardize_cols(A):\n",
    "    A = np.asarray(A, float)\n",
    "    return (A - A.mean(axis=0)) / (A.std(axis=0) + 1e-12)\n",
    "\n",
    "# ---------------------------\n",
    "# Compute T = tanh(X W1 + b1) for selected posterior draws\n",
    "# ---------------------------\n",
    "def hidden_T_from_posterior(posterior, X, K=50, sample_indices=None, standardize_X=True, standardize_T=True, seed=0):\n",
    "    \"\"\"\n",
    "    posterior: CmdStanPy posterior object (the one inside tanh_fit[name]['posterior'])\n",
    "    X: (n, p) design matrix\n",
    "    Returns: (T_list, indices)\n",
    "      - T_list: list of arrays [ (n, H) per draw ]\n",
    "      - indices: the draw indices used\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    if standardize_X:\n",
    "        X_use = _standardize_cols(X)\n",
    "    else:\n",
    "        X_use = X\n",
    "\n",
    "    W1_all = posterior.stan_variable(\"W_1\")           # (S, p, H)\n",
    "    b1_all = posterior.stan_variable(\"hidden_bias\")   # (S, 1, H)\n",
    "    S, p, H = W1_all.shape\n",
    "    assert b1_all.shape == (S, 1, H)\n",
    "\n",
    "    if sample_indices is None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        # stratified picks across S (stable & reproducible)\n",
    "        sample_indices = _choose_sample_indices(S, K)\n",
    "\n",
    "    T_list = []\n",
    "    for s in sample_indices:\n",
    "        W1 = W1_all[s]            # (p, H)\n",
    "        b1 = b1_all[s].reshape(1, H)  # (1, H)\n",
    "        Z1 = X_use @ W1 + b1      # (n, H)\n",
    "        T = np.tanh(Z1)           # tanh activation\n",
    "        if standardize_T:\n",
    "            T = _standardize_cols(T)\n",
    "        T_list.append(T)\n",
    "\n",
    "    return T_list, np.asarray(sample_indices, int)\n",
    "\n",
    "# ---------------------------\n",
    "# Main wrapper: I(X;T) across draws\n",
    "# ---------------------------\n",
    "def estimate_ix_t_ksg(\n",
    "    tanh_fit, model_name, X,\n",
    "    K=50, sample_indices=None, k=5,\n",
    "    standardize_X=True, standardize_T=True, seed=0,\n",
    "    jitter=1e-8  # small jitter helps when mappings are near-deterministic\n",
    "):\n",
    "    posterior = tanh_fit[model_name][\"posterior\"]\n",
    "\n",
    "    # Build hidden reps for chosen draws\n",
    "    T_list, indices = hidden_T_from_posterior(\n",
    "        posterior, X,\n",
    "        K=K, sample_indices=sample_indices,\n",
    "        standardize_X=standardize_X, standardize_T=standardize_T, seed=seed\n",
    "    )\n",
    "\n",
    "    X_std = _standardize_cols(X) if standardize_X else np.asarray(X, float)\n",
    "\n",
    "    rows = []\n",
    "    for draw_idx, T in zip(indices, T_list):\n",
    "        mi_xt = ksmi_xy_multi(X_std, T, k=k, jitter=jitter, random_state=seed)\n",
    "        rows.append({\"model\": model_name, \"draw\": int(draw_idx), \"IXT\": float(mi_xt)})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def rmse_from_output_test(posterior, y_test, sample_indices=None):\n",
    "    \"\"\"\n",
    "    posterior: CmdStanPosterior\n",
    "    y_test: (n_test,) or (n_test, 1)\n",
    "    \n",
    "    Returns:\n",
    "        rmse: (num_draws,) array of RMSE values for each draw.\n",
    "        sample_indices: indices used (in case of subsetting)\n",
    "    \"\"\"\n",
    "    y_test = np.asarray(y_test).reshape(-1, 1)  # ensure column\n",
    "    y_pred = posterior.stan_variable(\"output_test\")  # (S, n_test, 1)\n",
    "    S = y_pred.shape[0]\n",
    "\n",
    "    # choose which draws to use\n",
    "    if sample_indices is None:\n",
    "        sample_indices = np.arange(S)\n",
    "    else:\n",
    "        sample_indices = np.asarray(sample_indices)\n",
    "\n",
    "    # slice predictions for chosen draws\n",
    "    y_pred_sel = y_pred[sample_indices]         # (K, n_test, 1)\n",
    "\n",
    "    # compute RMSE draw-wise\n",
    "    diff = y_pred_sel - y_test[None, :, :]      # broadcast\n",
    "    rmse = np.sqrt(np.mean(diff**2, axis=(1, 2)))\n",
    "\n",
    "    return rmse, sample_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_sigma(tanh_fit_sigma, sigma_value, K=100, k=5, seed=123):\n",
    "    \"\"\"\n",
    "    tanh_fit_sigma: dict like {\"Gaussian tanh\": {...}, \"Regularized Horseshoe tanh\": {...}}\n",
    "    sigma_value: float noise level used when generating data.\n",
    "    Returns a tidy dataframe with columns: model, IXT, RMSE, draw, sigma.\n",
    "    \"\"\"\n",
    "    # 1) Generate data\n",
    "    X_train, X_test, y_train, y_test = generate_correlated_data_sigma(\n",
    "        n=100, p=6, random_state=42, sigma=sigma_value\n",
    "    )\n",
    "    \n",
    "    dfs = []  # collect one df per model\n",
    "\n",
    "    for model_name, model_dict in tanh_fit_sigma.items():\n",
    "\n",
    "        # 2) I(X,T)\n",
    "        df_ixt = estimate_ix_t_ksg(\n",
    "            tanh_fit_sigma,\n",
    "            model_name=model_name,\n",
    "            X=X_train,\n",
    "            K=K,\n",
    "            k=k,\n",
    "            standardize_X=True,\n",
    "            standardize_T=True,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        # 3) RMSE\n",
    "        rmse, draw_all = rmse_from_output_test(\n",
    "            model_dict[\"posterior\"],\n",
    "            y_test\n",
    "        )\n",
    "\n",
    "        # 4) Match RMSE to the draws in df_ixt\n",
    "        rmse_matched = rmse[df_ixt[\"draw\"].to_numpy()]\n",
    "\n",
    "        # 5) Build tidy df for this model\n",
    "        df_model = pd.DataFrame({\n",
    "            \"model\": df_ixt[\"model\"],\n",
    "            \"IXT\":   df_ixt[\"IXT\"],\n",
    "            \"RMSE\":  rmse_matched,\n",
    "            \"draw\":  df_ixt[\"draw\"],\n",
    "            \"sigma\": sigma_value\n",
    "        })\n",
    "        dfs.append(df_model)\n",
    "\n",
    "    # 6) Return tidy df for all models at this sigma\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sigma_00 = build_df_for_sigma(tanh_fit_sigma_00, sigma_value=0.0)\n",
    "df_sigma_05 = build_df_for_sigma(tanh_fit_sigma_05, sigma_value=0.5)\n",
    "df_sigma_1 = build_df_for_sigma(tanh_fit_sigma_1, sigma_value=1.0)\n",
    "df_sigma_2 = build_df_for_sigma(tanh_fit_sigma_2, sigma_value=2.0)\n",
    "\n",
    "df_all = pd.concat([df_sigma_00, df_sigma_05, df_sigma_1, df_sigma_2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_multi_ellipse(df, n_std=2.0):\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "    # ---- NEW: Rename models here ----\n",
    "    name_map = {\n",
    "        \"Gaussian tanh\": \"Gauss\",\n",
    "        \"Regularized Horseshoe tanh\": \"RHS\",\n",
    "        \"Dirichlet Horseshoe tanh\": \"DHS\",\n",
    "        \"Dirichlet Student T tanh\": \"DST\"\n",
    "    }\n",
    "    df = df.copy()\n",
    "    df[\"model_short\"] = df[\"model\"].map(name_map).fillna(df[\"model\"])\n",
    "\n",
    "    models = df[\"model_short\"].unique()\n",
    "    sigmas = np.sort(df[\"sigma\"].unique())\n",
    "\n",
    "    # Colors per model\n",
    "    color_map = {m: c for m, c in zip(models, [\"red\",\"blue\",\"green\",\"purple\",\"orange\",\"black\"])}\n",
    "    # Markers per sigma\n",
    "    marker_map = {s: m for s, m in zip(sigmas, [\"o\",\"s\",\"D\",\"^\",\"v\",\"P\"])}\n",
    "\n",
    "    for (model_short, sigma), sub in df.groupby([\"model_short\",\"sigma\"]):\n",
    "        x = sub[\"IXT\"].to_numpy()\n",
    "        y = sub[\"RMSE\"].to_numpy()\n",
    "\n",
    "        xm, ym = np.mean(x), np.mean(y)\n",
    "        xs, ys = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "\n",
    "        color = color_map[model_short]\n",
    "        marker = marker_map[sigma]\n",
    "\n",
    "        ax.scatter([xm], [ym], c=color, s=80, marker=marker,\n",
    "                   label=f\"{model_short}, σ={sigma}\")\n",
    "\n",
    "        ell = Ellipse((xm, ym),\n",
    "                      width=2*n_std*xs,\n",
    "                      height=2*n_std*ys,\n",
    "                      edgecolor=color,\n",
    "                      facecolor='none',\n",
    "                      lw=2,\n",
    "                      alpha=0.9)\n",
    "        ax.add_patch(ell)\n",
    "\n",
    "    ax.set_xlabel(\"I(X;T)\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_title(f\"I(X,T) vs RMSE — {n_std}σ ellipses\")\n",
    "    ax.legend(frameon=False, fontsize=9)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_multi_ellipse(df_all, n_std=1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_ellipse_like_Sigurd(df, n_std=2.0):\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "    name_map = {\n",
    "        \"Gaussian tanh\": \"Gauss\",\n",
    "        \"Regularized Horseshoe tanh\": \"RHS\",\n",
    "        \"Dirichlet Horseshoe tanh\": \"DHS\",\n",
    "        \"Dirichlet Student T tanh\": \"DST\"\n",
    "    }\n",
    "    df = df.copy()\n",
    "    df[\"model_short\"] = df[\"model\"].map(name_map).fillna(df[\"model\"])\n",
    "\n",
    "    models = df[\"model_short\"].unique()\n",
    "    sigmas = np.sort(df[\"sigma\"].unique())\n",
    "\n",
    "    color_map = {m: c for m, c in zip(models, [\"red\",\"blue\",\"green\",\"purple\",\"orange\",\"black\"])}\n",
    "    marker_map = {s: m for s, m in zip(sigmas, [\"o\",\"s\",\"D\",\"^\",\"v\",\"P\"])}\n",
    "\n",
    "    for model_short in models:\n",
    "\n",
    "        centers_x = []\n",
    "        centers_y = []\n",
    "        sigma_list = []\n",
    "\n",
    "        for sigma in sigmas:\n",
    "            sub = df[(df[\"model_short\"] == model_short) & (df[\"sigma\"] == sigma)]\n",
    "            x = sub[\"IXT\"].to_numpy()\n",
    "            y = sub[\"RMSE\"].to_numpy()\n",
    "            xm, ym = np.mean(x), np.mean(y)\n",
    "            xs, ys = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "\n",
    "            color = color_map[model_short]\n",
    "            marker = marker_map[sigma]\n",
    "\n",
    "            # store center points to connect later\n",
    "            centers_x.append(xm)\n",
    "            centers_y.append(ym)\n",
    "            sigma_list.append(sigma)\n",
    "\n",
    "            # draw ellipse\n",
    "            ell = Ellipse((xm, ym), width=2*n_std*xs, height=2*n_std*ys,\n",
    "                          edgecolor=color, facecolor='none', lw=2)\n",
    "            ax.add_patch(ell)\n",
    "\n",
    "            # draw center marker\n",
    "            ax.scatter([xm], [ym], c=color, s=80, marker=marker)\n",
    "\n",
    "        # ✅ draw line through centers in order of σ\n",
    "        ax.plot(centers_x, centers_y, '-', color=color_map[model_short], lw=2,\n",
    "                label=model_short)\n",
    "\n",
    "    ax.set_xlabel(\"I(X;T)\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_title(f\"Information–Performance Tradeoff ({n_std}σ ellipses)\")\n",
    "    ax.legend(frameon=False)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_multi_ellipse_like_Sigurd(df_all, n_std=1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array([0.1, 0.1, 0.8])\n",
    "p2 = np.array([1/3, 1/3, 1/3])\n",
    "ent1 = np.sum(-(p1 * np.log(p1 + 1e-12)))\n",
    "ent2 = np.sum(-(p2 * np.log(p2 + 1e-12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = generate_correlated_data_sigma(\n",
    "        n=100, p=6, random_state=42, sigma=0.0\n",
    "    )\n",
    "def hidden_activations_from_fit(fit, X):\n",
    "    \"\"\"\n",
    "    fit : tanh_fit_sigma_XX['Model']['posterior']\n",
    "    X   : (N, P) numpy array\n",
    "    Returns T_all : (draws, N, H)\n",
    "    \"\"\"\n",
    "    W = fit.stan_variable(\"W_1\")          # (draws, P, H)\n",
    "    b = fit.stan_variable(\"hidden_bias\")  # (draws, 1, H)\n",
    "\n",
    "    # X has shape (N, P) → add new axis for broadcasting\n",
    "    # result: (draws, N, H)\n",
    "    T = np.tanh(X @ W + b)\n",
    "    return T\n",
    "\n",
    "# ---- Extract post-activations for Gaussian and DHS ----\n",
    "X = X_train  # ensure standardized exactly as during training!\n",
    "\n",
    "T_gauss = hidden_activations_from_fit(\n",
    "    tanh_fit_sigma_00[\"Gaussian tanh\"][\"posterior\"], X\n",
    ")\n",
    "\n",
    "T_dhs = hidden_activations_from_fit(\n",
    "    tanh_fit_sigma_00[\"Dirichlet Horseshoe tanh\"][\"posterior\"], X\n",
    ")\n",
    "\n",
    "print(\"T_gauss shape:\", T_gauss.shape)\n",
    "print(\"T_dhs shape:\",   T_dhs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick hidden unit index\n",
    "unit = 0  \n",
    "\n",
    "# Flatten across draws + samples\n",
    "u_gauss = T_gauss[:, :, unit].ravel()\n",
    "u_dhs   = T_dhs[:,   :, unit].ravel()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(u_gauss, bins=30, alpha=0.6, label=\"Gaussian\", density=True)\n",
    "plt.hist(u_dhs,   bins=30, alpha=0.6, label=\"DHS\",      density=True)\n",
    "\n",
    "plt.axvline(0, color='black', lw=1, alpha=0.4)\n",
    "plt.xlabel(\"activation value (tanh)\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.title(f\"Hidden Unit {unit} Activation Distribution\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
