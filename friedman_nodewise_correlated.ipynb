{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman_correlated\"\n",
    "results_dir_tanh_corr = \"results/regression/single_layer/tanh/friedman_correlated\"\n",
    "\n",
    "# model_names_tanh_corr = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "model_names_tanh_corr = [\"Dirichlet Horseshoe tanh\", \"Beta Horseshoe tanh\"]\n",
    "\n",
    "tanh_fits_corr = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")\n",
    "    full_config_path = f\"{base_config_name}\"\n",
    "    \n",
    "    tanh_fit_corr = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh_corr,\n",
    "        models=model_names_tanh_corr,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fits_corr[base_config_name] = tanh_fit_corr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman_correlated\"\n",
    "results_dir_tanh_corr = \"results/regression/single_layer/tanh/friedman_correlated\"\n",
    "\n",
    "# model_names_tanh_corr_nodewise = [\"Dirichlet Horseshoe tanh nodewise\", \"Dirichlet Student T tanh nodewise\", \"Beta Horseshoe tanh nodewise\", \"Beta Student T tanh nodewise\"]\n",
    "model_names_tanh_corr_nodewise = [\"Dirichlet Horseshoe tanh nodewise\", \"Beta Horseshoe tanh nodewise\"]\n",
    "\n",
    "tanh_fits_corr_nodewise = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")\n",
    "    full_config_path = f\"{base_config_name}\"\n",
    "    \n",
    "    tanh_fit_corr_nodewise = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh_corr,\n",
    "        models=model_names_tanh_corr_nodewise,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fits_corr_nodewise[base_config_name] = tanh_fit_corr_nodewise\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_data import generate_Friedman_data, generate_correlated_Friedman_data\n",
    "\n",
    "_FRIEDMAN_KEY = re.compile(r\"Friedman_N(\\d+)_p\\d+_sigma([\\d.]+)_seed(\\d+)\")\n",
    "\n",
    "def extract_friedman_metadata(key: str):\n",
    "    \"\"\"\n",
    "    Parse 'Friedman_N{N}_p10_sigma{sigma}_seed{seed}' -> (N:int, sigma:float, seed:int)\n",
    "    Returns (None, None, None) if it doesn't match.\n",
    "    \"\"\"\n",
    "    m = _FRIEDMAN_KEY.search(key)\n",
    "    if not m:\n",
    "        return None, None, None\n",
    "    N = int(m.group(1))\n",
    "    sigma = float(m.group(2))\n",
    "    seed = int(m.group(3))\n",
    "    return N, sigma, seed\n",
    "\n",
    "def forward_pass_tanh(X, W1, b1, WL, bL):\n",
    "    # X: (N,P), W1: (P,H), b1: (H,), WL: (H,O), bL: (O,)\n",
    "    H = np.tanh(X @ W1 + b1.reshape(1, -1))\n",
    "    Y = H @ WL + bL.reshape(1, -1)\n",
    "    return Y  # (N,O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def _find_run_key(fits_by_run, *, N, D, sigma, seed, correlated=False):\n",
    "    \"\"\"\n",
    "    Tries to find the right key inside e.g. tanh_fits for the requested (N, D, sigma, seed).\n",
    "    Works even if your sigma formatting differs a bit (e.g. 1, 1.0, 1.00).\n",
    "    \"\"\"\n",
    "    # Common naming you showed: Friedman_N100_p10_sigma1.00_seed3\n",
    "    # If you also have \"CorrelatedFriedman\" etc, we try both patterns.\n",
    "    sigma_strs = [\n",
    "        f\"{sigma}\",\n",
    "        f\"{sigma:.1f}\",\n",
    "        f\"{sigma:.2f}\",\n",
    "        f\"{sigma:.3f}\",\n",
    "    ]\n",
    "    candidates = []\n",
    "    for s in sigma_strs:\n",
    "        if correlated:\n",
    "            candidates.append(f\"CorrelatedFriedman_N{N}_p{D}_sigma{s}_seed{seed}\")\n",
    "        candidates.append(f\"Friedman_N{N}_p{D}_sigma{s}_seed{seed}\")\n",
    "\n",
    "    for k in candidates:\n",
    "        if k in fits_by_run:\n",
    "            return k\n",
    "\n",
    "    # If exact match not found, do a regex search (robust to extra prefixes/suffixes)\n",
    "    # Example matches: \"...Friedman_N100_p10_sigma1.00_seed3...\"\n",
    "    sig_pat = \"|\".join(re.escape(s) for s in sigma_strs)\n",
    "    base = r\"Friedman\" if not correlated else r\"(?:CorrelatedFriedman|Friedman)\"\n",
    "    pat = re.compile(\n",
    "        rf\"{base}_N{N}_p{D}_sigma(?:{sig_pat})_seed{seed}\"\n",
    "    )\n",
    "    matches = [k for k in fits_by_run.keys() if pat.search(k)]\n",
    "    if len(matches) == 1:\n",
    "        return matches[0]\n",
    "    if len(matches) > 1:\n",
    "        # Prefer the shortest/most exact-looking key\n",
    "        matches = sorted(matches, key=len)\n",
    "        return matches[0]\n",
    "\n",
    "    raise KeyError(\n",
    "        f\"Could not find a run in fits_by_run for N={N}, D={D}, sigma={sigma}, seed={seed}, correlated={correlated}.\\n\"\n",
    "        f\"Example expected key: 'Friedman_N{N}_p{D}_sigma{sigma:.2f}_seed{seed}'.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_posterior_on_multiple_testsets(\n",
    "    fits_by_run,            # <-- pass tanh_fits here\n",
    "    models,\n",
    "    layers,\n",
    "    forward_pass,\n",
    "    *,\n",
    "    correlated=False,\n",
    "    sigma=1.0,\n",
    "    D=10,\n",
    "    N_train=100,\n",
    "    Ns=(5000,),             # <-- run multiple N's if you want\n",
    "    n_testsets=1,\n",
    "    seeds=(1,),\n",
    "    test_seed_base=123,\n",
    "):\n",
    "    \"\"\"\n",
    "    - You pass tanh_fits (a dict keyed by run-name like 'Friedman_N100_p10_sigma1.00_seed3')\n",
    "    - For each (N, seed), we:\n",
    "        1) generate n_testsets independent test sets (seed = test_seed_base + test_id)\n",
    "        2) evaluate posterior mean prediction RMSE on each test set\n",
    "        3) return:\n",
    "           df_mean: mean RMSE over testsets, *separately* per seed (not merged)\n",
    "           df_raw : per-testset RMSE rows\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for N in Ns:\n",
    "        for seed in seeds:\n",
    "            run_key = _find_run_key(\n",
    "                fits_by_run, N=N_train, D=D, sigma=sigma, seed=seed, correlated=correlated\n",
    "            )\n",
    "            fits = fits_by_run[run_key]  # <-- this is what you previously indexed manually\n",
    "\n",
    "            for test_id in range(n_testsets):\n",
    "                # Make test sets genuinely different:\n",
    "                data_seed = 123\n",
    "\n",
    "                if correlated:\n",
    "                    _, X_test, y_train_raw, y_test_raw = generate_correlated_Friedman_data(\n",
    "                        N=N, D=D, sigma=sigma, test_size=0.2, seed=data_seed, standardize_y=False\n",
    "                    )\n",
    "                else:\n",
    "                    _, X_test, y_train_raw, y_test_raw = generate_Friedman_data(\n",
    "                        N=N, D=D, sigma=sigma, test_size=0.2, seed=data_seed, standardize_y=False\n",
    "                    )\n",
    "\n",
    "                y_train_mean = y_train_raw.mean()\n",
    "                y_train_std = y_train_raw.std()\n",
    "\n",
    "                y_test = (y_test_raw - y_train_mean) / y_train_std\n",
    "                y_test_np = y_test.reshape(-1)\n",
    "\n",
    "                for model in models:\n",
    "                    fit = fits[model][\"posterior\"]\n",
    "\n",
    "                    W1_samples = fit.stan_variable(\"W_1\")         # (S, P, H)\n",
    "                    if layers == 2:\n",
    "                        W2_samples = fit.stan_variable(\"W_2\")     # (S, H, H) or similar\n",
    "                    WL_samples = fit.stan_variable(\"W_L\")         # (S, H, O)\n",
    "                    b_samples = fit.stan_variable(\"hidden_bias\")  # (S, L, H)\n",
    "                    b1_samples = b_samples[:, 0, :]\n",
    "                    if layers == 2:\n",
    "                        b2_samples = b_samples[:, 1, :]\n",
    "                    bL_samples = fit.stan_variable(\"output_bias\") # (S, O)\n",
    "\n",
    "                    S = W1_samples.shape[0]\n",
    "                    y_hats = np.zeros((S, y_test_np.shape[0]))\n",
    "\n",
    "                    for i in range(S):\n",
    "                        W1 = W1_samples[i]\n",
    "                        WL = WL_samples[i]\n",
    "\n",
    "                        if layers == 1:\n",
    "                            y_hat = forward_pass(X_test, W1, b1_samples[i], WL, bL_samples[i])\n",
    "                        else:\n",
    "                            W2 = W2_samples[i]\n",
    "                            y_hat = forward_pass(X_test, W1, b1_samples[i], W2, b2_samples[i], WL, bL_samples[i])\n",
    "\n",
    "                        y_hats[i] = y_hat.squeeze()\n",
    "\n",
    "                    post_mean = y_hats.mean(axis=0)\n",
    "                    posterior_rmse_std = np.sqrt(mean_squared_error(y_test_np, post_mean))\n",
    "                    posterior_rmse_rawscale = posterior_rmse_std * y_train_std\n",
    "\n",
    "                    rows.append({\n",
    "                        \"run_key\": run_key,\n",
    "                        \"model\": model,\n",
    "                        \"N\": N,\n",
    "                        \"D\": D,\n",
    "                        \"sigma\": sigma,\n",
    "                        \"correlated\": correlated,\n",
    "                        \"seed\": seed,\n",
    "                        \"test_set\": test_id,\n",
    "                        \"posterior_rmse\": posterior_rmse_rawscale,\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Mean over testsets, BUT kept separate for each (model, seed, N, ...)\n",
    "    group_cols = [\"model\", \"seed\", \"N\", \"D\", \"sigma\", \"correlated\"]\n",
    "    df_mean = (\n",
    "        df.groupby(group_cols, as_index=False)[\"posterior_rmse\"]\n",
    "          .mean()\n",
    "          .rename(columns={\"posterior_rmse\": \"mean_rmse_over_testsets (scaled)\"})\n",
    "          .sort_values(group_cols)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df_mean, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N100_corr, df_raw_N100_corr = evaluate_posterior_on_multiple_testsets(\n",
    "    fits_by_run=tanh_fits_corr,\n",
    "    models=list(tanh_fits_corr['Friedman_N100_p10_sigma1.00_seed1'].keys()),\n",
    "    layers=1,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    correlated=True,\n",
    "    sigma=1.00,\n",
    "    D=10,\n",
    "    N_train = 100,\n",
    "    Ns=[5000],\n",
    "    n_testsets=1,\n",
    "    seeds=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N100_corr.sort_values(by=\"mean_rmse_over_testsets (scaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N200_corr, df_raw_N200_corr = evaluate_posterior_on_multiple_testsets(\n",
    "    fits_by_run=tanh_fits_corr,\n",
    "    models=list(tanh_fits_corr['Friedman_N200_p10_sigma1.00_seed6'].keys()),\n",
    "    layers=1,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    correlated=True,\n",
    "    sigma=1.00,\n",
    "    D=10,\n",
    "    N_train = 200,\n",
    "    Ns=[5000],\n",
    "    n_testsets=1,\n",
    "    seeds=[6],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N200_corr.sort_values(by=\"mean_rmse_over_testsets (scaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N500_corr, df_raw_N500_corr = evaluate_posterior_on_multiple_testsets(\n",
    "    fits_by_run=tanh_fits_corr,\n",
    "    models=list(tanh_fits_corr['Friedman_N500_p10_sigma1.00_seed11'].keys()),\n",
    "    layers=1,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    correlated=True,\n",
    "    sigma=1.00,\n",
    "    D=10,\n",
    "    N_train = 500,\n",
    "    Ns=[5000],\n",
    "    n_testsets=1,\n",
    "    seeds=[11],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_N500_corr.sort_values(by=\"mean_rmse_over_testsets (scaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# posterior mean prediction on standardized scale (most likely)\n",
    "output_mean_std_DHS = (\n",
    "    tanh_fits_corr['Friedman_N500_p10_sigma1.00_seed11']\n",
    "    ['Dirichlet Horseshoe tanh nodewise']['posterior']\n",
    "    .stan_variable(\"output_test\")\n",
    "    .mean(axis=0)\n",
    ").reshape(-1)\n",
    "\n",
    "output_mean_std_BHS = (\n",
    "    tanh_fits_corr['Friedman_N500_p10_sigma1.00_seed11']\n",
    "    ['Beta Horseshoe tanh nodewise']['posterior']\n",
    "    .stan_variable(\"output_test\")\n",
    "    .mean(axis=0)\n",
    ").reshape(-1)\n",
    "\n",
    "_, X_test, y_train_raw, y_test_raw = generate_correlated_Friedman_data(\n",
    "    N=500, D=10, sigma=1.0, test_size=0.2, seed=11, standardize_y=False\n",
    ")\n",
    "\n",
    "y_train_raw = y_train_raw.reshape(-1)\n",
    "y_test_raw  = y_test_raw.reshape(-1)\n",
    "\n",
    "y_mean = y_train_raw.mean()\n",
    "y_std  = y_train_raw.std()\n",
    "\n",
    "# IMPORTANT: fully invert standardization if output is on standardized scale\n",
    "y_pred_raw_DHS = y_mean + y_std * output_mean_std_DHS\n",
    "y_pred_raw_BHS = y_mean + y_std * output_mean_std_BHS\n",
    "\n",
    "# ---- sanity checks (very helpful) ----\n",
    "print(\"len(output_mean_std):\", len(output_mean_std_DHS))\n",
    "print(\"len(y_train_raw):\", len(y_train_raw), \"len(y_test_raw):\", len(y_test_raw))\n",
    "\n",
    "# If your \"output\" is for TRAINING points, it should match len(y_train_raw) (80 here).\n",
    "# If it matches 20, it’s probably test output. If it matches 100, it’s for all data.\n",
    "# Pick the corresponding y_true.\n",
    "if len(output_mean_std_DHS) == len(y_train_raw):\n",
    "    y_true_raw = y_train_raw\n",
    "    title_suffix = \"train\"\n",
    "elif len(output_mean_std_DHS) == len(y_test_raw):\n",
    "    y_true_raw = y_test_raw\n",
    "    title_suffix = \"test\"\n",
    "else:\n",
    "    # fallback: truncate to min length (not ideal, but avoids crashing)\n",
    "    # n = min(len(output_mean_std_DHS), len(y_train_raw))\n",
    "    # y_true_raw = y_train_raw[:n]\n",
    "    # y_pred_raw = y_pred_raw[:n]\n",
    "    print(f\"ERROR\")\n",
    "\n",
    "# ---- plot 1: pred vs true (scatter with y=x line) ----\n",
    "plt.figure()\n",
    "plt.scatter(y_true_raw, y_pred_raw_DHS, alpha=0.7, label=\"DHS\", color=\"Orange\")\n",
    "lo = min(y_true_raw.min(), y_pred_raw_DHS.min())\n",
    "hi = max(y_true_raw.max(), y_pred_raw_DHS.max())\n",
    "plt.scatter(y_true_raw, y_pred_raw_BHS, alpha=0.7, label=\"BHS\", color=\"Green\")\n",
    "plt.plot([lo, hi], [lo, hi])  # identity line\n",
    "plt.xlabel(\"True y (raw)\")\n",
    "plt.ylabel(\"Predicted y (raw)\")\n",
    "plt.title(f\"Pred vs True ({title_suffix})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- plot 2: index plot (both series over observations) ----\n",
    "plt.figure()\n",
    "idx = np.arange(len(y_true_raw))\n",
    "plt.scatter(idx, y_true_raw, label=\"true\", alpha=0.8)\n",
    "plt.scatter(idx, y_pred_raw_DHS, label=\"pred DHS\", alpha=0.8)\n",
    "plt.scatter(idx, y_pred_raw_BHS, label=\"pred BHS\", alpha=0.8)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y (raw)\")\n",
    "plt.title(f\"True and Pred over index ({title_suffix})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DIFFERENT PRUNING SCHEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_global_mask_from_posterior(\n",
    "    W_samples,\n",
    "    sparsity,\n",
    "    method=\"Eabs\",          # \"Eabs\" or \"Eabs_stability\"\n",
    "    stability_quantile=0.1, # used if method=\"Eabs_stability\"\n",
    "    prune_smallest=True\n",
    "):\n",
    "    \"\"\"\n",
    "    W_samples: array (S, ..., ...) posterior draws of a weight matrix.\n",
    "    sparsity: fraction to prune (q). Keeps (1-q).\n",
    "    Returns mask with same trailing shape as one draw, dtype float {0,1}.\n",
    "    \"\"\"\n",
    "    assert 0.0 <= sparsity < 1.0\n",
    "    S = W_samples.shape[0]\n",
    "    W_abs = np.abs(W_samples)  # (S, ...)\n",
    "\n",
    "    # Importance score a = E|w|\n",
    "    a = W_abs.mean(axis=0)     # (..., ...)\n",
    "\n",
    "    if method == \"Eabs\":\n",
    "        score = a\n",
    "    elif method == \"Eabs_stability\":\n",
    "        # Stability proxy pi = P(|w| > t), where t is a small global quantile of |w|\n",
    "        t = np.quantile(W_abs.reshape(S, -1), stability_quantile)\n",
    "        pi = (W_abs > t).mean(axis=0)\n",
    "        # Combine: emphasize both \"large on average\" and \"consistently non-tiny\"\n",
    "        score = a * pi\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'Eabs' or 'Eabs_stability'\")\n",
    "\n",
    "    # Decide how many to prune\n",
    "    num_params = score.size\n",
    "    k_prune = int(np.floor(sparsity * num_params))\n",
    "    if k_prune == 0:\n",
    "        return np.ones_like(score, dtype=float)\n",
    "\n",
    "    flat = score.reshape(-1)\n",
    "\n",
    "    if prune_smallest:\n",
    "        # prune lowest scores\n",
    "        thresh = np.partition(flat, k_prune - 1)[k_prune - 1]\n",
    "        mask = (score > thresh).astype(float)\n",
    "        # if ties create too many kept/pruned, fix deterministically\n",
    "        # (rare but possible with many equal scores)\n",
    "        if mask.sum() > num_params - k_prune:\n",
    "            # drop some tied-at-threshold entries\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_drop = int(mask.sum() - (num_params - k_prune))\n",
    "            if need_drop > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                mask_flat[idx_tied[:need_drop]] = 0.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "        elif mask.sum() < num_params - k_prune:\n",
    "            # add some tied entries if we kept too few\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_add = int((num_params - k_prune) - mask.sum())\n",
    "            if need_add > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                # add back from tied\n",
    "                add_candidates = idx_tied[mask_flat[idx_tied] == 0.0]\n",
    "                mask_flat[add_candidates[:need_add]] = 1.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "    else:\n",
    "        # prune largest (not typical)\n",
    "        thresh = np.partition(flat, num_params - k_prune)[num_params - k_prune]\n",
    "        mask = (score < thresh).astype(float)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def precompute_global_masks(\n",
    "    all_fits,\n",
    "    dataset_key,\n",
    "    model,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict: sparsity -> (mask_W1, mask_W2 or None)\n",
    "    \"\"\"\n",
    "    fit = all_fits[dataset_key][model][\"posterior\"]\n",
    "\n",
    "    W1_samples = fit.stan_variable(\"W_1\")  # (S, P, H)\n",
    "    W2_samples = fit.stan_variable(\"W_L\")  # (S, H, O) or (S, H) depending on O\n",
    "\n",
    "    masks = {}\n",
    "    for q in sparsity_levels:\n",
    "        mask_W1 = build_global_mask_from_posterior(W1_samples, q, method=method)\n",
    "        mask_W2 = None\n",
    "        if prune_W2:\n",
    "            mask_W2 = build_global_mask_from_posterior(W2_samples, q, method=method)\n",
    "        masks[q] = (mask_W1, mask_W2)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.generate_data import sample_gaussian_copula_uniform\n",
    "\n",
    "\n",
    "def generate_Friedman_data_v2(N=100, D=10, sigma=1.0, test_size=0.2, seed=42, standardize_y=True, return_scale=True):\n",
    "    np.random.seed(seed)\n",
    "    X = np.random.uniform(0, 1, size=(N, D))\n",
    "    x0, x1, x2, x3, x4 = X[:, 0], X[:, 1], X[:, 2], X[:, 3], X[:, 4]\n",
    "\n",
    "    y_clean = (\n",
    "        10 * np.sin(np.pi * x0 * x1) +\n",
    "        20 * (x2 - 0.5) ** 2 +\n",
    "        10 * x3 +\n",
    "        5.0 * x4\n",
    "    )\n",
    "    y = y_clean + np.random.normal(0, sigma, size=N)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    if not standardize_y:\n",
    "        return (X_train, X_test, y_train, y_test) if not return_scale else (X_train, X_test, y_train, y_test, 0.0, 1.0)\n",
    "\n",
    "    y_mean = y_train.mean()\n",
    "    y_std = y_train.std() if y_train.std() > 0 else 1.0\n",
    "\n",
    "    y_train_s = (y_train - y_mean) / y_std\n",
    "    y_test_s = (y_test - y_mean) / y_std\n",
    "\n",
    "    if return_scale:\n",
    "        return X_train, X_test, y_train_s, y_test_s, y_mean, y_std\n",
    "    return X_train, X_test, y_train_s, y_test_s\n",
    "\n",
    "def generate_correlated_Friedman_data_v2(N=100, D=10, sigma=1.0, test_size=0.2, seed=42, standardize_y=True, return_scale=True):\n",
    "    \"\"\"\n",
    "    Generate synthetic regression data for Bayesian neural network experiments.\n",
    "\n",
    "    Parameters:\n",
    "        N (int): Number of samples.\n",
    "        D (int): Number of features.\n",
    "        sigma (float): Noise level.\n",
    "        test_size (float): Proportion for test split.\n",
    "        seed (int): Random seed.\n",
    "        standardize_y (bool): Whether to standardize the response variable.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test, y_mean, y_std) if standardize_y,\n",
    "               else (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    d = 10\n",
    "    S_custom = np.eye(d)\n",
    "    # Block 1 (vars 0..4): high Spearman, 0.7\n",
    "    for i in range(0, 3):\n",
    "        for j in range(i+1, 3):\n",
    "            S_custom[i, j] = S_custom[j, i] = 0.8\n",
    "    # Block 2 (vars 5..9): moderate Spearman, 0.4\n",
    "    for i in range(5, 10):\n",
    "        for j in range(i+1, 10):\n",
    "            S_custom[i, j] = S_custom[j, i] = -0.5\n",
    "    # Cross-block weaker, 0.15\n",
    "    for i in range(0, 5):\n",
    "        for j in range(5, 10):\n",
    "            S_custom[i, j] = S_custom[j, i] = 0.15\n",
    "    # A couple of bespoke pairs:\n",
    "    S_custom[0, 9] = S_custom[9, 0] = 0.4\n",
    "    S_custom[2, 7] = S_custom[7, 2] = 0.9  # very strong (will be projected if infeasible)\n",
    "    S_custom[3, 4] = S_custom[4, 3] = -0.9  # very strong (will be projected if infeasible)\n",
    "    S_custom[1, 6] = S_custom[6, 1] = -0.9  # very strong (will be projected if infeasible)\n",
    "\n",
    "    U, _ = sample_gaussian_copula_uniform(n=10000, S=S_custom, random_state=123)\n",
    "    #X = np.random.uniform(0, 1, size=(N, D))\n",
    "    if N != U.shape[0]:\n",
    "        idx = np.random.choice(U.shape[0], size=N, replace=False)\n",
    "        X = U[idx, :]\n",
    "    else:\n",
    "        X = U\n",
    "\n",
    "    x0, x1, x2, x3, x4 = X[:, 0], X[:, 1], X[:, 2], X[:, 3], X[:, 4]\n",
    "\n",
    "    y_clean = (\n",
    "        10 * np.sin(np.pi * x0 * x1) +\n",
    "        20 * (x2 - 0.5) ** 2 +\n",
    "        10 * x3 +\n",
    "        5.0 * x4\n",
    "    )\n",
    "\n",
    "    y = y_clean + np.random.normal(0, sigma, size=N)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    if not standardize_y:\n",
    "        return (X_train, X_test, y_train, y_test) if not return_scale else (X_train, X_test, y_train, y_test, 0.0, 1.0)\n",
    "\n",
    "    y_mean = y_train.mean()\n",
    "    y_std = y_train.std() if y_train.std() > 0 else 1.0\n",
    "\n",
    "    y_train_s = (y_train - y_mean) / y_std\n",
    "    y_test_s = (y_test - y_mean) / y_std\n",
    "\n",
    "    if return_scale:\n",
    "        return X_train, X_test, y_train_s, y_test_s, y_mean, y_std\n",
    "    return X_train, X_test, y_train_s, y_test_s\n",
    "\n",
    "def make_large_eval_set(\n",
    "    generator_fn,\n",
    "    N_train,\n",
    "    D,\n",
    "    sigma,\n",
    "    seed,\n",
    "    n_eval=5000,\n",
    "    standardize_y=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns X_eval, y_eval (standardized if standardize_y=True), plus y_mean,y_std\n",
    "    defined from the training split.\n",
    "    \"\"\"\n",
    "    N_total = N_train + n_eval\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te, y_mean, y_std = generator_fn(\n",
    "        N=N_total, D=D, sigma=sigma, test_size=n_eval / N_total, seed=seed,\n",
    "        standardize_y=standardize_y, return_scale=True\n",
    "    )\n",
    "    # Now X_te has approx n_eval points (exact given test_size construction).\n",
    "    return X_te, np.asarray(y_te).squeeze(), y_mean, y_std\n",
    "\n",
    "\n",
    "def _logsumexp(a, axis=None):\n",
    "    amax = np.max(a, axis=axis, keepdims=True)\n",
    "    out = amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))\n",
    "    return np.squeeze(out, axis=axis)\n",
    "\n",
    "def gaussian_nll_pointwise(y, mu, sigma):\n",
    "    return 0.5*np.log(2*np.pi*(sigma**2)) + 0.5*((y-mu)**2)/(sigma**2)\n",
    "\n",
    "def compute_sparse_metrics_results_globalmask_large_eval(\n",
    "    seeds, models, all_fits, get_N_sigma, forward_pass,\n",
    "    folder,\n",
    "    sparsity=0.0,\n",
    "    masks_cache=None,\n",
    "    prune_W2=False,\n",
    "    compute_nll=True,\n",
    "    noise_var_name=\"sigma\",\n",
    "    n_eval=5000,\n",
    "    D=10,\n",
    "    standardize_y=True,\n",
    "    # pass the correct generator functions\n",
    "    gen_uncorr=None,\n",
    "    gen_corr=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate on a large generated test set instead of the stored tiny X_test/y_test.\n",
    "    Assumes model was trained on standardized y if standardize_y=True.\n",
    "    \"\"\"\n",
    "    assert gen_uncorr is not None and gen_corr is not None, \"Pass both generator functions.\"\n",
    "\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "\n",
    "    # choose generator based on folder name\n",
    "    def choose_gen(folder):\n",
    "        return gen_corr if \"friedman_correlated\" in folder else gen_uncorr\n",
    "\n",
    "    for seed in seeds:\n",
    "        N, sigma = get_N_sigma(seed)\n",
    "        dataset_key = f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}'\n",
    "\n",
    "        # Build large eval set consistent with training split standardization\n",
    "        gen_fn = choose_gen(folder)\n",
    "        X_test, y_test, y_mean, y_std = make_large_eval_set(\n",
    "            generator_fn=gen_fn,\n",
    "            N_train=N,\n",
    "            D=D,\n",
    "            sigma=sigma,\n",
    "            seed=seed,\n",
    "            n_eval=n_eval,\n",
    "            standardize_y=standardize_y\n",
    "        )\n",
    "\n",
    "        for model in models:\n",
    "            try:\n",
    "                fit = all_fits[dataset_key][model]['posterior']\n",
    "                W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "                W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "                b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "                b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "\n",
    "                noise_samples = None\n",
    "                if compute_nll:\n",
    "                    try:\n",
    "                        noise_samples = fit.stan_variable(noise_var_name).squeeze()\n",
    "                    except Exception:\n",
    "                        noise_samples = None\n",
    "            except KeyError:\n",
    "                print(f\"[SKIP] Model or posterior not found: {dataset_key} -> {model}\")\n",
    "                continue\n",
    "\n",
    "            S = W1_samples.shape[0]\n",
    "            y_hats = np.zeros((S, y_test.shape[0]))\n",
    "            #rmses = np.zeros(S)\n",
    "\n",
    "            mask_W1 = mask_W2 = None\n",
    "            if masks_cache is not None and sparsity > 0.0:\n",
    "                mask_W1, mask_W2 = masks_cache[(dataset_key, model)][sparsity]\n",
    "\n",
    "            for i in range(S):\n",
    "                W1 = W1_samples[i]\n",
    "                W2 = W2_samples[i]\n",
    "\n",
    "                if mask_W1 is not None:\n",
    "                    W1 = W1 * mask_W1\n",
    "                if prune_W2 and (mask_W2 is not None):\n",
    "                    W2 = W2 * mask_W2\n",
    "\n",
    "                y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i]).squeeze()\n",
    "                y_hats[i] = y_hat\n",
    "                #rmses[i] = np.sqrt(np.mean((y_hat - y_test)**2))\n",
    "\n",
    "            # posterior mean RMSE (standardized scale)\n",
    "            posterior_mean = y_hats.mean(axis=0)\n",
    "            posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test)**2))\n",
    "\n",
    "            out_pm = {\n",
    "                'seed': seed,\n",
    "                'N': N,\n",
    "                'sigma': sigma,\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'n_eval': y_test.shape[0],\n",
    "                'posterior_mean_rmse': posterior_mean_rmse,\n",
    "                'posterior_mean_rmse_orig': posterior_mean_rmse * y_std,  # back to original y scale\n",
    "            }\n",
    "\n",
    "            if compute_nll:\n",
    "                if noise_samples is None:\n",
    "                    sig_s = np.ones(S)\n",
    "                else:\n",
    "                    sig_s = np.asarray(noise_samples).reshape(-1)[:S]\n",
    "\n",
    "                # Expected NLL\n",
    "                nll_draws = np.array([\n",
    "                    gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i]).mean()\n",
    "                    for i in range(S)\n",
    "                ])\n",
    "                expected_nll = nll_draws.mean()\n",
    "\n",
    "                # Predictive (mixture) NLL\n",
    "                loglik = -np.stack([\n",
    "                    gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i])\n",
    "                    for i in range(S)\n",
    "                ], axis=0)  # (S, n_eval)\n",
    "                lppd = (_logsumexp(loglik, axis=0) - np.log(S)).mean()\n",
    "                predictive_nll = -lppd\n",
    "\n",
    "                out_pm[\"expected_nll\"] = expected_nll\n",
    "                out_pm[\"predictive_nll\"] = predictive_nll\n",
    "\n",
    "                # Optional: predictive_nll on original scale (only if you also rescale sigma)\n",
    "                # If your sigma posterior is on standardized scale, original sigma = sig_s * y_std.\n",
    "                out_pm[\"predictive_nll_orig\"] = predictive_nll + np.log(y_std)  # see note below\n",
    "\n",
    "            posterior_means.append(out_pm)\n",
    "\n",
    "            # for i in range(S):\n",
    "            #     row = {\n",
    "            #         'seed': seed,\n",
    "            #         'N': N,\n",
    "            #         'sigma': sigma,\n",
    "            #         'model': model,\n",
    "            #         'sparsity': sparsity,\n",
    "            #         'n_eval': y_test.shape[0],\n",
    "            #         'rmse': rmses[i],\n",
    "            #         'rmse_orig': rmses[i] * y_std\n",
    "            #     }\n",
    "            #     if compute_nll:\n",
    "            #        row[\"nll\"] = gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i]).mean()\n",
    "            #    results.append(row)\n",
    "\n",
    "#    return pd.DataFrame(results), pd.DataFrame(posterior_means)\n",
    "    return pd.DataFrame(posterior_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "def build_masks_cache_for_all(\n",
    "    all_fits,\n",
    "    dataset_keys,\n",
    "    models,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    masks_cache = {}\n",
    "    for dataset_key in dataset_keys:\n",
    "        for model in models:\n",
    "            try:\n",
    "                masks_cache[(dataset_key, model)] = precompute_global_masks(\n",
    "                    all_fits=all_fits,\n",
    "                    dataset_key=dataset_key,\n",
    "                    model=model,\n",
    "                    sparsity_levels=sparsity_levels,\n",
    "                    prune_W2=prune_W2,\n",
    "                    method=method\n",
    "                )\n",
    "            except KeyError:\n",
    "                print(f\"[SKIP MASKS] Missing fit for {dataset_key} -> {model}\")\n",
    "    return masks_cache\n",
    "\n",
    "seeds_correlated = [1, 6, 11]\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "def get_N_sigma_correlated(seed):\n",
    "    if seed == 16:\n",
    "        N=50\n",
    "    elif seed == 1:\n",
    "        N=100\n",
    "    elif seed == 6:\n",
    "        N=200\n",
    "    else:\n",
    "        N=500\n",
    "    sigma=1.00\n",
    "    return N, sigma\n",
    "\n",
    "# Build the list of dataset keys you actually evaluate (same keys as in your compute loop)\n",
    "# dataset_keys = []\n",
    "# for seed in seeds:\n",
    "#     N, sigma = get_N_sigma(seed)\n",
    "#     dataset_keys.append(f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}')\n",
    "\n",
    "dataset_keys_corr = []\n",
    "for seed in seeds_correlated:\n",
    "    N, sigma = get_N_sigma_correlated(seed)\n",
    "    dataset_keys_corr.append(f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}')\n",
    "\n",
    "\n",
    "# Precompute masks once\n",
    "masks_tanh_corr = build_masks_cache_for_all(tanh_fits_corr, dataset_keys_corr, model_names_tanh_corr, sparsity_levels, prune_W2=False)\n",
    "\n",
    "df_post_tanh_corr = {}\n",
    "for q in sparsity_levels:\n",
    "    df_post_tanh_corr[q] = compute_sparse_metrics_results_globalmask_large_eval(\n",
    "        seeds=seeds_correlated,\n",
    "        models=model_names_tanh_corr,\n",
    "        all_fits=tanh_fits_corr,\n",
    "        get_N_sigma=get_N_sigma_correlated,\n",
    "        forward_pass=forward_pass_tanh,\n",
    "        folder=\"friedman_correlated\",\n",
    "        sparsity=q,\n",
    "        masks_cache=masks_tanh_corr,\n",
    "        prune_W2=False,\n",
    "        compute_nll=True,\n",
    "        noise_var_name=\"sigma\",\n",
    "        n_eval=2000,\n",
    "        D=10,\n",
    "        standardize_y=True,\n",
    "        gen_uncorr=generate_Friedman_data_v2,\n",
    "        gen_corr=generate_correlated_Friedman_data_v2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "# Build the list of dataset keys you actually evaluate (same keys as in your compute loop)\n",
    "dataset_keys_corr_nodewise = []\n",
    "for seed in seeds_correlated:\n",
    "    N, sigma = get_N_sigma_correlated(seed)\n",
    "    dataset_keys_corr_nodewise.append(f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}')\n",
    "\n",
    "\n",
    "# Precompute masks once\n",
    "masks_tanh_corr_nodewise = build_masks_cache_for_all(tanh_fits_corr_nodewise, dataset_keys_corr_nodewise, model_names_tanh_corr_nodewise, sparsity_levels, prune_W2=False)\n",
    "\n",
    "df_post_tanh_corr_nodewise = {}\n",
    "for q in sparsity_levels:\n",
    "    df_post_tanh_corr_nodewise[q] = compute_sparse_metrics_results_globalmask_large_eval(\n",
    "        seeds=seeds_correlated,\n",
    "        models=model_names_tanh_corr_nodewise,\n",
    "        all_fits=tanh_fits_corr_nodewise,\n",
    "        get_N_sigma=get_N_sigma_correlated,\n",
    "        forward_pass=forward_pass_tanh,\n",
    "        folder=\"friedman_correlated\",\n",
    "        sparsity=q,\n",
    "        masks_cache=masks_tanh_corr_nodewise,\n",
    "        prune_W2=False,\n",
    "        compute_nll=True,\n",
    "        noise_var_name=\"sigma\",\n",
    "        n_eval=2000,\n",
    "        D=10,\n",
    "        standardize_y=True,\n",
    "        gen_uncorr=generate_Friedman_data_v2,\n",
    "        gen_corr=generate_correlated_Friedman_data_v2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh_full = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_post_tanh_corr.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_post_tanh_full_nodewise = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_post_tanh_corr_nodewise.items()],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_post_tanh_full, df_post_tanh_full_nodewise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh_full[df_post_tanh_full['sparsity']==0.0].sort_values(by=['model', 'N', \"predictive_nll\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh_full_nodewise[df_post_tanh_full_nodewise['sparsity']==0.0].sort_values(by=['model', 'N', \"posterior_mean_rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {\n",
    "    \"Gaussian tanh\": \"C0\",\n",
    "    \"Regularized Horseshoe tanh\": \"C1\",\n",
    "    \"Dirichlet Horseshoe tanh\": \"C2\",\n",
    "    \"Dirichlet Horseshoe tanh nodewise\": \"C2\",\n",
    "    \"Dirichlet Student T tanh\": \"C3\",\n",
    "    \"Dirichlet Student T tanh nodewise\": \"C3\",\n",
    "    \"Beta Horseshoe tanh\": \"C4\",\n",
    "    \"Beta Horseshoe tanh nodewise\": \"C4\",\n",
    "    \"Beta Student T tanh\": \"C5\",\n",
    "    \"Beta Student T tanh nodewise\": \"C5\",                 \n",
    "}\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]#, 0.9]\n",
    "\n",
    "rmse_col = \"posterior_mean_rmse_orig\"\n",
    "\n",
    "df = df_all.copy()\n",
    "\n",
    "df = df[df[\"sparsity\"].isin(sparsity_levels)]\n",
    "df[\"sparsity\"] = pd.Categorical(df[\"sparsity\"],\n",
    "                                categories=sparsity_levels,\n",
    "                                ordered=True)\n",
    "\n",
    "for N, dN in df.groupby(\"N\", sort=True):\n",
    "    if N==100:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "    for model, g in dN.groupby(\"model\", sort=False):\n",
    "        # if model in [\"Gaussian tanh\", \"Dirichlet Student T tanh\", \"Beta Student T tanh\", \"Dirichlet Student T tanh nodewise\", \"Beta Student T tanh nodewise\"]:\n",
    "        if model in [\"Gaussian tanh\", \"Dirichlet Horseshoe tanh\", \"Beta Horseshoe tanh\", \"Dirichlet Horseshoe tanh nodewise\", \"Beta Horseshoe tanh nodewise\"]:\n",
    "            continue\n",
    "        g = g.sort_values(\"sparsity\")\n",
    "        # if \"nodewise\" in model:\n",
    "        #     # continue\n",
    "        #     axes[0].plot(g[\"sparsity\"], g[rmse_col], marker=\"v\", label=model, linestyle='dashed', color = colors[model])\n",
    "        #     axes[1].plot(g[\"sparsity\"], g[\"predictive_nll_orig\"],    marker=\"v\", label=model, linestyle='dashed', color = colors[model])\n",
    "        # else:\n",
    "        #     # continue\n",
    "        #     axes[0].plot(g[\"sparsity\"], g[rmse_col], marker=\"o\", label=model, color = colors[model])\n",
    "        #     axes[1].plot(g[\"sparsity\"], g[\"predictive_nll_orig\"],    marker=\"o\", label=model, color = colors[model])\n",
    "        if \"nodewise\" in model:\n",
    "            lw, alpha, ls, mk = 1.3, 0.7, \"--\", \"v\"\n",
    "        else:\n",
    "            lw, alpha, ls, mk = 2.2, 1.0, \"-\", \"o\"\n",
    "        axes[0].plot(g[\"sparsity\"], g[rmse_col], linewidth=lw, alpha=alpha, linestyle=ls, marker=mk, label=model, color = colors[model])\n",
    "        axes[1].plot(g[\"sparsity\"], g[\"predictive_nll_orig\"], linewidth=lw, alpha=alpha, linestyle=ls, marker=mk, label=model, color = colors[model])\n",
    "\n",
    "    axes[0].set_title(f\"RMSE vs sparsity (N={N})\")\n",
    "    axes[1].set_title(f\"PNLL vs sparsity (N={N})\")\n",
    "\n",
    "    axes[0].set_ylabel(\"RMSE\")\n",
    "    axes[1].set_ylabel(\"PNLL\")\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"sparsity\")\n",
    "        ax.set_xticks(sparsity_levels)\n",
    "        ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    \n",
    "    axes[0].legend(loc=\"upper left\",\n",
    "                   #bbox_to_anchor=(1.02, 0.5),\n",
    "                   frameon=False)\n",
    "    axes[1].legend(loc=\"upper left\",\n",
    "                   #bbox_to_anchor=(1.02, 0.5),\n",
    "                   frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE PRUNING SCHEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "def _node_sizes_from_degree(deg, base=80, scale=30):\n",
    "    # deg: array of degrees (>=0)\n",
    "    return base + scale * deg\n",
    "\n",
    "def plot_pruned_network_panels(\n",
    "    masks_for_model,                 # dict: q -> (mask_W1, mask_W2)\n",
    "    q_levels=(0.0, 0.5, 0.8, 0.9),    # 4 values recommended\n",
    "    feature_names=None,              # list length P\n",
    "    hidden_names=None,               # list length H (optional)\n",
    "    hidden_bias_meanabs=None,         # array length H (optional): E|b1_j| (or similar)\n",
    "    title_prefix=\"\",\n",
    "):\n",
    "    q_levels = list(q_levels)\n",
    "\n",
    "    # infer dimensions\n",
    "    mask_W1_0, mask_W2_0 = masks_for_model[q_levels[0]]\n",
    "    P, H = mask_W1_0.shape\n",
    "    O = 1  # scalar output\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"x{i+1}\" for i in range(P)]\n",
    "    if hidden_names is None:\n",
    "        hidden_names = [f\"h{j+1}\" for j in range(H)]\n",
    "\n",
    "    # fixed node positions (same in every panel)\n",
    "    # y arranged top-to-bottom\n",
    "    y_inputs = np.linspace(1.0, 0.0, P)\n",
    "    y_hidden = np.linspace(1.0, 0.0, H)\n",
    "    x_in, x_hid, x_out = 0.0, 1.0, 2.0\n",
    "\n",
    "    pos_in = np.column_stack([np.full(P, x_in), y_inputs])\n",
    "    pos_h  = np.column_stack([np.full(H, x_hid), y_hidden])\n",
    "    pos_o  = np.array([[x_out, 0.5]])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for ax, q in zip(axes, q_levels):\n",
    "        mask_W1, mask_W2 = masks_for_model[q]\n",
    "        if mask_W2 is None:\n",
    "            # if you didn't prune W2, treat as all ones (H x 1)\n",
    "            mask_W2 = np.ones((H, 1), dtype=float)\n",
    "\n",
    "        # degrees\n",
    "        deg_in = mask_W1.sum(axis=1)             # (P,)\n",
    "        deg_h_in = mask_W1.sum(axis=0)           # (H,)\n",
    "        deg_h_out = mask_W2[:, 0].astype(float)  # (H,) since scalar output, 0/1 if pruned\n",
    "\n",
    "        # node sizes\n",
    "        s_in = _node_sizes_from_degree(deg_in, base=80, scale=25)\n",
    "        # Hidden: combine structure + (optional) bias magnitude\n",
    "        if hidden_bias_meanabs is not None:\n",
    "            # normalize bias for sizing (robust-ish)\n",
    "            b = np.asarray(hidden_bias_meanabs).reshape(-1)\n",
    "            b = b / (np.max(b) + 1e-12)\n",
    "            s_h = 120 + 180 * b + 20 * deg_h_in\n",
    "        else:\n",
    "            s_h = _node_sizes_from_degree(deg_h_in, base=120, scale=20)\n",
    "\n",
    "        s_o = 180\n",
    "\n",
    "        # -------- edges: build line segments --------\n",
    "        segs = []\n",
    "        # input -> hidden\n",
    "        ii, jj = np.where(mask_W1 > 0.5)\n",
    "        for i, j in zip(ii, jj):\n",
    "            segs.append([pos_in[i], pos_h[j]])\n",
    "\n",
    "        # hidden -> output (only if mask_W2[j]=1)\n",
    "        alive_h = np.where(deg_h_out > 0.5)[0]\n",
    "        for j in alive_h:\n",
    "            segs.append([pos_h[j], pos_o[0]])\n",
    "\n",
    "        if segs:\n",
    "            lc = LineCollection(segs, linewidths=1.0)\n",
    "            ax.add_collection(lc)\n",
    "\n",
    "        # -------- nodes --------\n",
    "        ax.scatter(pos_in[:, 0], pos_in[:, 1], s=s_in)\n",
    "        ax.scatter(pos_h[:, 0], pos_h[:, 1], s=s_h)\n",
    "        ax.scatter(pos_o[:, 0], pos_o[:, 1], s=s_o)\n",
    "\n",
    "        # labels (keep minimal; can comment out if too busy)\n",
    "        for i, name in enumerate(feature_names):\n",
    "            ax.text(pos_in[i, 0] - 0.03, pos_in[i, 1], name, ha=\"right\", va=\"center\", fontsize=9)\n",
    "        # hidden labels only for “alive-ish” units to reduce clutter:\n",
    "        # (either has incoming or outgoing)\n",
    "        show_h = np.where((deg_h_in > 0) | (deg_h_out > 0.5))[0]\n",
    "        for j in show_h:\n",
    "            ax.text(pos_h[j, 0] + 0.03, pos_h[j, 1], hidden_names[j], ha=\"left\", va=\"center\", fontsize=8)\n",
    "\n",
    "        ax.text(pos_o[0, 0] + 0.03, pos_o[0, 1], \"y\", ha=\"left\", va=\"center\", fontsize=10)\n",
    "\n",
    "        # cosmetics\n",
    "        ax.set_title(f\"{title_prefix}q={q}\")\n",
    "        ax.set_xlim(-0.4, 2.4)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # annotate with a quick summary\n",
    "        kept_W1 = int(mask_W1.sum())\n",
    "        total_W1 = mask_W1.size\n",
    "        kept_W2 = int(mask_W2.sum())\n",
    "        total_W2 = mask_W2.size\n",
    "        ax.text(\n",
    "            0.0, -0.12,\n",
    "            f\"W1 kept: {kept_W1}/{total_W1}  |  W2 kept: {kept_W2}/{total_W2}  |  alive hidden (out): {kept_W2}\",\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"left\", va=\"top\", fontsize=9\n",
    "        )\n",
    "\n",
    "    # if fewer than 4 q-levels, hide extra axes\n",
    "    for k in range(len(q_levels), 4):\n",
    "        axes[k].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "model = \"Regularized Horseshoe tanh\"\n",
    "masks_for_model = masks_tanh_corr[('Friedman_N200_p10_sigma1.00_seed6', model)] # dict q -> (mask_W1, mask_W2)\n",
    "\n",
    "fit = tanh_fits_corr['Friedman_N200_p10_sigma1.00_seed6'][model][\"posterior\"]\n",
    "b1_samples = fit.stan_variable(\"hidden_bias\")   # shape (S, H) or (S, 1, H) depending on your Stan\n",
    "hidden_bias_meanabs = np.mean(np.abs(b1_samples.reshape(b1_samples.shape[0], -1)), axis=0)\n",
    "\n",
    "\n",
    "plot_pruned_network_panels(\n",
    "    masks_for_model=masks_for_model,\n",
    "    q_levels=[0.5, 0.7, 0.9],\n",
    "    feature_names=None,\n",
    "    hidden_bias_meanabs=hidden_bias_meanabs,  # or None\n",
    "    title_prefix=f\"{model} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Dirichlet Horseshoe tanh\"\n",
    "masks_for_model = masks_tanh_corr[('Friedman_N200_p10_sigma1.00_seed6', model)]  # dict q -> (mask_W1, mask_W2)\n",
    "fit = tanh_fits_corr['Friedman_N200_p10_sigma1.00_seed6'][model][\"posterior\"]\n",
    "b1_samples = fit.stan_variable(\"hidden_bias\")   # shape (S, H) or (S, 1, H) depending on your Stan\n",
    "hidden_bias_meanabs = np.mean(np.abs(b1_samples.reshape(b1_samples.shape[0], -1)), axis=0)\n",
    "\n",
    "plot_pruned_network_panels(\n",
    "    masks_for_model=masks_for_model,\n",
    "    q_levels=[0.5, 0.7, 0.9],\n",
    "    feature_names=None,\n",
    "    hidden_bias_meanabs=hidden_bias_meanabs,  # or None\n",
    "    title_prefix=f\"{model} \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_input_survival_curves(\n",
    "    masks_for_model,                 # dict: q -> (mask_W1, mask_W2)\n",
    "    feature_names=None,              # list length P\n",
    "    sparsity_levels=None,            # list of q's (sorted)\n",
    "    title=None,\n",
    "):\n",
    "    if sparsity_levels is None:\n",
    "        sparsity_levels = sorted(masks_for_model.keys())\n",
    "    else:\n",
    "        sparsity_levels = list(sparsity_levels)\n",
    "\n",
    "    # infer P, H from first mask\n",
    "    m0 = masks_for_model[sparsity_levels[0]][0]\n",
    "    P, H = m0.shape\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"x{i+1}\" for i in range(P)]\n",
    "\n",
    "    # degrees d_i(q) = sum_j mask[i,j]\n",
    "    D = np.zeros((P, len(sparsity_levels)), dtype=float)\n",
    "    for t, q in enumerate(sparsity_levels):\n",
    "        mask_W1, _ = masks_for_model[q]\n",
    "        D[:, t] = mask_W1.sum(axis=1)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    for i in range(P):\n",
    "        ax.plot(sparsity_levels, D[i, :], marker=\"o\", linewidth=1, label=feature_names[i])\n",
    "\n",
    "    # optional mean curve\n",
    "    ax.plot(sparsity_levels, D.mean(axis=0), marker=\"o\", linewidth=2, label=\"mean (inputs)\")\n",
    "\n",
    "    ax.set_xlabel(\"sparsity q\")\n",
    "    ax.set_ylabel(\"surviving connections per input (degree)\")\n",
    "    ax.set_xticks(sparsity_levels)\n",
    "    ax.set_ylim(-0.5, H + 0.5)\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1.02, 0.5), frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = \"Gaussian tanh\"\n",
    "masks_for_model = masks_tanh_corr[('Friedman_N200_p10_sigma1.00_seed6', model)]  # dict q -> (mask_W1, mask_W2)\n",
    "\n",
    "# If you want bias sizes: compute once from the fit (example names; adjust to your Stan variables)\n",
    "fit = tanh_fits_corr['Friedman_N200_p10_sigma1.00_seed6'][model][\"posterior\"]\n",
    "b1_samples = fit.stan_variable(\"hidden_bias\")   # shape (S, H) or (S, 1, H) depending on your Stan\n",
    "hidden_bias_meanabs = np.mean(np.abs(b1_samples.reshape(b1_samples.shape[0], -1)), axis=0)\n",
    "\n",
    "feature_names = [...]  # length 10, meaningful names\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "plot_input_survival_curves(\n",
    "    masks_for_model=masks_for_model,\n",
    "    feature_names=None,\n",
    "    sparsity_levels=sparsity_levels,\n",
    "    title=f\"{model}: input survival curves\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_tanh_corr = build_masks_cache_for_all(tanh_fits_corr, dataset_keys_corr, model_names_tanh_corr, sparsity_levels, prune_W2=True)\n",
    "# masks_tanh_corr_nodewise = build_masks_cache_for_all(tanh_fits_corr_nodewise, dataset_keys_corr_nodewise, model_names_tanh_corr_nodewise, sparsity_levels, prune_W2=True)\n",
    "\n",
    "model = \"Dirichlet Horseshoe tanh\"\n",
    "masks_for_model = masks_tanh_corr[('Friedman_N200_p10_sigma1.00_seed6', model)]  # dict q -> (mask_W1, mask_W2)\n",
    "\n",
    "# If you want bias sizes: compute once from the fit (example names; adjust to your Stan variables)\n",
    "fit = tanh_fits_corr['Friedman_N200_p10_sigma1.00_seed6'][model][\"posterior\"]\n",
    "b1_samples = fit.stan_variable(\"hidden_bias\")   # shape (S, H) or (S, 1, H) depending on your Stan\n",
    "hidden_bias_meanabs = np.mean(np.abs(b1_samples.reshape(b1_samples.shape[0], -1)), axis=0)\n",
    "\n",
    "feature_names = [...]  # length 10, meaningful names\n",
    "\n",
    "\n",
    "plot_input_survival_curves(\n",
    "    masks_for_model=masks_for_model,\n",
    "    feature_names=None,\n",
    "    sparsity_levels=sparsity_levels,\n",
    "    title=f\"{model}: input survival curves\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to old pruning scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "def compute_sparse_rmse_results(seeds, models, all_fits, get_N_sigma, forward_pass, folder,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        # N, sigma = get_N_sigma(seed)\n",
    "        # dataset_key = f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}'\n",
    "        # path = f\"datasets/{folder}/{dataset_key}.npz\"\n",
    "\n",
    "        # try:\n",
    "        #     data = np.load(path)\n",
    "        #     X_test, y_test = data[\"X_test\"], data[\"y_test\"]\n",
    "        # except FileNotFoundError:\n",
    "        #     print(f\"[SKIP] File not found: {path}\")\n",
    "        #     continue\n",
    "        N, sigma = get_N_sigma(seed)\n",
    "        dataset_key = f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}'\n",
    "\n",
    "        # Build large eval set consistent with training split standardization\n",
    "        # gen_fn = choose_gen(folder)\n",
    "        X_test, y_test, y_mean, y_std = make_large_eval_set(\n",
    "            generator_fn=generate_correlated_Friedman_data_v2,\n",
    "            N_train=N,\n",
    "            D=10,\n",
    "            sigma=sigma,\n",
    "            seed=seed,\n",
    "            n_eval=2000,\n",
    "            standardize_y=True\n",
    "        )\n",
    "\n",
    "        for model in models:\n",
    "            try:\n",
    "                fit = all_fits[dataset_key][model]['posterior']\n",
    "                W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "                W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "                b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "                b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "            except KeyError:\n",
    "                print(f\"[SKIP] Model or posterior not found: {dataset_key} -> {model}\")\n",
    "                continue\n",
    "\n",
    "            S = W1_samples.shape[0]\n",
    "            #rmses = np.zeros(S)\n",
    "            #print(y_test.shape)\n",
    "            y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "            for i in range(S):\n",
    "                W1 = W1_samples[i]\n",
    "                W2 = W2_samples[i]\n",
    "\n",
    "                # Apply pruning mask if requested\n",
    "                if prune_fn is not None and sparsity > 0.0:\n",
    "                    masks = prune_fn([W1, W2], sparsity)\n",
    "                    W1 = W1 * masks[0]\n",
    "                    #W2 = W2 * masks[1]\n",
    "\n",
    "                y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "                y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "                #rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "                \n",
    "            posterior_mean = np.mean(y_hats, axis=0)\n",
    "            posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "            posterior_means.append({\n",
    "                'seed': seed,\n",
    "                'N': N,\n",
    "                'sigma': sigma,\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'posterior_mean_rmse': posterior_mean_rmse*y_std\n",
    "            })\n",
    "\n",
    "            # for i in range(S):\n",
    "            #     results.append({\n",
    "            #         'seed': seed,\n",
    "            #         'N': N,\n",
    "            #         'sigma': sigma,\n",
    "            #         'model': model,\n",
    "            #         'sparsity': sparsity,\n",
    "            #         'rmse': rmses[i]\n",
    "            #     })\n",
    "\n",
    "    #df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    # return df_rmse, df_posterior_rmse\n",
    "    return df_posterior_rmse\n",
    "\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "seeds = [1, 2, 11]\n",
    "seeds_correlated = [1, 6, 11]\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    if seed == 1:\n",
    "        N=100\n",
    "    elif seed == 2:\n",
    "        N=200\n",
    "    else:\n",
    "        N=500\n",
    "    sigma=1.00\n",
    "    return N, sigma\n",
    "\n",
    "def get_N_sigma_correlated(seed):\n",
    "    if seed == 1:\n",
    "        N=100\n",
    "    elif seed == 6:\n",
    "        N=200\n",
    "    else:\n",
    "        N=500\n",
    "    sigma=1.00\n",
    "    return N, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posterior_rmse_tanh_corr = {}\n",
    "df_posterior_rmse_tanh_corr_nodewise = {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    \n",
    "    df_posterior_rmse_tanh_corr[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds_correlated, model_names_tanh_corr, tanh_fits_corr, get_N_sigma_correlated, forward_pass_tanh, folder = \"friedman_correlated\",\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )\n",
    "    \n",
    "    df_posterior_rmse_tanh_corr_nodewise[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds_correlated, model_names_tanh_corr_nodewise, tanh_fits_corr_nodewise, get_N_sigma_correlated, forward_pass_tanh, folder = \"friedman_correlated\",\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_full_tanh_corr = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_posterior_rmse_tanh_corr.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_tanh_corr_nodewise = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_posterior_rmse_tanh_corr_nodewise.items()],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tanh_c = df_rmse_full_tanh_corr.copy()\n",
    "#df_tanh_c[\"model\"] = df_tanh_c[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "df_tanh_c_nw = df_rmse_full_tanh_corr_nodewise.copy()\n",
    "#df_tanh_c_nw[\"model\"] = df_tanh_c_nw[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {\n",
    "    # \"Gaussian\": \"C0\",\n",
    "    # \"Regularized Horseshoe\": \"C1\",\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Horseshoe nodewise\": \"C3\",\n",
    "    # \"Dirichlet Student T\": \"C3\",\n",
    "    \"Beta Horseshoe\": \"C4\",\n",
    "    \"Beta Horseshoe nodewise\": \"C5\",\n",
    "    # \"Beta Student T\": \"C5\",\n",
    "}\n",
    "abbr = {\n",
    "    # \"Gaussian\": \"Gauss\",\n",
    "    # \"Regularized Horseshoe\": \"RHS\",\n",
    "    \"Dirichlet Horseshoe\": \"DHS\",\n",
    "    \"Dirichlet Horseshoe nodewise\": \"DHS - node\",\n",
    "    # \"Dirichlet Student T\": \"DST\",\n",
    "    \"Beta Horseshoe\": \"BHS\",\n",
    "    \"Beta Horseshoe nodewise\": \"BHS - node\",\n",
    "    # \"Beta Student T\": \"BST\",\n",
    "}\n",
    "\n",
    "def make_merged_df(\n",
    "    df_tanh_o, df_tanh_c,\n",
    "    drop_tanh_suffix=True\n",
    "):\n",
    "    \"\"\"Return one long df with columns: N, sparsity, rmse, model, activation, setting.\"\"\"\n",
    "    dfs = []\n",
    "    # Tanh (optionally strip ' tanh' from model names if present)\n",
    "    for df, setting in [(df_tanh_o, \"Original\"), (df_tanh_c, \"Correlated\")]:\n",
    "        d = df.copy()\n",
    "        if drop_tanh_suffix and \" tanh\" in \"\".join(d[\"model\"].unique()):\n",
    "            d[\"model\"] = d[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "        d[\"activation\"] = \"tanh\"\n",
    "        d[\"setting\"] = setting\n",
    "        dfs.append(d)\n",
    "    \n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Keep only models that exist in BOTH activations so legend doesn't show ghosts\n",
    "    models_tanh = set(out.loc[out.activation==\"tanh\",\"model\"].unique())\n",
    "    common_models = sorted(list(models_tanh))\n",
    "    if common_models:\n",
    "        out = out[out[\"model\"].isin(common_models)]\n",
    "    return out\n",
    "\n",
    "df_all = make_merged_df(df_tanh_c, df_tanh_c_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_rmse_one_figure(\n",
    "    df_all,\n",
    "    Ns=(100, 200, 500), figsize=(12, 12), title=\"Original vs Correlated (tanh vs ReLU)\"\n",
    "):\n",
    "    \n",
    "\n",
    "    # Orderings\n",
    "    setting_order = [\"Original\", \"Correlated\"]\n",
    "\n",
    "    # Seaborn aesthetics (keeps your 'talk' sizing / whitegrid)\n",
    "    #sns.set_context(\"talk\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams.update({\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        #\"axes.titleweight\": \"semibold\",\n",
    "        \"legend.frameon\": True\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(2, len(Ns), figsize=figsize, sharex=True, sharey=False)\n",
    "    if len(Ns) == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    # We’ll plot using seaborn’s style mapping (style=activation, markers=True, dashes=True)\n",
    "    # so tanh vs ReLU are visually distinct and consistent across the grid.\n",
    "    for j, Nval in enumerate(Ns):\n",
    "        for i, setting in enumerate(setting_order):\n",
    "            ax = axes[i, j]\n",
    "            dfN = df_all[(df_all[\"N\"] == Nval) & (df_all[\"setting\"] == setting)].copy()\n",
    "            # Safety: if empty, skip\n",
    "            if dfN.empty:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            # Use abbreviated labels on the legend (we’ll build custom legends later anyway)\n",
    "            dfN[\"model_abbr\"] = dfN[\"model\"].map(lambda m: abbr.get(m, m))\n",
    "\n",
    "            sns.lineplot(\n",
    "                data=dfN,\n",
    "                x=\"sparsity\",\n",
    "                y=\"posterior_mean_rmse\",\n",
    "                hue=\"model_abbr\",      # color = prior (abbr)\n",
    "                style=\"activation\",    # style = activation\n",
    "                markers=True,\n",
    "                dashes=True,\n",
    "                palette={abbr[k]: v for k, v in palette.items() if k in dfN[\"model\"].unique()},\n",
    "                hue_order=[abbr[m] for m in sorted(dfN[\"model\"].unique(), key=lambda x: list(palette).index(x) if x in palette else 999)],\n",
    "                errorbar=None,\n",
    "                ax=ax,\n",
    "            )\n",
    "            #ax.set_title(f\"N={Nval}\")\n",
    "            ax.set_title(f\"N={Nval}\", fontweight=\"normal\", fontsize=15)\n",
    "\n",
    "            ax.set_xlabel(\"Sparsity\", fontsize=15)\n",
    "            ax.set_ylabel(\"RMSE\" if j == 0 else \"\", fontsize=15)\n",
    "            ax.tick_params(axis='both', labelsize=10)\n",
    "            ax.grid(True, which=\"major\", alpha=0.25)\n",
    "            if ax.legend_:  # remove local legends\n",
    "                ax.legend_.remove()\n",
    "\n",
    "    # ---------- Build two clean, global legends ----------\n",
    "    # 1) Prior legend (colors), using abbreviations in desired order present in data\n",
    "    models_present = []\n",
    "    # for m in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]:\n",
    "    for m in [\"Dirichlet Horseshoe\", \"Beta Horseshoe\", \"Dirichlet Horseshoe nodewise\", \"Beta Horseshoe nodewise\"]:\n",
    "        if (df_all[\"model\"] == m).any():\n",
    "            models_present.append(m)\n",
    "    prior_handles = [\n",
    "        Line2D([0],[0], color=palette[m], marker='o', linestyle='-', linewidth=2, markersize=12)\n",
    "        for m in models_present\n",
    "    ]\n",
    "    prior_labels = [abbr[m] for m in models_present]\n",
    "\n",
    "    # Place legends: priors on top center, activations below it\n",
    "    # (Adjust bbox_to_anchor if you prefer side-by-side or bottom placement.)\n",
    "    if prior_handles:\n",
    "        leg1 = fig.legend(\n",
    "            prior_handles, prior_labels,\n",
    "            title=\"Prior\",\n",
    "            loc=\"upper right\",\n",
    "            ncol=len(prior_handles),\n",
    "            frameon=True,\n",
    "            bbox_to_anchor=(0.7, 1.02),\n",
    "            fontsize = 15\n",
    "        )\n",
    "        fig.add_artist(leg1)\n",
    "    #fig.suptitle(title, y=1.08, fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0.4, 0.95, 0.95])\n",
    "    plt.savefig(\"figures_for_use_in_paper/friedman_sparsity_tanh_with_beta.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_one_figure(df_all,\n",
    "                     Ns=(100, 200, 500),\n",
    "                     title=\"Original vs Correlated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
