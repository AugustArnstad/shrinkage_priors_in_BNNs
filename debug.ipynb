{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_two_moons(N=200, sigma=0.5, test_size=0.2, D=2, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a two moons dataset with optional redundant features and split into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples (int): Number of samples to generate.\n",
    "    noise (float): Standard deviation of Gaussian noise added to the data.\n",
    "    test_size (float): Proportion of the dataset to include in the test split.\n",
    "    n_features (int): Total number of features (must be >=2). Extra features will be random noise.\n",
    "    random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    X_train (ndarray): Training features.\n",
    "    X_test (ndarray): Test features.\n",
    "    y_train (ndarray): Training labels.\n",
    "    y_test (ndarray): Test labels.\n",
    "    \"\"\"\n",
    "    if D < 2:\n",
    "        raise ValueError(\"n_features must be at least 2.\")\n",
    "\n",
    "    X, y = make_moons(n_samples=N, noise=sigma, random_state=seed)\n",
    "    \n",
    "    y = np.where(y == 0, 1, 2)\n",
    "    \n",
    "    if D > 2:\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "        extra_features = rng.normal(0, 1, size=(N, D - 2))\n",
    "        X = np.hstack((X, extra_features))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpmath import hyper\n",
    "\n",
    "p=10\n",
    "alpha=1.0\n",
    "b=(p-1)*alpha\n",
    "\n",
    "# Funksjonen p(kappa | sigma, tau)\n",
    "def p_kappa_dirichlet_horseshoe(kappa, a_j=1.0, p=10):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    prefactor = (1/np.pi) * (a_j / ((1-kappa) * np.sqrt(kappa) * np.sqrt(1-kappa))) * (1/p)\n",
    "    z = -kappa / (1-kappa)\n",
    "    # {}_3F_2([1, 1.1/2, 2.1/1], [1, 3/2], z)\n",
    "    hyper_val = hyper([p*alpha, (alpha+1)/2, alpha/2 + 1], [(p*alpha+1)/2, p*alpha/2 + 1], z)\n",
    "    return float(prefactor * hyper_val)\n",
    "\n",
    "# Funksjonen p(kappa | sigma, tau)\n",
    "def p_kappa_horseshoe(kappa, a_j=1.0):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    prefactor = (1/np.pi) * (a_j / ((a_j**2-1)*kappa + 1)) * 1/(np.sqrt(kappa) * np.sqrt(1-kappa))\n",
    "    return float(prefactor)\n",
    "\n",
    "# Lag kappa-grid\n",
    "kappa_vals = np.linspace(0.001, 0.999, 500)\n",
    "p_vals_dirichlet_horseshoe = [p_kappa_dirichlet_horseshoe(k) for k in kappa_vals]\n",
    "\n",
    "p_vals_horseshoe = [p_kappa_horseshoe(k) for k in kappa_vals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(kappa_vals, p_vals_dirichlet_horseshoe, label=\"Dirichlet Horseshoe\")\n",
    "plt.plot(kappa_vals, p_vals_horseshoe, label=\"Horseshoe\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.ylabel(r\"$p(\\kappa \\mid \\sigma, \\tau)$\")\n",
    "plt.title(r\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Parameters ---\n",
    "a = 1.0          # your a_j\n",
    "p = 10\n",
    "alpha = 0.1\n",
    "n_mc = 20000     # MC samples for xi\n",
    "n_draw = 20000   # how many kappa samples to draw for the histogram\n",
    "grid_n = 600     # kappa grid resolution\n",
    "eps = 1e-4       # keep away from 0 and 1 to avoid singularities\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "# --- Draw xi once and reuse across all kappa (variance reduction) ---\n",
    "xi = rng.beta(alpha, (p - 1) * alpha, size=n_mc)\n",
    "\n",
    "# --- Build kappa grid and compute unnormalized density on the grid ---\n",
    "kappa_grid = np.linspace(eps, 1 - eps, grid_n)\n",
    "\n",
    "# Prefactor depends only on kappa\n",
    "prefactor = (1 / np.pi) * (a / ((1 - kappa_grid) * np.sqrt(kappa_grid) * np.sqrt(1 - kappa_grid)))\n",
    "\n",
    "# c(kappa) = kappa * a^2 / (1 - kappa)\n",
    "c_grid = (kappa_grid * a * a) / (1 - kappa_grid)\n",
    "\n",
    "# Monte Carlo expectation for each kappa in a vectorized way\n",
    "# E[ xi / (1 + c xi^2) ] â‰ˆ mean over xi; do it for all c in c_grid\n",
    "# Shape tricks: (grid_n, 1) vs (1, n_mc) to broadcast\n",
    "num = xi[None, :]                # shape (1, n_mc)\n",
    "den = 1.0 + (c_grid[:, None] * xi[None, :]**2)  # shape (grid_n, n_mc)\n",
    "exp_term = (num / den).mean(axis=1)  # shape (grid_n,)\n",
    "\n",
    "dens_unnorm = prefactor * exp_term\n",
    "dens_unnorm = np.clip(dens_unnorm, 0, np.inf)   # numerical safety\n",
    "\n",
    "# --- Turn grid density into a discrete sampling distribution ---\n",
    "probs = dens_unnorm / dens_unnorm.sum()\n",
    "\n",
    "# --- Sample kappa from the discretized density and plot histogram ---\n",
    "kappa_samples = rng.choice(kappa_grid, size=n_draw, p=probs)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(kappa_samples, bins=100, density=True, alpha=0.5, edgecolor='none', label=\"samples (hist)\")\n",
    "# Overlay MC density (rescale by grid spacing so the curve is comparable to a density)\n",
    "dx = kappa_grid[1] - kappa_grid[0]\n",
    "plt.plot(kappa_grid, dens_unnorm / (dens_unnorm.sum() * dx), lw=2, label=\"MC density (overlay)\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.ylim(0, 10)\n",
    "plt.title(r\"MC estimate of $p(\\kappa\\,|\\,\\sigma,\\tau)$ with $c(\\kappa)=\\kappa a^2/(1-\\kappa)$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma, factorial\n",
    "from mpmath import hyper\n",
    "\n",
    "p=10\n",
    "alpha=1.0\n",
    "nu = 1\n",
    "b=(p-1)*alpha\n",
    "\n",
    "# Funksjonen p(kappa | sigma, tau)\n",
    "def p_kappa_dirichlet_stud_t(kappa, one_or_two=1, a_j=1.0, p=10):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    prefactor_1 = (1/a_j)*(1/(np.sqrt(np.pi*nu))) * (gamma((nu+1)/2))/(gamma(nu/2)) * kappa**(nu/2 - 1)*np.sqrt(1-kappa)\n",
    "    prefactor_2 = (1/a_j)*(1/(np.sqrt(np.pi*nu))) * (gamma((nu+1)/2))/(gamma(nu/2)) * kappa**(nu/2 - 1)*(1/(1-kappa)**(3/2)) * gamma(alpha + nu)/(gamma(alpha)) * gamma(p*alpha)/(gamma(p*alpha+nu))\n",
    "    \n",
    "    prefactor = (1/np.pi) * (a_j / ((1-kappa) * np.sqrt(kappa) * np.sqrt(1-kappa))) * (1/p)\n",
    "    \n",
    "    if one_or_two == 1:\n",
    "        z_1 = (-kappa*nu) / (1-kappa)\n",
    "        hyper_val = hyper([1, (alpha+1)/2, alpha/2 + 1], [(p*alpha+1)/2, p*alpha/2 + 1], z_1)\n",
    "        return float(prefactor_1 * hyper_val)\n",
    "    elif one_or_two == 2:\n",
    "        z_2 = (-kappa*nu) / (1-kappa)\n",
    "        hyper_val = hyper([(nu+1)/2, (alpha+nu)/2, (alpha+nu+1)/2], [(p*alpha+nu)/2, (p*alpha+nu+1)/2], z_2)\n",
    "        return float(prefactor_2 * hyper_val)\n",
    "    else:\n",
    "        return(print(\"You fucked up\"))\n",
    "\n",
    "\n",
    "# Lag kappa-grid\n",
    "kappa_vals = np.linspace(0.001, 0.999, 500)\n",
    "p_vals_dirichlet_stud_t = [p_kappa_dirichlet_stud_t(k, 2) for k in kappa_vals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kappa_vals, p_vals_dirichlet_stud_t, label=\"Dirichlet Student T\")\n",
    "#plt.plot(kappa_vals, p_vals_horseshoe, label=\"Horseshoe\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.ylabel(r\"$p(\\kappa \\mid \\sigma, \\tau)$\")\n",
    "plt.title(r\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma(alpha + nu)/(gamma(alpha))*gamma(p*alpha)/(gamma(p*alpha + nu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_two_moons(N=200, sigma=0.5, test_size=0.2, D=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"datasets/moons/many/Moon_N100_p2_sigma0.20_seed3.npz\"\n",
    "\n",
    "path_2 = \"datasets/moons/many/Moon_N200_p2_sigma0.20_seed7.npz\"\n",
    "\n",
    "path_3 = \"datasets/moons/many/Moon_N100_p2_sigma0.20_seed11.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = np.load(path_3)[\"X_train\"], np.load(path_3)[\"X_test\"], np.load(path_3)[\"y_train\"], np.load(path_3)[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#X_train, X_test, y_train, y_test = generate_two_moons(N=200, sigma=0.5, test_size=0.2, D=2, seed=42)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr', edgecolor='k')\n",
    "plt.title(\"Training Data from generate_two_moons (sigma=0.5)\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import laplace, t, gamma\n",
    "\n",
    "# Parameters\n",
    "b = 1.0\n",
    "n_samples = 10000000\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "# True Laplace PDF\n",
    "laplace_pdf = laplace.pdf(x, loc=0, scale=b)\n",
    "\n",
    "# Sample from the t2-Gamma mixture\n",
    "xi_samples = gamma.rvs(a=1, scale=2 * b**2, size=n_samples)\n",
    "t_samples = t.rvs(df=2, size=n_samples)\n",
    "w_samples = np.sqrt(xi_samples) * t_samples\n",
    "\n",
    "# Create histogram using same binning as PDF evaluation\n",
    "hist_vals, bin_edges = np.histogram(w_samples, bins=200, range=(-10, 10), density=True)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, laplace_pdf, label='Laplace(0, b)', linewidth=2)\n",
    "plt.plot(bin_centers, hist_vals, label='t2-Gamma mixture (hist)', linestyle='--', linewidth=2)\n",
    "plt.title(\"Laplace vs t2-Gamma Scale Mixture\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from scipy.stats import laplace\n",
    "\n",
    "# Parameters\n",
    "b = 1.0\n",
    "a = 4 * b**2\n",
    "\n",
    "# Define the function based on the symbolic integral expression\n",
    "def symbolic_integral(w, a):\n",
    "    sqrt_pi = np.sqrt(np.pi)\n",
    "    sqrt_b = np.abs(w)\n",
    "    sqrt_a = np.sqrt(a)\n",
    "    erf_term = erf(sqrt_b / sqrt_a)\n",
    "    exp_term = np.exp(sqrt_b**2 / a)\n",
    "    \n",
    "    numerator = (\n",
    "        (2 * sqrt_pi * a * erf_term - 2 * sqrt_pi * a) * sqrt_b**2\n",
    "        - sqrt_pi * a**2 * erf_term\n",
    "        + sqrt_pi * a**2\n",
    "    ) * exp_term + 2 * a**1.5 * sqrt_b\n",
    "    denominator = 2 * a**(2.5)\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "# w values (positive only for this check)\n",
    "w_vals = np.linspace(0.01, 5, 500)  # Avoid w = 0 to prevent division by zero\n",
    "\n",
    "# Evaluate symbolic expression and Laplace density\n",
    "integral_vals = np.array([symbolic_integral(w, a) for w in w_vals])\n",
    "laplace_vals = laplace.pdf(w_vals, loc=0, scale=b)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w_vals, integral_vals, label='Symbolic integral expression', linestyle='--')\n",
    "plt.plot(w_vals, laplace_vals, label='Laplace(0, b)', linewidth=2)\n",
    "plt.title('Comparison: Symbolic Integral vs Laplace Density')\n",
    "plt.xlabel('w')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gamma, t, laplace\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Parameters\n",
    "b = 1.36  # Laplace scale\n",
    "df = 4   # degrees of freedom for Student-t\n",
    "rate = 1 / (2 * b**2)  # Gamma(1, rate) for scale prior\n",
    "\n",
    "# Define the integrand: Student-t density times Gamma density\n",
    "def marginal_density(w):\n",
    "    def integrand(xi):\n",
    "        t_density = t.pdf(w, df=df, loc=0, scale=np.sqrt(xi))\n",
    "        gamma_density = gamma.pdf(xi, a=1, scale=1/rate)\n",
    "        return t_density * gamma_density\n",
    "    result, _ = quad(integrand, 0, np.inf)\n",
    "    return result\n",
    "\n",
    "# Evaluate on a grid of w values\n",
    "w_vals = np.linspace(-10, 10, 500)\n",
    "marginal_vals = np.array([marginal_density(w) for w in w_vals])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_1 = 1.36  # Laplace scale\n",
    "b_2 = 2.0  # Laplace scale\n",
    "b_3 = 3.0  # Laplace scale\n",
    "# Plot the results\n",
    "laplace_vals_1 = laplace.pdf(w_vals, loc=0, scale=b_1)\n",
    "laplace_vals_2 = laplace.pdf(w_vals, loc=0, scale=b_2)\n",
    "laplace_vals_3 = laplace.pdf(w_vals, loc=0, scale=b_3)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w_vals, marginal_vals, label='Student-t4 + Gamma mixture', linestyle='--')\n",
    "plt.plot(w_vals, laplace_vals_1, label='Laplace(0, 1.36)', linewidth=2)\n",
    "#plt.plot(w_vals, laplace_vals_2, label='Laplace(0, 2)', linewidth=2)\n",
    "#plt.plot(w_vals, laplace_vals_3, label='Laplace(0, 3)', linewidth=2)\n",
    "plt.title(\"Marginal density from Student-t4 + Gamma vs. Laplace\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gamma, t, laplace\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Parameters\n",
    "df = 50              # degrees of freedom for Student-t\n",
    "alpha = 1.0          # shape parameter for Gamma\n",
    "beta = 1.0           # rate parameter for Gamma (note: rate = 1/scale in SciPy)\n",
    "rate = beta          # used in gamma.pdf(x, a=alpha, scale=1/rate)\n",
    "\n",
    "# Compute matching Laplace scale b\n",
    "b_match = np.sqrt((df * alpha) / (2 * beta * (df - 2)))\n",
    "\n",
    "print(f\"Matched Laplace scale b = {b_match:.4f}\")\n",
    "\n",
    "# Define the marginal density by integrating out xi\n",
    "def marginal_density(w):\n",
    "    def integrand(xi):\n",
    "        t_density = t.pdf(w, df=df, loc=0, scale=np.sqrt(xi))\n",
    "        gamma_density = gamma.pdf(xi, a=alpha, scale=1/rate)\n",
    "        return t_density * gamma_density\n",
    "    result, _ = quad(integrand, 0, np.inf, epsabs=1e-10, epsrel=1e-10)\n",
    "    return result\n",
    "\n",
    "# Evaluate densities over a grid\n",
    "w_vals = np.linspace(-10, 10, 500)\n",
    "marginal_vals = np.array([marginal_density(w) for w in w_vals])\n",
    "laplace_vals = laplace.pdf(w_vals, loc=0, scale=b_match)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w_vals, marginal_vals, label='Student-t4 + Gamma mixture', linestyle='--')\n",
    "plt.plot(w_vals, laplace_vals, label=f'Laplace(0, {b_match:.2f})', linewidth=2, color='orange')\n",
    "plt.title(\"Marginal density from Student-t4 + Gamma vs. Laplace\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
