{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#from sklearn.metrics import mean_squared_errosr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_priors = \"results/priors/single_layer/tanh/friedman\"\n",
    "results_dir_posteriors = \"results/regression/single_layer/tanh/friedman\"\n",
    "\n",
    "prior_names = [\"Dirichlet Horseshoe\", \"Regularized Horseshoe\", \"Dirichlet Student T\", \"Gaussian\"]\n",
    "posterior_names = [\"Dirichlet Horseshoe tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Gaussian tanh\"]\n",
    "\n",
    "\n",
    "prior_N100_fits = get_model_fits(\n",
    "    config=\"Friedman_N100_p10_sigma1.00_seed1\",\n",
    "    results_dir=results_dir_priors,\n",
    "    models=prior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "prior_N200_fits = get_model_fits(\n",
    "    config=\"Friedman_N200_p10_sigma1.00_seed2\",\n",
    "    results_dir=results_dir_priors,\n",
    "    models=prior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "prior_N500_fits = get_model_fits(\n",
    "    config=\"Friedman_N500_p10_sigma1.00_seed11\",\n",
    "    results_dir=results_dir_priors,\n",
    "    models=prior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "    \n",
    "posterior_N100_fits = get_model_fits(\n",
    "    config=\"Friedman_N100_p10_sigma1.00_seed1\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "posterior_N200_fits = get_model_fits(\n",
    "    config=\"Friedman_N200_p10_sigma1.00_seed2\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "posterior_N500_fits = get_model_fits(\n",
    "    config=\"Friedman_N500_p10_sigma1.00_seed11\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/friedman/Friedman_N500_p10_sigma1.00_seed11.npz\"\n",
    "data = np.load(path)\n",
    "X = data['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Callable\n",
    "\n",
    "# ---------- Aktivasjon og deriverte ----------\n",
    "\n",
    "def get_activation(activation: str = \"tanh\") -> Tuple[Callable, Callable]:\n",
    "    if activation == \"tanh\":\n",
    "        phi = np.tanh\n",
    "        def dphi(a): return 1.0 - np.tanh(a)**2\n",
    "    elif activation == \"relu\":\n",
    "        def phi(a): return np.maximum(0.0, a)\n",
    "        def dphi(a): return (a > 0.0).astype(a.dtype)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation: {activation}\")\n",
    "    return phi, dphi\n",
    "\n",
    "# ---------- H(w0) og J_W(w0, v0) ----------\n",
    "\n",
    "def build_hidden_and_jacobian_W(\n",
    "    X: np.ndarray,               # (n, p)\n",
    "    W0: np.ndarray,              # (H, p)  -- vekter i referansepunktet w0\n",
    "    b0: np.ndarray,              # (H,)    -- bias i referansepunktet w0\n",
    "    v0: np.ndarray,              # (H,)    -- utgangsvekter i referansepunktet v0\n",
    "    activation: str = \"tanh\",\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returnerer:\n",
    "      H  : (n, H)         = H(w0)\n",
    "      JW : (n, H*p)       = d(H(w)v)/d vec(W) |_(w0, v0), kolonner ordnet som (h=0..H-1, j=0..p-1)\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    H, pW = W0.shape\n",
    "    assert pW == p\n",
    "    phi, dphi = get_activation(activation)\n",
    "\n",
    "    # Pre- og post-aktivert\n",
    "    A = X @ W0.T + b0[None, :]        # (n, H), a_{i,h}\n",
    "    Hmat = phi(A)                     # (n, H), h_{i,h}\n",
    "    dphiA = dphi(A)                   # (n, H)\n",
    "\n",
    "    # J_W: df/dW_{h,j} = v_h * dphi(a_{i,h}) * x_{i,j}\n",
    "    # For hver node h bygger vi et (n, p)-bidrag og flater ut langs j, og stabler så langs h.\n",
    "    JW_blocks = []\n",
    "    for h in range(H):\n",
    "        # (n,1) * (1,p) -> (n,p)\n",
    "        block_h = (v0[h] * dphiA[:, [h]]) * X \n",
    "        JW_blocks.append(block_h.reshape(n, p))\n",
    "    # Stack kolonnevis i rekkefølge (h, j) -> (n, H*p)\n",
    "    JW = np.hstack([B for B in JW_blocks])\n",
    "    return Hmat, JW\n",
    "\n",
    "# ---------- Sigma_y og P ----------\n",
    "\n",
    "def build_Sigma_y(\n",
    "    Hmat: np.ndarray,     # (n, H) = H(w0)\n",
    "    tau_v: float,         # prior std for v\n",
    "    sigma: float          # støy std i likelihood\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Σ_y = τ_v^2 H H^T + σ^2 I_n\n",
    "    \"\"\"\n",
    "    n = Hmat.shape[0]\n",
    "    return (tau_v**2) * (Hmat @ Hmat.T) + (sigma**2) * np.eye(n)\n",
    "\n",
    "def build_P_from_lambda_tau(\n",
    "    lambda_tilde: np.ndarray,  # (H, p) lokale skalaer for W\n",
    "    tau_w: float               # global skala for w\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    P = τ_w^{-2} Λ^{-1} der Λ = diag(λ^2) for konsistens med uttrykket 1/(1 + τ^2 λ^2 s).\n",
    "    Dvs. diag(P) = 1 / (τ_w^2 * λ^2).\n",
    "    Returnerer P som (H*p, H*p) diagonalmatrise.\n",
    "    \"\"\"\n",
    "    lam_vec = lambda_tilde.reshape(-1)          # (H*p,)\n",
    "    diagP = 1.0 / ( (tau_w**2) * (lam_vec) ) # (H*p,)\n",
    "    return np.diag(diagP)\n",
    "\n",
    "# ---------- S, shrinkage-matrise R = (P+S)^{-1} P ----------\n",
    "\n",
    "def build_S(JW: np.ndarray, Sigma_y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    S = J_W^T Σ_y^{-1} J_W  (Hp x Hp).\n",
    "    Løser via lineær solve for stabilitet: X = Σ_y^{-1} J_W = solve(Σ_y, J_W).\n",
    "    \"\"\"\n",
    "    X = np.linalg.solve(Sigma_y, JW)       # (n, Hp)\n",
    "    return JW.T @ X                        # (Hp, Hp)\n",
    "\n",
    "def shrinkage_matrix(P: np.ndarray, S: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    R = (P+S)^{-1} P. Bruk Cholesky når mulig.\n",
    "    Løser (P+S) * R = P for R.\n",
    "    \"\"\"\n",
    "    A = P + S\n",
    "    # Robust fallback hvis Cholesky feiler\n",
    "    try:\n",
    "        L = np.linalg.cholesky(A)\n",
    "        # L Y = P  -> Y\n",
    "        Y = np.linalg.solve(L, P)\n",
    "        # L^T R = Y -> R\n",
    "        R = np.linalg.solve(L.T, Y)\n",
    "    except np.linalg.LinAlgError:\n",
    "        R = np.linalg.solve(A, P)\n",
    "    return R\n",
    "\n",
    "def shrinkage_matrix_stable(P, S, jitter=0.0):\n",
    "    \"\"\"\n",
    "    Stabil beregning av R = (P+S)^{-1} P via\n",
    "    R = P^{1/2} (I + P^{-1/2} S P^{-1/2})^{-1} P^{1/2}.\n",
    "    Krever at P er diagonal (positiv).\n",
    "    \"\"\"\n",
    "    d = np.diag(P).astype(float)\n",
    "    # Guardrails: ingen nuller/NaN/negativ\n",
    "    eps = 1e-12\n",
    "    d = np.clip(d, eps, np.finfo(float).max)\n",
    "    Phalf    = np.diag(np.sqrt(d))\n",
    "    Pinvhalf = np.diag(1.0 / np.sqrt(d))\n",
    "\n",
    "    M = Pinvhalf @ S @ Pinvhalf\n",
    "    # Jitter for SPD-sikkerhet (skader ikke i praksis)\n",
    "    if jitter > 0:\n",
    "        M = M + jitter * np.eye(M.shape[0])\n",
    "\n",
    "    # (I + M) er SPD -> Cholesky\n",
    "    I = np.eye(M.shape[0])\n",
    "    L = np.linalg.cholesky(I + M)\n",
    "    # (I+M)^{-1} P^{1/2} = (L^T)^{-1} (L)^{-1} P^{1/2}\n",
    "    Z = np.linalg.solve(L, Phalf)\n",
    "    W = np.linalg.solve(L.T, Z)\n",
    "    # R = P^{1/2} * W\n",
    "    R = Phalf @ W\n",
    "    # Symmetrer (numerisk)\n",
    "    R = 0.5 * (R + R.T)\n",
    "    return R\n",
    "\n",
    "def shrinkage_eigs_and_df(P, S):\n",
    "    \"\"\"Returner r-eigenverdier og df_eff i P-whitnede koordinater.\"\"\"\n",
    "    d = np.diag(P).astype(float)\n",
    "    eps = 1e-12\n",
    "    Pinvhalf = np.diag(1.0 / np.sqrt(np.maximum(d, eps)))\n",
    "\n",
    "    M = Pinvhalf @ S @ Pinvhalf          # SPD\n",
    "    mu = np.linalg.eigvalsh(M)           # >= 0\n",
    "    r = 1.0 / (1.0 + mu)                 # i (0,1]\n",
    "    df_eff = np.sum(1.0 - r)             # = sum mu/(1+mu) >= 0\n",
    "    return r, df_eff\n",
    "\n",
    "\n",
    "# ---------- (Valgfritt) shrinket \"hat w\" gitt y*, hvis du vil sjekke tallene ----------\n",
    "\n",
    "# def extract_model_draws(fit_dict, model: str):\n",
    "#     \"\"\"\n",
    "#     Returns ALL draws stacked:\n",
    "#       W_all      : (D, H, p)\n",
    "#       b_all      : (D, H)\n",
    "#       v_all      : (D, H)\n",
    "#       c_all      : (D,)\n",
    "#       sigma_all  : (D,)\n",
    "#       tau_w_all  : (D,)\n",
    "#       tau_v_all  : (D,)   (ones if not in fit)\n",
    "#       lambda_all : (D, H, p)\n",
    "#     \"\"\"\n",
    "#     post = fit_dict[model]['posterior']\n",
    "\n",
    "#     # W_1: (D, p, H) -> (D, H, p)\n",
    "#     W_1 = np.asarray(post.stan_variable(\"W_1\"))\n",
    "#     W_all = np.transpose(W_1, (0, 2, 1))              # (D, H, p)\n",
    "#     D, H, p = W_all.shape\n",
    "\n",
    "#     # W_L: (D, H, 1) -> (D, H)\n",
    "#     W_L = np.asarray(post.stan_variable(\"W_L\"))\n",
    "#     v_all = W_L.reshape(D, -1)                        # (D, H)\n",
    "\n",
    "#     # hidden_bias: (D, 1, H) -> (D, H)\n",
    "#     b_1 = np.asarray(post.stan_variable(\"hidden_bias\"))\n",
    "#     b_all = b_1.reshape(D, -1)                        # (D, H)\n",
    "\n",
    "#     # output_bias: (D, 1) -> (D,)\n",
    "#     b_2 = np.asarray(post.stan_variable(\"output_bias\"))\n",
    "#     c_all = b_2.reshape(D)                            # (D,)\n",
    "\n",
    "#     # sigma: (D,)\n",
    "#     sigma_all = np.asarray(post.stan_variable(\"sigma\")).reshape(D)\n",
    "\n",
    "#     # tau_w: (D,)\n",
    "#     if model in (\"Gaussian\", \"Gaussian tanh\"):\n",
    "#         tau_w_all = np.ones(D)\n",
    "#         tau_v_all = np.ones(D)\n",
    "#         lambda_all = np.ones((D, H, p))\n",
    "#     else:\n",
    "#         tau_w_all = np.asarray(post.stan_variable(\"tau\")).reshape(D)\n",
    "#         # tau_v may not exist; default to ones\n",
    "#         try:\n",
    "#             tau_v_all = np.asarray(post.stan_variable(\"tau_v\")).reshape(D)\n",
    "#         except Exception:\n",
    "#             tau_v_all = np.ones(D)\n",
    "\n",
    "#         # lambda_tilde: (D, H, p)  or  (D, p, H)\n",
    "#         lam_name = \"lambda_tilde\" if model in (\"Regularized Horseshoe\",\"Regularized Horseshoe tanh\") else \"lambda_tilde_data\"\n",
    "#         lam = np.asarray(post.stan_variable(lam_name))\n",
    "#         if lam.shape[1:] == (H, p):\n",
    "#             lambda_all = lam\n",
    "#         else:\n",
    "#             # assume (D, p, H) -> (D, H, p)\n",
    "#             lambda_all = np.transpose(lam, (0, 2, 1))\n",
    "\n",
    "#     return W_all, b_all, v_all, c_all, sigma_all, tau_w_all, tau_v_all, lambda_all\n",
    "\n",
    "def extract_model_draws(fit_dict, model: str):\n",
    "    \"\"\"\n",
    "    Returnerer ALL draws, med 'lambda_all' definert som EFFEKTIV VARIANSFAKTOR per vekt:\n",
    "      Gaussian:                 lambda_all = 1\n",
    "      Regularized Horseshoe:    lambda_all = lambda_tilde\n",
    "      Dirichlet (DHS/DST):      lambda_all = lambda_tilde_data * phi_data\n",
    "\n",
    "    Shapes:\n",
    "      W_all      : (D, H, p)\n",
    "      b_all      : (D, H)\n",
    "      v_all      : (D, H)\n",
    "      c_all      : (D,)\n",
    "      sigma_all  : (D,)\n",
    "      tau_w_all  : (D,)\n",
    "      tau_v_all  : (D,)   (ones if not in fit)\n",
    "      lambda_all : (D, H, p)  <-- effektiv variansfaktor\n",
    "    \"\"\"\n",
    "    post = fit_dict[model]['posterior']\n",
    "\n",
    "    # W_1: (D, p, H) -> (D, H, p)\n",
    "    W_1 = np.asarray(post.stan_variable(\"W_1\"))\n",
    "    W_all = np.transpose(W_1, (0, 2, 1))\n",
    "    D, H, p = W_all.shape\n",
    "\n",
    "    # W_L: (D, H, out_nodes=1) -> (D, H)\n",
    "    W_L = np.asarray(post.stan_variable(\"W_L\"))\n",
    "    v_all = W_L.reshape(D, -1)\n",
    "\n",
    "    # hidden_bias: (D, 1, H) -> (D, H)\n",
    "    b_1 = np.asarray(post.stan_variable(\"hidden_bias\"))\n",
    "    b_all = b_1.reshape(D, -1)\n",
    "\n",
    "    # output_bias: (D, 1) -> (D,)\n",
    "    b_2 = np.asarray(post.stan_variable(\"output_bias\"))\n",
    "    c_all = b_2.reshape(D)\n",
    "\n",
    "    # sigma: (D,)\n",
    "    sigma_all = np.asarray(post.stan_variable(\"sigma\")).reshape(D)\n",
    "\n",
    "    # Modell-flagg\n",
    "    is_gauss      = (\"Gaussian\" in model)\n",
    "    is_rhs        = (\"Regularized Horseshoe\" in model)\n",
    "    is_dirichlet  = (\"Dirichlet\" in model) or (\"DST\" in model)\n",
    "\n",
    "    # tau_w / tau_v\n",
    "    if is_gauss:\n",
    "        tau_w_all = np.ones(D)\n",
    "        tau_v_all = np.ones(D)\n",
    "    else:\n",
    "        tau_w_all = np.asarray(post.stan_variable(\"tau\")).reshape(D)\n",
    "        try:\n",
    "            tau_v_all = np.asarray(post.stan_variable(\"tau_v\")).reshape(D)\n",
    "        except Exception:\n",
    "            tau_v_all = np.ones(D)\n",
    "\n",
    "    # Effektiv lokal variansfaktor lambda_all\n",
    "    if is_gauss:\n",
    "        lambda_all = np.ones((D, H, p))\n",
    "    else:\n",
    "        lam_name = \"lambda_tilde\" if is_rhs else \"lambda_tilde_data\"\n",
    "        lam = np.asarray(post.stan_variable(lam_name))\n",
    "        # Bring til (D, H, p)\n",
    "        if lam.shape[1:] == (H, p):\n",
    "            lam_var = lam\n",
    "        else:\n",
    "            lam_var = np.transpose(lam, (0, 2, 1))\n",
    "\n",
    "        if is_dirichlet:\n",
    "            # phi_data: sannsynlige shapes (D, H, p) eller (D, p, H)\n",
    "            phi = np.asarray(post.stan_variable(\"phi_data\"))\n",
    "            if phi.shape[1:] == (H, p):\n",
    "                phi_hp = phi\n",
    "            else:\n",
    "                phi_hp = np.transpose(phi, (0, 2, 1))\n",
    "            # Stan: stddev = tau * sqrt(lambda_tilde) * sqrt(phi)\n",
    "            #  => var = tau^2 * lambda_tilde * phi\n",
    "            lambda_all = lam_var * phi_hp\n",
    "        else:\n",
    "            # RHS: var = tau^2 * lambda_tilde\n",
    "            lambda_all = lam_var\n",
    "\n",
    "    return W_all, b_all, v_all, c_all, sigma_all, tau_w_all, tau_v_all, lambda_all\n",
    "\n",
    "# ------- Knyt alt sammen -------\n",
    "\n",
    "def compute_shrinkage_for_W_block(\n",
    "    X: np.ndarray,\n",
    "    W0: np.ndarray, b0: np.ndarray, v0: np.ndarray,\n",
    "    sigma: float, tau_w: float, tau_v: float,\n",
    "    lambda_tilde: np.ndarray,\n",
    "    activation: str = \"tanh\"\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returnerer (R, P, S, Sigma_y) der R = (P+S)^{-1} P for W-blokken.\n",
    "    \"\"\"\n",
    "    Hmat, JW = build_hidden_and_jacobian_W(X, W0, b0, v0, activation=activation)  # (n,H), (n,Hp)\n",
    "    Sigma_y = build_Sigma_y(Hmat, tau_v=tau_v, sigma=sigma)                       # (n,n)\n",
    "    P = build_P_from_lambda_tau(lambda_tilde, tau_w=tau_w)                        # (Hp,Hp)\n",
    "    S = build_S(JW, Sigma_y)                                                      # (Hp,Hp)\n",
    "    R = shrinkage_matrix_stable(P, S)                                                    # (Hp,Hp)\n",
    "    return R, P, S, Sigma_y\n",
    "\n",
    "\n",
    "def compute_shrinkage(\n",
    "    X,\n",
    "    W_all, b_all, v_all,          # (D,H,p), (D,H), (D,H)\n",
    "    sigma_all, tau_w_all, tau_v_all,  # (D,), (D,), (D,)\n",
    "    lambda_all,                   # (D,H,p)\n",
    "    activation=\"tanh\",\n",
    "    return_mats=True,             # set False if you only want summaries\n",
    "):\n",
    "    \"\"\"\n",
    "    Loop over draws and compute R=(P+S)^{-1}P per draw using your single-draw function.\n",
    "    Returns:\n",
    "      R_stack : (D, N, N) with N=H*p  (if return_mats=True, else None)\n",
    "      r_eigs  : (D, N)  sorted eigenvalues in [0,1]\n",
    "      df_eff  : (D,)    effective dof = tr(I-R) = N - tr(R)\n",
    "    \"\"\"\n",
    "    D, H, p = W_all.shape\n",
    "    N = H * p\n",
    "\n",
    "    R_stack = np.empty((D, N, N)) if return_mats else None\n",
    "    P_stack = np.empty((D, N, N)) if return_mats else None\n",
    "    r_eigs  = np.empty((D, N))\n",
    "    df_eff  = np.empty(D)\n",
    "\n",
    "    for d in range(D):\n",
    "        R, P, S, Sigma_y = compute_shrinkage_for_W_block(\n",
    "            X=X,\n",
    "            W0=W_all[d],\n",
    "            b0=b_all[d],\n",
    "            v0=v_all[d],\n",
    "            sigma=float(sigma_all[d]),\n",
    "            tau_w=float(tau_w_all[d]),\n",
    "            tau_v=float(tau_v_all[d]),\n",
    "            lambda_tilde=lambda_all[d],\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "        if return_mats:\n",
    "            R_stack[d] = R\n",
    "            P_stack[d] = P\n",
    "\n",
    "        r, df = shrinkage_eigs_and_df(P, S)\n",
    "        r_eigs[d] = np.sort(r)\n",
    "        df_eff[d] = df\n",
    "\n",
    "    return R_stack, P_stack, r_eigs, df_eff\n",
    "\n",
    "\n",
    "# ---------- Minimal kjøreeksempel ----------\n",
    "#draw = 0\n",
    "W, b1, v, b2, sigma, tau_w, tau_v, lambda_tilde = extract_model_draws(posterior_N100_fits, model='Gaussian tanh')\n",
    "\n",
    "R_gauss, P_gauss, eigs_gauss, df_eff_gauss = compute_shrinkage(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "\n",
    "#R_gauss, P_gauss, S_gauss, Sigma_y_gauss = compute_shrinkage_for_W_block(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "\n",
    "W, b1, v, b2, sigma, tau_w, tau_v, lambda_tilde = extract_model_draws(posterior_N100_fits, model='Regularized Horseshoe tanh')\n",
    "R_RHS, P_RHS, eigs_RHS, df_eff_RHS = compute_shrinkage(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "# R_RHS, P_RHS, S_RHS, Sigma_y_RHS = compute_shrinkage_for_W_block(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "\n",
    "W, b1, v, b2, sigma, tau_w, tau_v, lambda_tilde = extract_model_draws(posterior_N100_fits, model='Dirichlet Horseshoe tanh')\n",
    "R_DHS, P_DHS, eigs_DHS, df_eff_DHS = compute_shrinkage(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "# R_DHS, P_DHS, S_DHS, Sigma_y_DHS = compute_shrinkage_for_W_block(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "\n",
    "W, b1, v, b2, sigma, tau_w, tau_v, lambda_tilde = extract_model_draws(posterior_N100_fits, model='Dirichlet Student T tanh')\n",
    "R_DST, P_DST, eigs_DST, df_eff_DST = compute_shrinkage(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n",
    "# R_DST, P_DST, S_DST, Sigma_y_DST = compute_shrinkage_for_W_block(X, W, b1, v, sigma, tau_w, tau_v, lambda_tilde, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------- summaries -------\n",
    "def summarize_df(df):\n",
    "    df = np.asarray(df).reshape(-1)\n",
    "    return {\n",
    "        \"mean\": float(np.mean(df)),\n",
    "        \"sd\":   float(np.std(df, ddof=1)),\n",
    "        \"q10\":  float(np.quantile(df, 0.10)),\n",
    "        \"q50\":  float(np.quantile(df, 0.50)),\n",
    "        \"q90\":  float(np.quantile(df, 0.90)),\n",
    "    }\n",
    "\n",
    "def summarize_eigs(eigs, small=0.1, large=0.9):\n",
    "    # eigs: (D,N) of r \\in [0,1]\n",
    "    r = np.asarray(eigs).reshape(-1)\n",
    "    return {\n",
    "        \"median_r\": float(np.median(r)),\n",
    "        \"q10_r\":    float(np.quantile(r, 0.10)),\n",
    "        \"q90_r\":    float(np.quantile(r, 0.90)),\n",
    "        \"frac_small(<{:.2f})\".format(small): float(np.mean(r < small)),\n",
    "        \"frac_large(>{:.2f})\".format(large): float(np.mean(r > large)),\n",
    "    }\n",
    "\n",
    "# ------- ECDF plotting helpers -------\n",
    "\n",
    "def plot_hist_eigs(model_eigs_dict, bins=50, title=\"\"):\n",
    "    \"\"\"\n",
    "    model_eigs_dict: {\"Name\": eigs}, where eigs has shape (D, N) or (D*N,)\n",
    "                     and contains r-eigenvalues in [0, 1].\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(9,5))\n",
    "\n",
    "    # common bins across models for fair comparison\n",
    "    if isinstance(bins, int):\n",
    "        bins = np.linspace(0.0, 1.0, bins+1)\n",
    "\n",
    "    for name, eigs in model_eigs_dict.items():\n",
    "        x = np.asarray(eigs).ravel()\n",
    "        x = np.clip(x, 0.0, 1.0)               # safety\n",
    "        plt.hist(x, bins=bins, density=True, alpha=0.5, label=name)\n",
    "\n",
    "    plt.xlabel(\"r eigenvalues (0 = no shrink, 1 = hard shrink)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------- optional: rho transform (prior/data ratio) -------\n",
    "def plot_hist_log1p_rho(model_eigs_dict, bins=50, eps=1e-12, title=\"\"):\n",
    "    \"\"\"\n",
    "    model_eigs_dict: {\"Name\": eigs}, eigs shape (D,N) or (D*N,)\n",
    "                     r-eigenvalues in [0,1].\n",
    "    Plots overlaid histograms of log(1 + rho), rho = r/(1-r).\n",
    "    \"\"\"\n",
    "    # flatten & transform for pooled bin edges\n",
    "    pooled = []\n",
    "    for eigs in model_eigs_dict.values():\n",
    "        r = np.asarray(eigs).ravel()\n",
    "        r = np.clip(r, 0.0, 1.0 - eps)        # avoid division by zero at r=1\n",
    "        rho = r / (1.0 - r)\n",
    "        pooled.append(np.log1p(rho))\n",
    "    pooled = np.concatenate(pooled)\n",
    "\n",
    "    # common bins (use pooled range, cap extreme tail)\n",
    "    if isinstance(bins, int):\n",
    "        hi = float(np.quantile(pooled, 0.995))  # ignore extreme 0.5% tail\n",
    "        bins = np.linspace(0.0, hi, bins + 1)\n",
    "\n",
    "    plt.figure(figsize=(9,5))\n",
    "    for name, eigs in model_eigs_dict.items():\n",
    "        r = np.asarray(eigs).ravel()\n",
    "        r = np.clip(r, 0.0, 1.0 - eps)\n",
    "        rho = r / (1.0 - r)\n",
    "        x = np.log1p(rho)\n",
    "        plt.hist(x, bins=bins, density=True, alpha=0.5, label=name)\n",
    "\n",
    "    plt.xlabel(\"log(1 + rho),  rho = r/(1-r)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------- run summaries -------\n",
    "models_eigs = {\n",
    "    \"Gaussian\": eigs_gauss,\n",
    "    \"RHS\":      eigs_RHS,\n",
    "    \"DHS\":      eigs_DHS,\n",
    "    \"DST\":      eigs_DST,\n",
    "}\n",
    "models_df = {\n",
    "    \"Gaussian\": df_eff_gauss,\n",
    "    \"RHS\":      df_eff_RHS,\n",
    "    \"DHS\":      df_eff_DHS,\n",
    "    \"DST\":      df_eff_DST,\n",
    "}\n",
    "\n",
    "print(\"df_eff summaries:\")\n",
    "for name, df in models_df.items():\n",
    "    print(name, summarize_df(df))\n",
    "\n",
    "print(\"\\nEigenvalue summaries:\")\n",
    "for name, eigs in models_eigs.items():\n",
    "    print(name, summarize_eigs(eigs, small=0.1, large=0.9))\n",
    "\n",
    "# Plots to visualize differences in shrinkage\n",
    "plot_hist_eigs(models_eigs, title=\"Histogram of shrinkage eigenvalues r\")\n",
    "plot_hist_log1p_rho(models_eigs, title=\"Histogram of log(1+rho)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import SymLogNorm, Normalize\n",
    "import numpy as np\n",
    "\n",
    "def add_block_grid(ax, H, p, color=\"w\", lw=0.5):\n",
    "    Hp = H*p\n",
    "    for h in range(1, H):\n",
    "        k = h*p\n",
    "        ax.axhline(k-0.5, color=color, lw=lw)\n",
    "        ax.axvline(k-0.5, color=color, lw=lw)\n",
    "\n",
    "def visualize_models(\n",
    "    matrices, names, H=16, p=10, use_abs=False, cmap=\"magma\",\n",
    "    q_low=0.05, q_high=0.95\n",
    "):\n",
    "    \"\"\"\n",
    "    Viser heatmaps av matriser med felles, robust fargeskala:\n",
    "    vmin = q_low-kvantilen over ALLE matrisene\n",
    "    vmax = q_high-kvantilen over ALLE matrisene\n",
    "    Verdier utenfor [vmin, vmax] klippes til endene.\n",
    "    \"\"\"\n",
    "    # valgfritt absoluttbeløp\n",
    "    mats = [np.abs(M) if use_abs else M for M in matrices]\n",
    "\n",
    "    # Samle alle endelige verdier\n",
    "    all_vals = np.concatenate([M[np.isfinite(M)].ravel() for M in mats]) if mats else np.array([])\n",
    "\n",
    "    if all_vals.size == 0:\n",
    "        vmin, vmax = -1.0, 1.0\n",
    "    else:\n",
    "        vmin = float(np.quantile(all_vals, q_low))\n",
    "        vmax = float(np.quantile(all_vals, q_high))\n",
    "        if not np.isfinite(vmin) or not np.isfinite(vmax) or vmin == vmax:\n",
    "            # fallback hvis alt er likt/NaN\n",
    "            m = float(np.nanmean(all_vals)) if np.isfinite(np.nanmean(all_vals)) else 0.0\n",
    "            vmin, vmax = m - 1.0, m + 1.0\n",
    "\n",
    "    norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    # Figur\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10), dpi=150, constrained_layout=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    im = None\n",
    "    for ax, M, title in zip(axes, mats, names):\n",
    "        Mplot = np.clip(M, vmin, vmax)  # klipp utfor intervallet\n",
    "        im = ax.imshow(Mplot, aspect='equal', interpolation='nearest', cmap=cmap, norm=norm)\n",
    "        add_block_grid(ax, H, p)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Columns\")\n",
    "        ax.set_ylabel(\"Rows\")\n",
    "\n",
    "    # Felles colorbar\n",
    "    if im is not None:\n",
    "        fig.colorbar(im, ax=axes.tolist(), label=(\"|Value|\" if use_abs else \"Value\"))\n",
    "\n",
    "    # (valgfritt) print hva som faktisk ble brukt\n",
    "    print(f\"Felles kvantiler: vmin (q={q_low}) = {vmin:.6g}, vmax (q={q_high}) = {vmax:.6g}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example call:\n",
    "matrices = [\n",
    "    R_gauss.mean(axis=0), #[0],\n",
    "    R_RHS.mean(axis=0), #[0],\n",
    "    R_DHS.mean(axis=0), #[0],\n",
    "    R_DST.mean(axis=0), #[0]\n",
    "]\n",
    "\n",
    "# matrices = [\n",
    "#     R_gauss[1],\n",
    "#     R_RHS[1],\n",
    "#     R_DHS[1],\n",
    "#     R_DST[1]\n",
    "# ]\n",
    "names = [\n",
    "    \"Shrinkage (Gauss)\", #\"Data shrinkage (Gauss)\", \"Prior shrinkage (Gauss)\",\n",
    "    \"Shrinkage (RHS)\",   #\"Data shrinkage (RHS)\",   \"Prior shrinkage (RHS)\",\n",
    "    \"Shrinkage (DHS)\",   #\"Data shrinkage (DHS)\",   \"Prior shrinkage (DHS)\",\n",
    "    \"Shrinkage (DST)\",   #\"Data shrinkage (DST)\",   \"Prior shrinkage (DST)\",\n",
    "]\n",
    "\n",
    "visualize_models(matrices, names, H=16, p=10, use_abs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
