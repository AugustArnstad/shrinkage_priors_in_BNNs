Status 08.25:
Fors√∏kt √• skrive et avnsitt om de s√•kalte "Dirichlet scale mixture" priorene. H√•per det faller i smak.

Liste over ting som b√∏r gj√∏res:

Dirichlet priorene virker √• faktisk fungere bedre med slike interaksjoner, i allefall n√•r N ikke er veldig stor. Pr√∏v √• simuler fra funksjonen som Geir og Aleksandir kom frem til fra Abalone datasettet, det kan gi oss mer lignende data som kan brukes for √• styrke v√•r hypotese om at Dirichlet komponenten gj√∏r priorene mer robuste n√•r det er mye interaksjoner.

Vi har plot av konvergens vs feil i de ulike testpunktene i konvergens koden. Det kan v√¶re et aktuelt plot, kanskje enda bedre enn Rhat vs RMSE plottet.

Vi m√• finne CRPS for Friedman og Abalone dataen, selv om det er tidkrevende. Pr√∏v √• regn det ut n√•r du ikke sampler noe annet.

En siste ting kan v√¶re √• se p√• bias variansen, eventuelt √∏ke den for √• gj√∏re bias leddene mindre informative.

Vi kan vurdere √• ta med SPSL og Normal-Gamma priorer, men jeg ville pr√∏vd med Dirichlet-Laplace prioren f√∏r vi bruker de andre. Det krever i s√• fall et nytt Stan script.


Status 29.08.2025:
Jeg har n√• skrevet inn Proposition 1 og 2 og teoremer 1 og 2, samt beviser for de alle. Det som mangler er forventning og varians for b√•de proposition 2 og teorem 2. Se chat med ChatGPT, hvor den nyeste meldingen med A gjelder proposition 1 og B gjelder teorem 2. Jeg tror hvis vi f√•r inn forventning og varians her s√• har vi kommet langt!
Jeg kunne godt tenkt meg √• f√•tt noen til √• se over bevisene mine. Spesielt der hvor jeg;
-Ekspanderer til en sum
-Bytter sum og integral
-Bruker analytisk kontinuering
Dersom disse sitter tror jeg jaggu det blir artikkel.


Det som da alts√• m√• gj√∏res fremover, er √• lage en ryddig og fin Overleaf. F√∏rst m√• forventning og varians for Proposition 1 og Teorem 2 inn. Etter det handler mye om √• tolke resultatene og √• skrive en god artikkel som forteller en historie og selger poengene godt!

En figur som ville gjort seg bra, er den som n√• er av fordelingen til kappa(ligger i kappa.ipynb). Jeg tror vi her kunne testet for forskjellige frihetsgrader og verdier for a (alts√• konstanten foran den tilfeldige skalaen). Kanskje vi ogs√• burde simulere litt, det er litt vanskelig √• vite hvordan q-leddet oppf√∏rer seg. Det g√•r jo litt h√•nd i h√•nd med tolkningen av ting, s√• det sampsillet f√•r vi vel til.

05.09.2025:

Et plot som kunne v√¶rt kult √• ha med er kappa for prior og posterior. Jeg bruker Friedman med N=200 for √• gj√∏re dette. Jeg kan bruke modellene for regresjon direkte, men m√• kj√∏re prior modellene p√• nytt. I tillegg m√• jeg regne ut q to ganger, en gang for prior modellen og en gang for posterior modellen.

Her er det som n√• m√• gj√∏res:
Klassifiseringen fro Dirichlet Student T m√• kj√∏res om igjen for b√•de Relu og Tanh, for b√•de Moons og Breastcancer. Regresjonen for Dirichlet Student T m√• kj√∏res om igjen for b√•de Relu og Tanh, for b√•de Abalone og Friedman. N√• skaleres ingen med p, alle regulariserer og alle bruker tau. Vi legger det rett inn i resultatene, og oppdaterer Overleaf.

Du burde ogs√• kj√∏re konvergens en gang til. Gj√∏r det for DST, og for alle modeller med N=500, men kj√∏r kun for ett seed, trenger ikke flere. Du b√∏r kopiere over ett av datasettene med N=500, ogs√• kj√∏re, ogs√• kan du bare beholde datasettet i den lille mappa til Friedman. Gj√∏r ikke noe det.

Deretter vil jeg ha fine plot for prior/posterior. Det er egentlig p√• plass, men du m√• "rydde opp" i plottene.

Deretter kan vi se p√• de siste utregningene som nevnt tidligere.

08.09.2025:
Et sp√∏rsm√•l som jeg stiller er om skaleringen med p faktisk har v√¶rt bra? Virker som om jeg f√•r d√•rligere resultater n√•. Jeg tester med moons datasettet en gang til, denne gangen med skalering p√• DST, for √• sjekke om det blir bedre. Det virker ikke som om det er noe d√•rligere p√• Breastcancer dataen. Er moons for simpel? Og dermed blir DST for komplisert?

SVAR: Med skaleringen, s√• f√•r vi jevnt over bedre resultater for Relu DST p√• moons datasettet, men ikke s√¶rlig forskjell p√• breastcancer. Dette var da litt rart, men kanskje det er fordi datasettet er relativt lite og dermed blir modellen veldig sensitiv? Resultatene som n√• ligger inne for relu er med skalering. 

python3 utils/run_all_classification_models.py --model dirichlet_student_t --output_dir results/classification/single_layer/relu/moons ‚úÖ

python3 utils/run_all_classification_models.py --model dirichlet_student_t_tanh --output_dir results/classification/single_layer/tanh/moons ü§∑üèº‚Äç‚ôÇÔ∏è

python3 utils/run_breastcancer.py --model dirichlet_student_t --output_dir results/classification/single_layer/relu/breastcancer ‚úÖ

python3 utils/run_breastcancer.py --model dirichlet_student_t_tanh --output_dir results/classification/single_layer/tanh/breastcancer ‚úÖ

python3 utils/run_all_regression_models.py --model dirichlet_student_t --output_dir results/regression/single_layer/relu/friedman ‚úÖ

python3 utils/run_all_regression_models.py --model dirichlet_student_t_tanh --output_dir results/regression/single_layer/tanh/friedman ‚úÖ

python3 utils/run_abalone.py --model dirichlet_student_t --output_dir results/regression/single_layer/relu/abalone ‚úÖ

python3 utils/run_abalone.py --model dirichlet_student_t_tanh --output_dir results/regression/single_layer/tanh/abalone ‚úÖ

python3 utils/run_all_regression_models.py --model dirichlet_student_t --output_dir results/regression/single_layer/relu/friedman/convergence --sample 2000 --warmup 5000 --overwrite ‚úÖ

python3 utils/run_all_regression_models.py --model dirichlet_student_t_tanh --output_dir results/regression/single_layer/tanh/friedman/convergence --sample 2000 --warmup 5000 --overwrite ‚úÖ
