{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/abalone\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/abalone\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/abalone\"\n",
    "\n",
    "# model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "# model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "model_names_relu = [\"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "model_names_tanh = [\"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "\n",
    "\n",
    "full_config_path = \"abalone_N3341_p8\"\n",
    "relu_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST NEW PRUNING SCHEME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_global_mask_from_posterior(\n",
    "    W_samples,\n",
    "    sparsity,\n",
    "    method=\"Eabs\",          # \"Eabs\" or \"Eabs_stability\"\n",
    "    stability_quantile=0.1, # used if method=\"Eabs_stability\"\n",
    "    prune_smallest=True\n",
    "):\n",
    "    \"\"\"\n",
    "    W_samples: array (S, ..., ...) posterior draws of a weight matrix.\n",
    "    sparsity: fraction to prune (q). Keeps (1-q).\n",
    "    Returns mask with same trailing shape as one draw, dtype float {0,1}.\n",
    "    \"\"\"\n",
    "    assert 0.0 <= sparsity < 1.0\n",
    "    S = W_samples.shape[0]\n",
    "    W_abs = np.abs(W_samples)  # (S, ...)\n",
    "\n",
    "    # Importance score a = E|w|\n",
    "    a = W_abs.mean(axis=0)     # (..., ...)\n",
    "\n",
    "    if method == \"Eabs\":\n",
    "        score = a\n",
    "    elif method == \"Eabs_stability\":\n",
    "        # Stability proxy pi = P(|w| > t), where t is a small global quantile of |w|\n",
    "        t = np.quantile(W_abs.reshape(S, -1), stability_quantile)\n",
    "        pi = (W_abs > t).mean(axis=0)\n",
    "        # Combine: emphasize both \"large on average\" and \"consistently non-tiny\"\n",
    "        score = a * pi\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'Eabs' or 'Eabs_stability'\")\n",
    "\n",
    "    # Decide how many to prune\n",
    "    num_params = score.size\n",
    "    k_prune = int(np.floor(sparsity * num_params))\n",
    "    if k_prune == 0:\n",
    "        return np.ones_like(score, dtype=float)\n",
    "\n",
    "    flat = score.reshape(-1)\n",
    "\n",
    "    if prune_smallest:\n",
    "        # prune lowest scores\n",
    "        thresh = np.partition(flat, k_prune - 1)[k_prune - 1]\n",
    "        mask = (score > thresh).astype(float)\n",
    "        # if ties create too many kept/pruned, fix deterministically\n",
    "        # (rare but possible with many equal scores)\n",
    "        if mask.sum() > num_params - k_prune:\n",
    "            # drop some tied-at-threshold entries\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_drop = int(mask.sum() - (num_params - k_prune))\n",
    "            if need_drop > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                mask_flat[idx_tied[:need_drop]] = 0.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "        elif mask.sum() < num_params - k_prune:\n",
    "            # add some tied entries if we kept too few\n",
    "            idx_tied = np.where(score.reshape(-1) == thresh)[0]\n",
    "            need_add = int((num_params - k_prune) - mask.sum())\n",
    "            if need_add > 0:\n",
    "                mask_flat = mask.reshape(-1)\n",
    "                # add back from tied\n",
    "                add_candidates = idx_tied[mask_flat[idx_tied] == 0.0]\n",
    "                mask_flat[add_candidates[:need_add]] = 1.0\n",
    "                mask = mask_flat.reshape(score.shape)\n",
    "    else:\n",
    "        # prune largest (not typical)\n",
    "        thresh = np.partition(flat, num_params - k_prune)[num_params - k_prune]\n",
    "        mask = (score < thresh).astype(float)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def precompute_global_masks(\n",
    "    all_fits,\n",
    "    model,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict: sparsity -> (mask_W1, mask_W2 or None)\n",
    "    \"\"\"\n",
    "    fit = all_fits[model][\"posterior\"]\n",
    "\n",
    "    W1_samples = fit.stan_variable(\"W_1\")  # (S, P, H)\n",
    "    W2_samples = fit.stan_variable(\"W_L\")  # (S, H, O) or (S, H) depending on O\n",
    "\n",
    "    masks = {}\n",
    "    for q in sparsity_levels:\n",
    "        mask_W1 = build_global_mask_from_posterior(W1_samples, q, method=method)\n",
    "        mask_W2 = None\n",
    "        if prune_W2:\n",
    "            mask_W2 = build_global_mask_from_posterior(W2_samples, q, method=method)\n",
    "        masks[q] = (mask_W1, mask_W2)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_abalone_regression_data\n",
    "def _logsumexp(a, axis=None):\n",
    "    amax = np.max(a, axis=axis, keepdims=True)\n",
    "    out = amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))\n",
    "    return np.squeeze(out, axis=axis)\n",
    "\n",
    "def gaussian_nll_pointwise(y, mu, sigma):\n",
    "    return 0.5*np.log(2*np.pi*(sigma**2)) + 0.5*((y-mu)**2)/(sigma**2)\n",
    "\n",
    "def compute_sparse_metrics_results_globalmask_large_eval(\n",
    "    models, all_fits, forward_pass,\n",
    "    sparsity=0.0,\n",
    "    masks_cache=None,\n",
    "    prune_W2=False,\n",
    "    compute_nll=True,\n",
    "    noise_var_name=\"sigma\",\n",
    "    # pass the correct generator functions\n",
    "    gen_uncorr=None,\n",
    "    gen_corr=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate on a large generated test set instead of the stored tiny X_test/y_test.\n",
    "    Assumes model was trained on standardized y if standardize_y=True.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "    # Build large eval set consistent with training split standardization\n",
    "    X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "    y_std = y_train.std()\n",
    "    y_mean = y_train.mean()\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "\n",
    "            noise_samples = None\n",
    "            if compute_nll:\n",
    "                try:\n",
    "                    noise_samples = fit.stan_variable(noise_var_name).squeeze()\n",
    "                except Exception:\n",
    "                    noise_samples = None\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found: -> {model}\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "        rmses = np.zeros(S)\n",
    "\n",
    "        mask_W1 = mask_W2 = None\n",
    "        if masks_cache is not None and sparsity > 0.0:\n",
    "            mask_W1, mask_W2 = masks_cache[(model)][sparsity]\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            if mask_W1 is not None:\n",
    "                W1 = W1 * mask_W1\n",
    "            if prune_W2 and (mask_W2 is not None):\n",
    "                W2 = W2 * mask_W2\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i]).squeeze()\n",
    "            y_hats[i] = y_hat\n",
    "            rmses[i] = np.sqrt(np.mean((y_hat - y_test)**2))\n",
    "\n",
    "        # posterior mean RMSE (standardized scale)\n",
    "        posterior_mean = y_hats.mean(axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test)**2))\n",
    "\n",
    "        out_pm = {\n",
    "            'N': X_train.shape[0],\n",
    "            #'sigma': sigma,\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'n_eval': y_test.shape[0],\n",
    "            'posterior_mean_rmse': posterior_mean_rmse,\n",
    "            'posterior_mean_rmse_orig': posterior_mean_rmse * y_std,  # back to original y scale\n",
    "        }\n",
    "\n",
    "        if compute_nll:\n",
    "            if noise_samples is None:\n",
    "                sig_s = np.ones(S)\n",
    "            else:\n",
    "                sig_s = np.asarray(noise_samples).reshape(-1)[:S]\n",
    "\n",
    "            # Expected NLL\n",
    "            nll_draws = np.array([\n",
    "                gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i]).mean()\n",
    "                for i in range(S)\n",
    "            ])\n",
    "            expected_nll = nll_draws.mean()\n",
    "\n",
    "            # Predictive (mixture) NLL\n",
    "            loglik = -np.stack([\n",
    "                gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i])\n",
    "                for i in range(S)\n",
    "            ], axis=0)  # (S, n_eval)\n",
    "            lppd = (_logsumexp(loglik, axis=0) - np.log(S)).mean()\n",
    "            predictive_nll = -lppd\n",
    "\n",
    "            out_pm[\"expected_nll\"] = expected_nll\n",
    "            out_pm[\"predictive_nll\"] = predictive_nll\n",
    "\n",
    "            # Optional: predictive_nll on original scale (only if you also rescale sigma)\n",
    "            # If your sigma posterior is on standardized scale, original sigma = sig_s * y_std.\n",
    "            out_pm[\"predictive_nll_orig\"] = predictive_nll + np.log(y_std)  # see note below\n",
    "\n",
    "        posterior_means.append(out_pm)\n",
    "\n",
    "        for i in range(S):\n",
    "            row = {\n",
    "                'N': X_train.shape[0],\n",
    "                #'sigma': sigma,\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'n_eval': y_test.shape[0],\n",
    "                'rmse': rmses[i],\n",
    "                'rmse_orig': rmses[i] * y_std\n",
    "            }\n",
    "            if compute_nll:\n",
    "                row[\"nll\"] = gaussian_nll_pointwise(y_test, y_hats[i], sig_s[i]).mean()\n",
    "            results.append(row)\n",
    "\n",
    "    return pd.DataFrame(results), pd.DataFrame(posterior_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "def build_masks_cache_for_all(\n",
    "    all_fits,\n",
    "    models,\n",
    "    sparsity_levels,\n",
    "    prune_W2=False,\n",
    "    method=\"Eabs_stability\"\n",
    "):\n",
    "    masks_cache = {}\n",
    "    for model in models:\n",
    "        try:\n",
    "            masks_cache[(model)] = precompute_global_masks(\n",
    "                all_fits=all_fits,\n",
    "                model=model,\n",
    "                sparsity_levels=sparsity_levels,\n",
    "                prune_W2=prune_W2,\n",
    "                method=method\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP MASKS] Missing fit for -> {model}\")\n",
    "    return masks_cache\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "\n",
    "# Build the list of dataset keys you actually evaluate (same keys as in your compute loop)\n",
    "\n",
    "# Precompute masks once\n",
    "masks_relu = build_masks_cache_for_all(relu_fit, model_names_relu, sparsity_levels, prune_W2=False)\n",
    "\n",
    "masks_tanh = build_masks_cache_for_all(tanh_fit, model_names_tanh, sparsity_levels, prune_W2=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_relu, df_post_relu = {}, {}\n",
    "\n",
    "for q in sparsity_levels:\n",
    "    df_rmse_relu[q], df_post_relu[q] = compute_sparse_metrics_results_globalmask_large_eval(\n",
    "        models=model_names_relu,\n",
    "        all_fits=relu_fit,\n",
    "        forward_pass=forward_pass_relu,\n",
    "        sparsity=q,\n",
    "        masks_cache=masks_relu,\n",
    "        prune_W2=False,\n",
    "        compute_nll=True,\n",
    "        noise_var_name=\"sigma\",\n",
    "    )\n",
    "\n",
    "df_rmse_tanh, df_post_tanh = {}, {}\n",
    "\n",
    "for q in sparsity_levels:\n",
    "    df_rmse_tanh[q], df_post_tanh[q] = compute_sparse_metrics_results_globalmask_large_eval(\n",
    "        models=model_names_tanh,\n",
    "        all_fits=tanh_fit,\n",
    "        forward_pass=forward_pass_tanh,\n",
    "        sparsity=q,\n",
    "        masks_cache=masks_tanh,\n",
    "        prune_W2=False,\n",
    "        compute_nll=True,\n",
    "        noise_var_name=\"sigma\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_relu_full = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_post_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_post_tanh_full = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_post_tanh.items()],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_relu_full[df_post_relu_full['sparsity']==0.0].sort_values(by=\"posterior_mean_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_relu_full[df_post_relu_full['sparsity']==0.0].sort_values(by=\"predictive_nll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh_full[df_post_tanh_full['sparsity']==0.0].sort_values(by=\"posterior_mean_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_tanh_full[df_post_tanh_full['sparsity']==0.0].sort_values(by=\"predictive_nll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Dirichlet Horseshoe\"]['predictive_nll'], label=\"DHS\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Beta Horseshoe\"]['predictive_nll'], label=\"BHS\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Dirichlet Student T\"]['predictive_nll'], label=\"DST\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Beta Student T\"]['predictive_nll'], label=\"BST\")\n",
    "plt.xlabel(\"Sparsity\")\n",
    "plt.ylabel(\"PLL\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Dirichlet Horseshoe\"]['posterior_mean_rmse'], label=\"DHS\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Beta Horseshoe\"]['posterior_mean_rmse'], label=\"BHS\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Dirichlet Student T\"]['posterior_mean_rmse'], label=\"DST\")\n",
    "plt.plot(sparsity_levels, df_post_relu_full[df_post_relu_full['model']==\"Beta Student T\"]['posterior_mean_rmse'], label=\"BST\")\n",
    "plt.xlabel(\"Sparsity\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Dirichlet Horseshoe tanh\"]['predictive_nll'], label=\"DHS\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Beta Horseshoe tanh\"]['predictive_nll'], label=\"BHS\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Dirichlet Student T tanh\"]['predictive_nll'], label=\"DST\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Beta Student T tanh\"]['predictive_nll'], label=\"BST\")\n",
    "plt.xlabel(\"Sparsity\")\n",
    "plt.ylabel(\"PLL\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Dirichlet Horseshoe tanh\"]['posterior_mean_rmse'], label=\"DHS\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Beta Horseshoe tanh\"]['posterior_mean_rmse'], label=\"BHS\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Dirichlet Student T tanh\"]['posterior_mean_rmse'], label=\"DST\")\n",
    "plt.plot(sparsity_levels, df_post_tanh_full[df_post_tanh_full['model']==\"Beta Student T tanh\"]['posterior_mean_rmse'], label=\"BST\")\n",
    "plt.xlabel(\"Sparsity\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
