{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/correlated\"\n",
    "results_dir_tanh = \"results/correlated\"\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "full_config_path = \"correlated_N400_p6\"\n",
    "\n",
    "tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORTANT: this y_test must correspond to the same test set used to make `output_test` in Stan,\n",
    "# otherwise scores won’t be comparable.\n",
    "from utils.generate_data import generate_correlated_data\n",
    "X_train, X_test, y_train, y_test = generate_correlated_data(n=500, p=6)\n",
    "\n",
    "rows = []\n",
    "for model_name, model_entry in tanh_fit.items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    # (S, n_test)\n",
    "    y_samps = post.stan_variable(\"output_test\").squeeze(-1)\n",
    "\n",
    "    # Posterior-mean predictions and RMSE\n",
    "    y_mean = y_samps.mean(axis=0)                                   # (n_test,)\n",
    "    rmse_post_mean = float(np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "\n",
    "    # Per-draw RMSEs and their mean\n",
    "    per_draw_rmse = np.sqrt(((y_samps - y_test[None, :])**2).mean(axis=1))  # (S,)\n",
    "    rmse_draw_mean = float(per_draw_rmse.mean())\n",
    "\n",
    "    # CRPS across the ensemble (expects shape (n_test, S))\n",
    "    crps = float(np.mean(crps_ensemble(y_test, y_samps.T)))\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE_posterior_mean\": rmse_post_mean,\n",
    "        \"RMSE_mean_over_draws\": rmse_draw_mean,\n",
    "        \"CRPS\": crps,\n",
    "        \"n_draws\": y_samps.shape[0]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE_posterior_mean\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_sparse_rmse_results_hastie(models, all_fits, forward_pass,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "    _, X_test, _, y_test = generate_correlated_data(n=500, p=6)\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found:\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        rmses = np.zeros(S)\n",
    "        #print(y_test.shape)\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            # Apply pruning mask if requested\n",
    "            if prune_fn is not None and sparsity > 0.0:\n",
    "                masks = prune_fn([W1, W2], sparsity)\n",
    "                W1 = W1 * masks[0]\n",
    "                #W2 = W2 * masks[1]\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "            y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "            rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "            \n",
    "        posterior_mean = np.mean(y_hats, axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "        posterior_means.append({\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'posterior_mean_rmse': posterior_mean_rmse\n",
    "        })\n",
    "\n",
    "        for i in range(S):\n",
    "            results.append({\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'rmse': rmses[i]\n",
    "            })\n",
    "\n",
    "    df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    return df_rmse, df_posterior_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "df_rmse_tanh, df_posterior_rmse_tanh = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "\n",
    "    df_rmse_tanh[sparsity], df_posterior_rmse_tanh[sparsity] = compute_sparse_rmse_results_hastie(\n",
    "        models = model_names_tanh,\n",
    "        all_fits = tanh_fit, \n",
    "        forward_pass = forward_pass_tanh,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "frames = []\n",
    "for sp, df in df_rmse_tanh.items():\n",
    "    df = df.copy()\n",
    "    # Sikre at sparsity-kolonnen matcher key (skriver inn hvis avvik)\n",
    "    df['sparsity'] = float(sp)\n",
    "    frames.append(df)\n",
    "\n",
    "df_all = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "# Rydding: sikre dtypes og sortering\n",
    "df_all['sparsity'] = df_all['sparsity'].astype(float)\n",
    "df_all['rmse'] = pd.to_numeric(df_all['rmse'], errors='coerce')\n",
    "df_all = df_all.dropna(subset=['rmse', 'sparsity', 'model'])\n",
    "\n",
    "# Valgfritt: sortér modellnavn som kategorisk for konsistent plottrekkefølge\n",
    "models_order = sorted(df_all['model'].unique())\n",
    "df_all['model'] = pd.Categorical(df_all['model'], categories=models_order, ordered=True)\n",
    "\n",
    "# ---- Oppsummeringsstatistikk: mean, std, n, 95% CI ----\n",
    "summary = (\n",
    "    df_all.groupby(['model', 'sparsity'])\n",
    "    .agg(n=('rmse', 'size'),\n",
    "         mean_rmse=('rmse', 'mean'),\n",
    "         std_rmse=('rmse', 'std'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Unngå deling på null\n",
    "summary['sem'] = summary['std_rmse'] / summary['n'].replace(0, np.nan).pow(0.5)\n",
    "# 95% CI med normaltilnærming: mean ± 1.96 * SEM\n",
    "summary['ci95'] = 1.96 * summary['sem']\n",
    "summary['ymin'] = summary['mean_rmse'] - summary['ci95']\n",
    "summary['ymax'] = summary['mean_rmse'] + summary['ci95']\n",
    "\n",
    "# ---- Plot-stil ----\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# ---- Figur 1: Linjeplot av mean RMSE vs sparsity, farget per modell, med CI ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Linjer\n",
    "sns.lineplot(\n",
    "    data=summary.sort_values(['model', 'sparsity']),\n",
    "    x='sparsity', y='mean_rmse', hue='model',\n",
    "    linewidth=2.5, marker='o', markersize=7\n",
    ")\n",
    "# Errorbars (CI)\n",
    "for _, row in summary.iterrows():\n",
    "    plt.plot([row['sparsity'], row['sparsity']], [row['ymin'], row['ymax']],\n",
    "             color=sns.color_palette()[models_order.index(row['model'])], lw=2)\n",
    "\n",
    "plt.title('RMSE vs sparsity per modell (mean ± 95% CI)')\n",
    "plt.xlabel('Sparsity')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(title='Modell', loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "# ---- Figur 2: Boxplot av RMSE fordelt per sparsity, delt (hue) på modell ----\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    data=df_all,\n",
    "    x='sparsity', y='rmse', hue='model',\n",
    "    showfliers=False,  # skjul outliers for ryddigere helhetsinntrykk\n",
    "    linewidth=1.2\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_all.sample(min(len(df_all), 2000), random_state=42),  # vis et utvalg punkter, ikke alt\n",
    "    x='sparsity', y='rmse', hue='model',\n",
    "    dodge=True, size=2, alpha=0.25, palette='dark'\n",
    ")\n",
    "# Fjern duplisert legend fra stripplot\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles[:len(models_order)], labels[:len(models_order)], title='Modell', loc='best')\n",
    "\n",
    "plt.title('RMSE-fordeling per sparsity og modell (box + punkter)')\n",
    "plt.xlabel('Sparsity')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSTERIOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from utils.generate_data import generate_correlated_data\n",
    "X_train, _, _, _ = generate_correlated_data(n=500, p=6)\n",
    "\n",
    "P = 6\n",
    "H = 16\n",
    "L = 1\n",
    "out_nodes = 1\n",
    "\n",
    "layer_structure = {\n",
    "    'input_to_hidden': {'name': 'W_1', 'shape': (P, H)},\n",
    "    'hidden_to_output': {'name': 'W_L', 'shape': (H, out_nodes)}\n",
    "}\n",
    "\n",
    "\n",
    "def build_single_draw_weights(fits, layer_structure, draw_idx):\n",
    "    \"\"\"Return {model: {'W_1': (P,H), 'W_L': (H,O)}} for ONE draw.\"\"\"\n",
    "    out = {}\n",
    "    for name, fd in fits.items():\n",
    "        fit = fd[\"posterior\"]\n",
    "        W1 = fit.stan_variable(layer_structure['input_to_hidden']['name'])[draw_idx]\n",
    "        WL = fit.stan_variable(layer_structure['hidden_to_output']['name'])[draw_idx]\n",
    "        WL = WL.reshape(layer_structure['hidden_to_output']['shape'])\n",
    "        out[name] = {\"W_1\": W1, \"W_L\": WL}\n",
    "    return out\n",
    "\n",
    "def scale_W1_for_plot(model_means, mode='global'):\n",
    "    \"\"\"\n",
    "    Skalerer alle W_1 til [-1, 1] for rettferdig sammenligning av edge-tykkelser.\n",
    "\n",
    "    mode:\n",
    "      - 'global' : én felles skala over alle modeller (mest sammenlignbar)\n",
    "      - 'per_model': egen skala per modell (uavhengig sammenligning)\n",
    "      - 'per_node' : skalerer hver kolonne (node) separat til [-1,1]\n",
    "\n",
    "    Returnerer: scaled_model_means (samme struktur som input), scale_info\n",
    "    \"\"\"\n",
    "    scaled = {}\n",
    "    if mode == 'global':\n",
    "        gmax = max(np.abs(m['W_1']).max() for m in model_means.values())\n",
    "        gmax = max(gmax, 1e-12)\n",
    "        for name, m in model_means.items():\n",
    "            W1s = m['W_1'] / gmax\n",
    "            out = {k: v for k, v in m.items()}\n",
    "            out['W_1'] = W1s\n",
    "            scaled[name] = out\n",
    "        return scaled, {'mode': 'global', 'scale': gmax}\n",
    "\n",
    "    elif mode == 'per_model':\n",
    "        for name, m in model_means.items():\n",
    "            s = max(np.abs(m['W_1']).max(), 1e-12)\n",
    "            out = {k: v for k, v in m.items()}\n",
    "            out['W_1'] = m['W_1'] / s\n",
    "            scaled[name] = out\n",
    "        return scaled, {'mode': 'per_model'}\n",
    "\n",
    "    elif mode == 'per_node':\n",
    "        for name, m in model_means.items():\n",
    "            W1 = m['W_1'].copy()\n",
    "            P, H = W1.shape\n",
    "            for h in range(H):\n",
    "                colmax = max(np.abs(W1[:, h]).max(), 1e-12)\n",
    "                W1[:, h] = W1[:, h] / colmax\n",
    "            out = {k: v for k, v in m.items()}\n",
    "            out['W_1'] = W1\n",
    "            scaled[name] = out\n",
    "        return scaled, {'mode': 'per_node'}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'global', 'per_model', or 'per_node'\")\n",
    "#feature_names = list(X_train.columns)\n",
    "def plot_models_with_activations(model_means, layer_sizes,\n",
    "                                 activations=None, activation_color_max=None,\n",
    "                                 ncols=3, figsize_per_plot=(5,4), signed_colors=False, feature_names=None):\n",
    "    \"\"\"\n",
    "    model_means: dict {model_name: {'W_1':(P,H), 'W_L':(H,O), optional 'W_internal':[...]} }\n",
    "    layer_sizes: f.eks [P, H, O] eller [P, H, H, O] ved internlag\n",
    "    activations: dict {model_name: (H,)} – aktiveringsfrekvens kun for første skjulte lag\n",
    "    activation_color_max: global maks for skalering av farger (hvis None brukes 1.0)\n",
    "    \"\"\"\n",
    "    names = list(model_means.keys())\n",
    "    n_models = len(names)\n",
    "    nrows = int(np.ceil(n_models / ncols))\n",
    "    figsize = (figsize_per_plot[0] * ncols, figsize_per_plot[1] * nrows)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    if nrows * ncols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Skru av blanke akser\n",
    "    for ax in axes[n_models:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    for ax, name in zip(axes, names):\n",
    "        weights = model_means[name]\n",
    "        G = nx.DiGraph()\n",
    "        pos, nodes_per_layer, node_colors = {}, [], []\n",
    "\n",
    "        # Noder med posisjon og farge\n",
    "        for li, size in enumerate(layer_sizes):\n",
    "            ids = []\n",
    "            ycoords = np.linspace(size - 1, 0, size) - (size - 1) / 2\n",
    "            for i in range(size):\n",
    "                nid = f\"L{li}_{i}\"\n",
    "                G.add_node(nid)\n",
    "                pos[nid] = (li, ycoords[i])\n",
    "                ids.append(nid)\n",
    "                if li == 0 and feature_names is not None:\n",
    "                    ax.text(pos[nid][0]-0.12, pos[nid][1], feature_names[i],\n",
    "                            ha='right', va='center', fontsize=8)\n",
    "\n",
    "                if activations is not None and li == 1:  # kun første skjulte lag\n",
    "                    #a = activations.get(name, np.zeros(size))\n",
    "                    a = activations.get(name, np.zeros(size))\n",
    "                    a = np.asarray(a).ravel()   # <-- flater til 1D array\n",
    "                    scale = activation_color_max if activation_color_max is not None else 1.0\n",
    "                    val = float(np.clip(a[i] / max(scale, 1e-12), 0.0, 1.0))\n",
    "                    color = plt.cm.winter(val)\n",
    "                else:\n",
    "                    color = 'lightgray'\n",
    "                node_colors.append(color)\n",
    "\n",
    "            nodes_per_layer.append(ids)\n",
    "\n",
    "        edge_colors, edge_widths = [], []\n",
    "\n",
    "        def add_edges(W, inn, ut):\n",
    "            for j, out_n in enumerate(ut):\n",
    "                for i, in_n in enumerate(inn):\n",
    "                    w = float(W[i, j])\n",
    "                    G.add_edge(in_n, out_n, weight=abs(w))\n",
    "                    edge_colors.append('red' if w >= 0 else 'blue')\n",
    "                    edge_widths.append(abs(w))\n",
    "\n",
    "        # input -> hidden(1)\n",
    "        add_edges(weights['W_1'], nodes_per_layer[0], nodes_per_layer[1])\n",
    "\n",
    "        # ev. internlag\n",
    "        if 'W_internal' in weights:\n",
    "            for l, Win in enumerate(weights['W_internal']):\n",
    "                add_edges(Win, nodes_per_layer[l+1], nodes_per_layer[l+2])\n",
    "\n",
    "        # siste hidden -> output\n",
    "        add_edges(weights['W_L'], nodes_per_layer[-2], nodes_per_layer[-1])\n",
    "\n",
    "        nx.draw(G, pos, ax=ax,\n",
    "                node_color=node_colors,\n",
    "                edge_color=(edge_colors if signed_colors else 'red'),\n",
    "                width=[G[u][v]['weight'] for u,v in G.edges()],\n",
    "                with_labels=False, node_size=400, arrows=False)\n",
    "\n",
    "        ax.set_title(name, fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def compute_hidden_activation(fit_dict, x_train, draw_idx):\n",
    "    fit = fit_dict['posterior']\n",
    "    W1 = fit.stan_variable('W_1')[draw_idx, :, :]          # (P,H)\n",
    "    try:\n",
    "        b1 = fit.stan_variable('hidden_bias')[draw_idx, :] # (H,)\n",
    "    except Exception:\n",
    "        b1 = np.zeros(W1.shape[1])\n",
    "    # tanh i [-1,1]\n",
    "    a_full = np.tanh(x_train @ W1 + b1)             # (H,)\n",
    "    a=np.mean(a_full, axis=0)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velg en observasjon å \"lyse opp\" nodefargene med\n",
    "obs_idx = 3\n",
    "draw_idx = 69 #pick_draw_idx(prior_fits, seed=42)      # one common draw across models\n",
    "prior_draws = build_single_draw_weights(tanh_fit, layer_structure, draw_idx)\n",
    "\n",
    "# 1) Beregn aktivasjoner for ALLE modellene\n",
    "activations = {}\n",
    "for name, fd in tanh_fit.items():\n",
    "    a = compute_hidden_activation(fd, X_train, draw_idx)\n",
    "    activations[name] = np.abs(a)      \n",
    "\n",
    "# 2) Skaler vekter for plotting (som før)\n",
    "scaled, _ = scale_W1_for_plot(prior_draws, mode='per_model')\n",
    "\n",
    "# 3) Kall plottet med aktivasjoner\n",
    "# Siden tanh ∈ [-1,1] og vi bruker |a|, så sett activation_color_max=1.0\n",
    "fig = plot_models_with_activations(\n",
    "    scaled,\n",
    "    layer_sizes=[P, H, out_nodes],\n",
    "    activations=activations,\n",
    "    activation_color_max=1.0,\n",
    "    ncols=2,\n",
    "    feature_names = None #feature_names\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST SHAPLEY VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import generate_correlated_data\n",
    "X_train, X_test, y_train, y_test = generate_correlated_data(n=500, p=6)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose X_train has shape (n, p)\n",
    "X_train_pd = pd.DataFrame(X_train, columns=[f\"X{i+1}\" for i in range(X_train.shape[1])])\n",
    "X_test_pd = pd.DataFrame(X_test, columns=[f\"X{i+1}\" for i in range(X_train.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.robust_utils import build_pytorch_model_from_stan_sample\n",
    "\n",
    "models_to_eval = [\n",
    "    \"Gaussian tanh\",\n",
    "    \"Regularized Horseshoe tanh\",\n",
    "    \"Dirichlet Horseshoe tanh\",\n",
    "    \"Dirichlet Student T tanh\"\n",
    "]\n",
    "\n",
    "H = 16                       # hidden dim\n",
    "feature_names = [f\"X{i+1}\" for i in range(P)]\n",
    "\n",
    "# SHAP background & evaluation subsets (reuse across models for fairness)\n",
    "X_bg   = X_train_pd.sample(n=400, random_state=0).to_numpy(float)\n",
    "X_eval = X_test_pd.sample(n=100, random_state=1).to_numpy(float)\n",
    "\n",
    "results = {}   # store mean SHAP vectors per model\n",
    "\n",
    "for model_name in models_to_eval:\n",
    "\n",
    "    print(f\"\\n=== Evaluating SHAP for model: {model_name} ===\")\n",
    "\n",
    "    fit = tanh_fit[model_name]['posterior']\n",
    "\n",
    "    # Build one representative sample from posterior\n",
    "    model = build_pytorch_model_from_stan_sample(\n",
    "        fit, sample_idx=69, input_dim=P, hidden_dim=H,\n",
    "        output_dim=1, task=\"regression\", activation=torch.tanh\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    def predict_numpy(X_np):\n",
    "        with torch.no_grad():\n",
    "            X_t = torch.tensor(X_np, dtype=torch.float32)\n",
    "            y = model(X_t).cpu().numpy()\n",
    "        return y\n",
    "\n",
    "    explainer = shap.KernelExplainer(predict_numpy, X_bg)\n",
    "    shap_vals = explainer.shap_values(X_eval)  # shape = (n_eval, P)\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_vals).mean(axis=0)  # global importance\n",
    "\n",
    "    results[model_name] = mean_abs_shap\n",
    "\n",
    "    print(f\"Top features for {model_name}:\")\n",
    "    order = np.argsort(mean_abs_shap)[::-1]\n",
    "    for j in order[:10]:\n",
    "        print(f\"  {feature_names[j]:16s}  SHAP={mean_abs_shap[j]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING DIFFERENCE IN RMSE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _as_SN(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 3 and arr.shape[-1] == 1:\n",
    "        arr = arr[..., 0]\n",
    "    return arr\n",
    "\n",
    "def mse_rmse_summary(y_true, y_samps):\n",
    "    \"\"\"\n",
    "    y_true: (N,) or (N,1)\n",
    "    y_samps: (S,N) or (S,N,1)\n",
    "    Returns a dict with:\n",
    "      - rmse_mean_pred: RMSE of posterior mean (Option 1)\n",
    "      - rmse_per_sample: array of per-sample RMSEs (length S) (Option 2)\n",
    "      - rmse_per_sample_mean: mean of per-sample RMSEs\n",
    "      - mse_gap: avg_sample_MSE - MSE_of_mean = average epistemic variance\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_true).reshape(-1)\n",
    "    Y = _as_SN(y_samps)  # (S,N)\n",
    "\n",
    "    # Posterior predictive mean\n",
    "    y_bar = Y.mean(axis=0)                 # (N,)\n",
    "    se_mean = (y - y_bar)**2               # (N,)\n",
    "    mse_mean = se_mean.mean()\n",
    "    rmse_mean = np.sqrt(mse_mean)          # Option 1\n",
    "\n",
    "    # Per-sample RMSEs\n",
    "    se_all = (y[None, :] - Y)**2           # (S,N)\n",
    "    mse_per_sample = se_all.mean(axis=1)   # (S,)\n",
    "    rmse_per_sample = np.sqrt(mse_per_sample)  # (S,)\n",
    "    rmse_per_sample_mean = rmse_per_sample.mean()   # Option 2\n",
    "\n",
    "    # Decomposition & gap\n",
    "    # avg_sample_MSE = MSE(mean) + mean Var_s(Y[:,i])\n",
    "    avg_sample_mse = mse_per_sample.mean()\n",
    "    epistemic_var = Y.var(axis=0, ddof=0).mean()\n",
    "    mse_gap = avg_sample_mse - mse_mean    # should equal epistemic_var (up to MC noise)\n",
    "\n",
    "    return dict(\n",
    "        rmse_mean_pred=rmse_mean,\n",
    "        rmse_per_sample=rmse_per_sample,\n",
    "        rmse_per_sample_mean=rmse_per_sample_mean,\n",
    "        avg_sample_mse=avg_sample_mse,\n",
    "        mse_mean=mse_mean,\n",
    "        epistemic_var_est=epistemic_var,\n",
    "        mse_gap=mse_gap\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_gauss = tanh_fit['Gaussian tanh']['posterior'].stan_variable(\"output_test\")\n",
    "output_test_RHS = tanh_fit['Regularized Horseshoe tanh']['posterior'].stan_variable(\"output_test\")\n",
    "output_test_DHS = tanh_fit['Dirichlet Horseshoe tanh']['posterior'].stan_variable(\"output_test\")\n",
    "output_test_DST = tanh_fit['Dirichlet Student T tanh']['posterior'].stan_variable(\"output_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_gauss = mse_rmse_summary(y_test, output_test_gauss)\n",
    "sum_rhs   = mse_rmse_summary(y_test, output_test_RHS)\n",
    "sum_dhs   = mse_rmse_summary(y_test, output_test_DHS)\n",
    "sum_dst   = mse_rmse_summary(y_test, output_test_DST)\n",
    "\n",
    "print(\"Gaussian — RMSE(mean):\", sum_gauss[\"rmse_mean_pred\"], \n",
    "      \" mean per-sample RMSE:\", sum_gauss[\"rmse_per_sample_mean\"],\n",
    "      \" gap (avg MSE - mean MSE):\", sum_gauss[\"mse_gap\"])\n",
    "\n",
    "print(\"RHS      — RMSE(mean):\", sum_rhs[\"rmse_mean_pred\"], \n",
    "      \" mean per-sample RMSE:\", sum_rhs[\"rmse_per_sample_mean\"],\n",
    "      \" gap (avg MSE - mean MSE):\", sum_rhs[\"mse_gap\"])\n",
    "\n",
    "print(\"DHS      — RMSE(mean):\", sum_dhs[\"rmse_mean_pred\"], \n",
    "      \" mean per-sample RMSE:\", sum_dhs[\"rmse_per_sample_mean\"],\n",
    "      \" gap (avg MSE - mean MSE):\", sum_dhs[\"mse_gap\"])\n",
    "\n",
    "print(\"DST      — RMSE(mean):\", sum_dst[\"rmse_mean_pred\"], \n",
    "      \" mean per-sample RMSE:\", sum_dst[\"rmse_per_sample_mean\"],\n",
    "      \" gap (avg MSE - mean MSE):\", sum_dst[\"mse_gap\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_table(y_true, y_samps, levels=(0.5, 0.8, 0.9, 0.95)):\n",
    "    \"\"\"\n",
    "    Central coverage: for each level q, compute lower=(1-q)/2 and upper=1-lower,\n",
    "    then check fraction of y within [q_low, q_high] pointwise and average over N.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_true).reshape(-1)\n",
    "    Y = _as_SN(y_samps)  # (S,N)\n",
    "    S, N = Y.shape\n",
    "    cov = {}\n",
    "    for q in levels:\n",
    "        lo = (1 - q) / 2\n",
    "        hi = 1 - lo\n",
    "        q_lo = np.quantile(Y, lo, axis=0)\n",
    "        q_hi = np.quantile(Y, hi, axis=0)\n",
    "        covered = ((y >= q_lo) & (y <= q_hi)).mean()\n",
    "        cov[q] = covered\n",
    "    return cov\n",
    "\n",
    "# Example:\n",
    "cov_gauss = coverage_table(y_test, output_test_gauss)\n",
    "cov_rhs   = coverage_table(y_test, output_test_RHS)\n",
    "cov_dhs   = coverage_table(y_test, output_test_DHS)\n",
    "cov_dst   = coverage_table(y_test, output_test_DST)\n",
    "print(\"Coverage — Gaussian:\", cov_gauss)\n",
    "print(\"Coverage — RHS     :\", cov_rhs)\n",
    "print(\"Coverage — DHS     :\", cov_dhs)\n",
    "print(\"Coverage — DST     :\", cov_dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit_uniformity(y_true, y_samps, n_bins=10):\n",
    "    \"\"\"\n",
    "    Rank-based PIT: u_i = rank(y_i among draws)/S. \n",
    "    Returns summary stats and a simple KS-like max deviation from uniform CDF.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_true).reshape(-1)\n",
    "    Y = _as_SN(y_samps)  # (S,N)\n",
    "    S, N = Y.shape\n",
    "\n",
    "    # For each i, PIT u_i = (#{s: Y_s,i <= y_i}) / S\n",
    "    u = np.mean(Y <= y[None, :], axis=0)   # (N,)\n",
    "\n",
    "    # Histogram bins (for a quick glance)\n",
    "    hist, edges = np.histogram(u, bins=n_bins, range=(0.0, 1.0), density=False)\n",
    "    hist = hist / hist.sum()  # empirical frequencies per bin\n",
    "    # KS-like sup norm to uniform CDF on the N points\n",
    "    u_sorted = np.sort(u)\n",
    "    ecdf = np.arange(1, N+1) / N\n",
    "    ks_stat = np.max(np.abs(u_sorted - ecdf))  # lower is better\n",
    "\n",
    "    return dict(\n",
    "        u=u,\n",
    "        hist=hist,\n",
    "        edges=edges,\n",
    "        mean=np.mean(u),\n",
    "        var=np.var(u, ddof=0),\n",
    "        ks_stat=ks_stat\n",
    "    )\n",
    "\n",
    "pit_gauss = pit_uniformity(y_test, output_test_gauss)\n",
    "pit_rhs   = pit_uniformity(y_test, output_test_RHS)\n",
    "pit_dhs   = pit_uniformity(y_test, output_test_DHS)\n",
    "pit_dst   = pit_uniformity(y_test, output_test_DST)\n",
    "print(\"PIT KS — Gaussian:\", pit_gauss[\"ks_stat\"], \" mean:\", pit_gauss[\"mean\"], \" var:\", pit_gauss[\"var\"])\n",
    "print(\"PIT KS — RHS     :\", pit_rhs[\"ks_stat\"],   \" mean:\", pit_rhs[\"mean\"],   \" var:\", pit_rhs[\"var\"])\n",
    "print(\"PIT KS — DHS     :\", pit_dhs[\"ks_stat\"],   \" mean:\", pit_dhs[\"mean\"],   \" var:\", pit_dhs[\"var\"])\n",
    "print(\"PIT KS — DHS     :\", pit_dst[\"ks_stat\"],   \" mean:\", pit_dst[\"mean\"],   \" var:\", pit_dst[\"var\"])\n",
    "# For perfect calibration: mean ~ 0.5, var ~ 1/12 ≈ 0.0833, small ks_stat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_entropy_gaussian(y_samps, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Gaussian plug-in predictive entropy per test point from posterior draws.\n",
    "    Returns per-point entropies and their mean.\n",
    "    \"\"\"\n",
    "    Y = _as_SN(y_samps)  # (S,N)\n",
    "    var_pred = Y.var(axis=0, ddof=0) + eps\n",
    "    H = 0.5 * np.log(2*np.pi*np.e*var_pred)  # nats\n",
    "    return H, H.mean()\n",
    "\n",
    "H_gauss, H_gauss_mean = predictive_entropy_gaussian(output_test_gauss)\n",
    "H_rhs,   H_rhs_mean   = predictive_entropy_gaussian(output_test_RHS)\n",
    "H_dhs,   H_dhs_mean   = predictive_entropy_gaussian(output_test_DHS)\n",
    "H_dst,   H_dst_mean   = predictive_entropy_gaussian(output_test_DST)\n",
    "print(\"Mean predictive entropy (nats) — Gaussian:\", H_gauss_mean)\n",
    "print(\"Mean predictive entropy (nats) — RHS     :\", H_rhs_mean)\n",
    "print(\"Mean predictive entropy (nats) — DHS     :\", H_dhs_mean)\n",
    "print(\"Mean predictive entropy (nats) — DST     :\", H_dst_mean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
