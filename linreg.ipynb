{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_linreg_dataset, generate_linreg_simple_data\n",
    "\n",
    "rhos = [-0.9, -0.5, 0.0, 0.5, 0.9]\n",
    "\n",
    "# Map rho to the correct results directory\n",
    "results_dir_map = {\n",
    "    -0.9: \"results/regression/linreg/high_neg_corr\",\n",
    "    -0.5: \"results/regression/linreg/medium_neg_corr\",\n",
    "    0.0: \"results/regression/linreg/no_corr\",\n",
    "    0.5: \"results/regression/linreg/medium_corr\",\n",
    "    0.9: \"results/regression/linreg/high_corr\",\n",
    "}\n",
    "\n",
    "model_names = [\n",
    "    \"Linreg Gaussian\",\n",
    "    \"Linreg Regularized Horseshoe\",\n",
    "    \"Linreg Dirichlet Horseshoe\",\n",
    "    \"Linreg Dirichlet Student T\",\n",
    "    \"Linreg Beta Horseshoe\",\n",
    "    \"Linreg Beta Student T\",\n",
    "]\n",
    "\n",
    "data_dir = \"datasets/linreg\"\n",
    "\n",
    "# This will hold everything in an easy-to-handle structure\n",
    "experiments = {}\n",
    "\n",
    "for rho in rhos:\n",
    "    # 1. Load data\n",
    "    dataset_path = f\"{data_dir}/linreg_data_rho_{rho}.npz\"\n",
    "    X_train, X_test, y_train, y_test, _, _, _ = load_linreg_dataset(\n",
    "        path=dataset_path,\n",
    "        test_fraction=0.2,\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "    # 2. True coefficients\n",
    "    _, _, beta_true = generate_linreg_simple_data(rho=rho)\n",
    "\n",
    "    # 3. Model fits\n",
    "    results_dir_linreg = results_dir_map[rho]\n",
    "    full_config_path = f\"linreg_N200_p10_rho_{rho}\"\n",
    "\n",
    "    linreg_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_linreg,\n",
    "        models=model_names,\n",
    "        include_prior=False,\n",
    "    )\n",
    "\n",
    "    # 4. Store everything nicely under this rho\n",
    "    experiments[rho] = {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_test\": y_test,\n",
    "        \"beta_true\": beta_true,\n",
    "        \"results_dir\": results_dir_linreg,\n",
    "        \"config\": full_config_path,\n",
    "        \"fits\": linreg_fit,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rmse_results = {}\n",
    "\n",
    "for rho, exp in experiments.items():\n",
    "    X_train = exp[\"X_train\"]\n",
    "    X_test  = exp[\"X_test\"]\n",
    "    y_train = exp[\"y_train\"]\n",
    "    y_test  = exp[\"y_test\"]\n",
    "    fits    = exp[\"fits\"]\n",
    "\n",
    "    # Posterior samples\n",
    "    beta_gauss = fits['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "    beta_RHS   = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_DHS   = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_DST   = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "    beta_BHS   = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_BST   = fits['Linreg Beta Student T']['posterior'].stan_variable(\"beta\")\n",
    "\n",
    "    # GLS / OLS baseline\n",
    "    beta_GLS = np.linalg.pinv(X_train.T @ X_train) @ (X_train.T @ y_train)\n",
    "\n",
    "    # RMSEs based on posterior means\n",
    "    rmse_gauss = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_gauss, axis=0))**2))\n",
    "    rmse_RHS   = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_RHS,   axis=0))**2))\n",
    "    rmse_DHS   = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_DHS,   axis=0))**2))\n",
    "    rmse_DST   = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_DST,   axis=0))**2))\n",
    "    rmse_BHS   = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_BHS,   axis=0))**2))\n",
    "    rmse_BST   = np.sqrt(np.mean((y_test - X_test @ np.mean(beta_BST,   axis=0))**2))\n",
    "    rmse_GLS   = np.sqrt(np.mean((y_test - X_test @ beta_GLS)**2))\n",
    "\n",
    "    rmse_results[rho] = {\n",
    "        \"Gaussian\"       : rmse_gauss,\n",
    "        \"Regularized HS\" : rmse_RHS,\n",
    "        \"Dirichlet HS\"   : rmse_DHS,\n",
    "        \"Dirichlet ST\"   : rmse_DST,\n",
    "        \"Beta HS\"        : rmse_BHS,\n",
    "        \"Beta ST\"        : rmse_BST,\n",
    "        \"GLS\"            : rmse_GLS,\n",
    "    }\n",
    "\n",
    "# Nice printout\n",
    "for rho in sorted(rmse_results.keys()):\n",
    "    res = rmse_results[rho]\n",
    "    print(f\"\\nRMSE summary for rho = {rho}\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Gaussian        : {res['Gaussian']:.4f}\")\n",
    "    print(f\"Regularized HS  : {res['Regularized HS']:.4f}\")\n",
    "    print(f\"Dirichlet HS    : {res['Dirichlet HS']:.4f}\")\n",
    "    print(f\"Dirichlet ST    : {res['Dirichlet ST']:.4f}\")\n",
    "    print(f\"Beta HS         : {res['Beta HS']:.4f}\")\n",
    "    print(f\"Beta ST         : {res['Beta ST']:.4f}\")\n",
    "    print(f\"GLS             : {res['GLS']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- choose which rho to plot ---\n",
    "rho_to_plot = -0.9   # change to 0.0 or 0.5 if you like\n",
    "\n",
    "exp = experiments[rho_to_plot]\n",
    "fits = exp[\"fits\"]\n",
    "beta_true = exp[\"beta_true\"]\n",
    "\n",
    "# Extract posterior draws for this rho\n",
    "beta_gauss = fits['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "beta_RHS   = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DHS   = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DST   = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "beta_BHS   = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_BST   = fits['Linreg Beta Student T']['posterior'].stan_variable(\"beta\")\n",
    "\n",
    "S, P = beta_gauss.shape  # number of draws, number of coefficients\n",
    "\n",
    "# Put all draws into one long DataFrame\n",
    "def beta_to_long_df(beta_array, model_name):\n",
    "    \"\"\"\n",
    "    beta_array: (S, P)\n",
    "    returns DataFrame with columns: model, draw, coeff, beta\n",
    "    \"\"\"\n",
    "    S, P = beta_array.shape\n",
    "    df = pd.DataFrame(\n",
    "        beta_array.reshape(S * P),\n",
    "        columns=[\"beta\"]\n",
    "    )\n",
    "    df[\"draw\"] = np.repeat(np.arange(S), P)\n",
    "    df[\"coeff\"] = np.tile(np.arange(P), S)\n",
    "    df[\"model\"] = model_name\n",
    "    return df\n",
    "\n",
    "df_gauss = beta_to_long_df(beta_gauss, \"Gaussian\")\n",
    "df_RHS   = beta_to_long_df(beta_RHS,   \"Regularized Horseshoe\")\n",
    "df_DHS   = beta_to_long_df(beta_DHS,   \"Dirichlet Horseshoe\")\n",
    "df_DST   = beta_to_long_df(beta_DST,   \"Dirichlet Student T\")\n",
    "df_BHS   = beta_to_long_df(beta_DHS,   \"Beta Horseshoe\")\n",
    "df_BST   = beta_to_long_df(beta_DST,   \"Beta Student T\")\n",
    "\n",
    "#beta_df = pd.concat([df_gauss, df_RHS, df_DHS, df_DST], ignore_index=True)\n",
    "beta_df = pd.concat([df_gauss, df_RHS, df_DHS, df_DST, df_BHS, df_BST], ignore_index=True)\n",
    "\n",
    "# Attach true beta from experiments\n",
    "beta_true_series = pd.Series(beta_true, index=np.arange(len(beta_true)))\n",
    "beta_df[\"beta_true\"] = beta_df[\"coeff\"].map(beta_true_series)\n",
    "\n",
    "# Boxplot per coefficient, grouped by model\n",
    "coeffs_to_plot = 6\n",
    "rows = 3\n",
    "cols = int(np.ceil(coeffs_to_plot / rows))\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6, 6), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for j in range(coeffs_to_plot):\n",
    "    ax = axes[j]\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "\n",
    "    # Boxplot of posterior for beta_j under each model\n",
    "    data = [\n",
    "        df_j[df_j[\"model\"] == m][\"beta\"].values\n",
    "        for m in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "    ]\n",
    "    ax.boxplot(data, showfliers=False)\n",
    "    #ax.set_xticks([1, 2, 3, 4])\n",
    "    ax.set_xticks([1, 2, 3, 4, 5, 6])\n",
    "    #ax.set_xticklabels([\"Gauss\", \"RHS\", \"DHS\", \"DST\"], rotation=30)\n",
    "    ax.set_xticklabels([\"Gauss\", \"RHS\", \"DHS\", \"DST\", \"BHS\", \"BST\"], rotation=30)\n",
    "    ax.set_title(fr\"$w_{{{j+1}}}$\")\n",
    "\n",
    "    # True beta as horizontal line\n",
    "    ax.axhline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Hide unused axes if any\n",
    "for k in range(P, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "fig.suptitle(fr\"Posterior distributions of $w_j$ by prior, $\\rho={rho}$\", fontsize=12)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- choose which rho to work with ---\n",
    "rho_to_plot = -0.9  # or 0.0, 0.5\n",
    "\n",
    "exp = experiments[rho_to_plot]\n",
    "fits = exp[\"fits\"]\n",
    "X_train = exp[\"X_train\"]\n",
    "beta_true = exp[\"beta_true\"]\n",
    "\n",
    "# --- extract posterior draws for global/local scales and betas ---\n",
    "beta_gauss = fits['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "sigma_gauss = fits['Linreg Gaussian']['posterior'].stan_variable(\"sigma\")\n",
    "\n",
    "beta_RHS = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "sigma_RHS = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_RHS   = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_RHS = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "\n",
    "beta_DHS = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "sigma_DHS = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DHS   = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DHS = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_DHS     = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "beta_DST = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "sigma_DST = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DST   = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DST = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "xi_DST     = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "beta_BHS = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "sigma_BHS = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_BHS   = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_BHS = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_BHS     = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "beta_BST = fits['Linreg Beta Student T']['posterior'].stan_variable(\"beta\")\n",
    "sigma_BST = fits['Linreg Beta Student T']['posterior'].stan_variable(\"sigma\")\n",
    "tau_BST   = fits['Linreg Beta Student T']['posterior'].stan_variable(\"tau\")\n",
    "lambda_BST = fits['Linreg Beta Student T']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "xi_BST     = fits['Linreg Beta Student T']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "# GLS baseline\n",
    "beta_GLS = np.linalg.pinv(X_train.T @ X_train) @ (X_train.T @ exp[\"y_train\"])\n",
    "\n",
    "# infer dimensions\n",
    "S, p = beta_RHS.shape       # number of posterior draws, number of covariates\n",
    "N = X_train.shape[0]        # sample size used in the model\n",
    "\n",
    "# --- compute shrinkage factors kappa and effective parameters m_eff ---\n",
    "kappa_gauss = np.zeros((S, p))\n",
    "kappa_RHS = np.zeros((S, p))\n",
    "kappa_DHS = np.zeros((S, p))\n",
    "kappa_DST = np.zeros((S, p))\n",
    "kappa_BHS = np.zeros((S, p))\n",
    "kappa_BST = np.zeros((S, p))\n",
    "\n",
    "meff_gauss = np.zeros(S)\n",
    "meff_RHS = np.zeros(S)\n",
    "meff_DHS = np.zeros(S)\n",
    "meff_DST = np.zeros(S)\n",
    "meff_BHS = np.zeros(S)\n",
    "meff_BST = np.zeros(S)\n",
    "\n",
    "for i in range(S):\n",
    "     # RHS: kappa_j = 1 / (1 + N * sigma^-2 * tau^2 * lambda_j)\n",
    "    kappa_gauss[i] = 1.0 / (1.0 + N * sigma_gauss[i]**(-2))\n",
    "    \n",
    "    # RHS: kappa_j = 1 / (1 + N * sigma^-2 * tau^2 * lambda_j)\n",
    "    kappa_RHS[i] = 1.0 / (1.0 + N * sigma_RHS[i]**(-2) * tau_RHS[i]**2 * lambda_RHS[i])\n",
    "\n",
    "    # DHS: kappa_j = 1 / (1 + N * sigma^-2 * tau^2 * lambda_j * xi_j)\n",
    "    kappa_DHS[i] = 1.0 / (1.0 + N * sigma_DHS[i]**(-2) * tau_DHS[i]**2 * lambda_DHS[i] * xi_DHS[i])\n",
    "\n",
    "    # DST: same structure, but with DST parameters (note: tau_DST, not tau_DHS)\n",
    "    kappa_DST[i] = 1.0 / (1.0 + N * sigma_DST[i]**(-2) * tau_DST[i]**2 * lambda_DST[i] * xi_DST[i])\n",
    "    \n",
    "    # BHS: kappa_j = 1 / (1 + N * sigma^-2 * tau^2 * lambda_j * xi_j)\n",
    "    kappa_BHS[i] = 1.0 / (1.0 + N * sigma_BHS[i]**(-2) * tau_BHS[i]**2 * lambda_BHS[i] * xi_BHS[i])\n",
    "\n",
    "    # BST: same structure, but with DST parameters (note: tau_DST, not tau_DHS)\n",
    "    kappa_BST[i] = 1.0 / (1.0 + N * sigma_BST[i]**(-2) * tau_BST[i]**2 * lambda_BST[i] * xi_BST[i])\n",
    "\n",
    "    meff_gauss[i] = np.sum(1.0 - kappa_gauss[i])\n",
    "    meff_RHS[i] = np.sum(1.0 - kappa_RHS[i])\n",
    "    meff_DHS[i] = np.sum(1.0 - kappa_DHS[i])\n",
    "    meff_DST[i] = np.sum(1.0 - kappa_DST[i])\n",
    "    meff_BHS[i] = np.sum(1.0 - kappa_BHS[i])\n",
    "    meff_BST[i] = np.sum(1.0 - kappa_BST[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Indices of coefficients to visualize\n",
    "idxs = [0, 4, 5]\n",
    "\n",
    "# If you want to hard-code \"true\" betas, use this:\n",
    "beta_true_vals = {0: 3, 4: 0.2, 5: 0.0}\n",
    "titles = {\n",
    "    0: r\"$\\beta_1$\", #1: r\"$\\beta_2$\", \n",
    "    #2: r\"$\\beta_3$\", 3: r\"$\\beta_4$\", \n",
    "    4: r\"$\\beta_5$\", 5: r\"$\\beta_6$\"\n",
    "}\n",
    "\n",
    "def common_bins(*arrays, bins=40, range=None):\n",
    "    \"\"\"Compute common histogram bin edges for multiple arrays.\"\"\"\n",
    "    data = np.concatenate([a.ravel() for a in arrays])\n",
    "    return np.histogram_bin_edges(data, bins=bins, range=range)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(10, 8), sharex=False, sharey=False)\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax_kappa = axes[row, 1]\n",
    "    ax_beta  = axes[row, 0]\n",
    "\n",
    "    # --- Kappa posterior ---\n",
    "    bins_kappa = common_bins(kappa_gauss[:, j], kappa_RHS[:, j], kappa_DHS[:, j], kappa_DST[:, j],\n",
    "                              bins=40, range=(0, 1.0))\n",
    "    ax_kappa.hist(kappa_gauss[:, j], bins=bins_kappa, alpha=0.6, label=\"Gauss\", density=True, color = \"C0\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.hist(kappa_RHS[:, j], bins=bins_kappa, alpha=0.6, label=\"RHS\", density=True, color = \"C1\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.hist(kappa_DHS[:, j], bins=bins_kappa, alpha=0.6, label=\"DHS\", density=True, color = \"C2\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.hist(kappa_DST[:, j], bins=bins_kappa, alpha=0.6, label=\"DST\", density=True, color = \"C3\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.hist(kappa_BHS[:, j], bins=bins_kappa, alpha=0.6, label=\"BHS\", density=True, color = \"C4\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.hist(kappa_BST[:, j], bins=bins_kappa, alpha=0.6, label=\"BST\", density=True, color = \"C5\", histtype=\"step\", linewidth=2)\n",
    "    ax_kappa.set_xlabel(fr\"$\\kappa_{j+1}$\", fontsize=15)\n",
    "\n",
    "\n",
    "    # --- Beta posterior ---\n",
    "    bins_beta = common_bins(beta_gauss[:, j], beta_RHS[:, j], beta_DHS[:, j], beta_DST[:, j], bins=40)\n",
    "    x = np.linspace(bins_beta[0], bins_beta[-1], 500)\n",
    "    ax_beta.plot(x, gaussian_kde(beta_gauss[:, j], bw_method=0.25)(x), label=\"Gauss\")\n",
    "    ax_beta.plot(x, gaussian_kde(beta_RHS[:, j], bw_method=0.25)(x), label=\"RHS\", color=\"C1\")\n",
    "    ax_beta.plot(x, gaussian_kde(beta_DHS[:, j], bw_method=0.25)(x), label=\"DHS\", color=\"C2\")\n",
    "    ax_beta.plot(x, gaussian_kde(beta_DST[:, j], bw_method=0.25)(x), label=\"DST\", color=\"C3\")\n",
    "    ax_beta.plot(x, gaussian_kde(beta_BHS[:, j], bw_method=0.25)(x), label=\"BHS\", color=\"C4\")\n",
    "    ax_beta.plot(x, gaussian_kde(beta_BST[:, j], bw_method=0.25)(x), label=\"BST\", color=\"C5\")\n",
    "\n",
    "\n",
    "    ax_beta.axvline(beta_true_vals[j], alpha=0.9, label=\"w true\", color=\"black\", linestyle=\"--\")\n",
    "    ax_beta.axvline(beta_GLS[j], alpha=0.9, label=\"w GLS\", color=\"purple\", linestyle=\":\")\n",
    "    ax_beta.set_xlabel(fr\"$w_{j+1}$\", fontsize=15)\n",
    "    ax_beta.set_ylabel(\"Density\", fontsize=15)\n",
    "    #ax_beta.set_title(f\"Beta, {titles[j]}\")\n",
    "\n",
    "# One legend for beta panels\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(handles, labels, loc=\"upper center\", ncol=3, bbox_to_anchor=(0.45, 1))\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.93])\n",
    "fig.savefig(\"figures_for_use_in_paper/w_vs_kappa.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------\n",
    "# 2) Plot posterior distribution of effective parameters\n",
    "# ------------------------------------------------------\n",
    "\n",
    "P = p\n",
    "bins = np.linspace(2, 10, 30)#np.arange(0, P + 2) - 0.1  # bin edges at integers\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "# Use plt.hist to keep dependencies minimal\n",
    "plt.hist(meff_gauss, bins=bins, density=True, alpha=0.6, label=\"Gauss\", histtype=\"stepfilled\")\n",
    "plt.hist(meff_RHS, bins=bins, density=True, alpha=0.6, label=\"RHS\", histtype=\"stepfilled\")\n",
    "plt.hist(meff_DHS, bins=bins, density=True, alpha=0.6, label=\"DHS\", histtype=\"stepfilled\")\n",
    "plt.hist(meff_DST, bins=bins, density=True, alpha=0.6, label=\"DST\", histtype=\"stepfilled\")\n",
    "plt.hist(meff_BHS, bins=bins, density=True, alpha=0.6, label=\"BHS\", histtype=\"stepfilled\")\n",
    "plt.hist(meff_BST, bins=bins, density=True, alpha=0.6, label=\"BST\", histtype=\"stepfilled\")\n",
    "\n",
    "# vertical line at true number of active coefficients\n",
    "true_active = 4  # adjust if needed\n",
    "plt.axvline(true_active, color=\"black\", linestyle=\"--\", linewidth=1.5,\n",
    "            label=f\"True active = {true_active}\")\n",
    "\n",
    "# add posterior means as vertical lines + text\n",
    "ymax = plt.ylim()[1]\n",
    "for Meff, label, color in [\n",
    "    (meff_gauss, \"Gauss\", \"C0\"),\n",
    "    (meff_RHS, \"RHS\", \"C1\"),\n",
    "    (meff_DHS, \"DHS\", \"C2\"),\n",
    "    (meff_DST, \"DST\", \"C3\"),\n",
    "    (meff_BHS, \"BHS\", \"C4\"),\n",
    "    (meff_BST, \"BST\", \"C5\"),\n",
    "]:\n",
    "    mean_val = np.mean(Meff)\n",
    "    plt.axvline(mean_val, color=color, linestyle=\":\", linewidth=1.5)\n",
    "    plt.text(mean_val + 0.1, ymax * 0.8,\n",
    "             f\"{label} mean={mean_val:.1f}\",\n",
    "             color=\"black\", fontsize=9, rotation=90, va=\"top\")\n",
    "\n",
    "plt.xticks(range(0, P + 1))\n",
    "plt.xlabel(r\"Effective number of parameters $m_{\\mathrm{eff}}$\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(fr\"Posterior samples of effective parameters, $\\rho={rho_to_plot}$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXING PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model_names = [\n",
    "    \"Linreg Gaussian\",\n",
    "    \"Linreg Regularized Horseshoe\",\n",
    "    \"Linreg Dirichlet Horseshoe\",\n",
    "    \"Linreg Dirichlet Student T\",\n",
    "    \"Linreg Beta Horseshoe\",\n",
    "    \"Linreg Beta Student T\",\n",
    "]\n",
    "\n",
    "def beta_to_long_df(beta_array, model_name, rho, beta_true):\n",
    "    \"\"\"\n",
    "    beta_array: (S, P)\n",
    "    returns DataFrame with columns: rho, model, draw, coeff, beta, beta_true\n",
    "    \"\"\"\n",
    "    S, P = beta_array.shape\n",
    "    df = pd.DataFrame(\n",
    "        beta_array.reshape(S * P),\n",
    "        columns=[\"beta\"]\n",
    "    )\n",
    "    df[\"draw\"] = np.repeat(np.arange(S), P)\n",
    "    df[\"coeff\"] = np.tile(np.arange(P), S)\n",
    "    df[\"model\"] = model_name\n",
    "    df[\"rho\"] = rho\n",
    "    # attach true beta per coefficient\n",
    "    beta_true_series = pd.Series(beta_true, index=np.arange(len(beta_true)))\n",
    "    df[\"beta_true\"] = df[\"coeff\"].map(beta_true_series)\n",
    "    return df\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for rho, exp in experiments.items():\n",
    "    fits = exp[\"fits\"]\n",
    "    beta_true = exp[\"beta_true\"]\n",
    "\n",
    "    beta_gauss = fits['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "    beta_RHS   = fits['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_DHS   = fits['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_DST   = fits['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "    beta_BHS   = fits['Linreg Beta Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "    beta_BST   = fits['Linreg Beta Student T']['posterior'].stan_variable(\"beta\")\n",
    "\n",
    "    all_dfs.append(beta_to_long_df(beta_gauss, \"Gauss\",             rho, beta_true))\n",
    "    all_dfs.append(beta_to_long_df(beta_RHS,   \"RHS\",       rho, beta_true))\n",
    "    all_dfs.append(beta_to_long_df(beta_DHS,   \"DHS\",         rho, beta_true))\n",
    "    all_dfs.append(beta_to_long_df(beta_DST,   \"DST\",  rho, beta_true))\n",
    "    all_dfs.append(beta_to_long_df(beta_BHS,   \"BHS\",         rho, beta_true))\n",
    "    all_dfs.append(beta_to_long_df(beta_BST,   \"BST\",  rho, beta_true))\n",
    "\n",
    "beta_all = pd.concat(all_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# coefficients to visualize\n",
    "coeffs_to_plot = [0, 1, 2, 3, 4, 5]   # β1,…,β6\n",
    "rows, cols = 2, 3\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 8), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, j in enumerate(coeffs_to_plot):\n",
    "    ax = axes[idx]\n",
    "    df_j = beta_all[beta_all[\"coeff\"] == j].copy()\n",
    "\n",
    "    # nice ordering for models and rho\n",
    "    df_j[\"model\"] = pd.Categorical(\n",
    "        df_j[\"model\"],\n",
    "        categories=[\"Gauss\", \"RHS\", \"DHS\", \"DST\", \"BHS\", \"BST\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "    df_j[\"rho\"] = df_j[\"rho\"].astype(float)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_j,\n",
    "        x=\"model\",\n",
    "        y=\"beta\",\n",
    "        hue=\"rho\",\n",
    "        ax=ax,\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    # true beta line\n",
    "    beta_true_j = df_j[\"beta_true\"].iloc[0]\n",
    "    ax.axhline(beta_true_j, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(fr\"$w_{{{j+1}}}$\", fontsize=15, rotation=0, labelpad=15)\n",
    "    #ax.set_title(fr\"$w_{{{j+1}}}$\", fontsize=11)\n",
    "    ax.tick_params(axis=\"x\", rotation=20, labelsize=13)\n",
    "\n",
    "# remove extra axes if any\n",
    "for k in range(len(coeffs_to_plot), len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "# one legend for the whole figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title=r\"$\\rho$\", loc=\"upper center\", bbox_to_anchor=(0.5, 1.0), ncol=3)\n",
    "for ax in axes:\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "#fig.suptitle(r\"Posterior distributions of $w_j$ by prior and correlation $\\rho$\", fontsize=13)\n",
    "fig.tight_layout(rect=[0, 0.3, 1, 0.95])\n",
    "fig.savefig(\"figures_for_use_in_paper/w_distribution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploartory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta, dirichlet, norm\n",
    "import seaborn as sns\n",
    "\n",
    "# --- scale parameter ---\n",
    "p=10\n",
    "alpha = 0.1\n",
    "alpha_vec = [alpha, alpha, alpha, alpha, alpha, alpha, alpha, alpha, alpha, alpha]\n",
    "samples_A = dirichlet.rvs(alpha = alpha_vec, size=10000)\n",
    "samples_B = beta.rvs(a = alpha, b = (p-1)*alpha, size=(10000, 10))\n",
    "\n",
    "# --- 2-dim joint contour KDE for Dirichlet vs Beta ---\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.kdeplot(\n",
    "    x=samples_A[:, 0],\n",
    "    y=samples_A[:, 1],\n",
    "    levels=5,\n",
    "    cmap=\"Reds\",\n",
    "    linewidths=2.0,\n",
    "    label=\"Dirichlet\"\n",
    ")\n",
    "sns.kdeplot(\n",
    "    x=samples_B[:, 0],\n",
    "    y=samples_B[:, 1],\n",
    "    levels=5,\n",
    "    cmap=\"Blues\",\n",
    "    linewidths=2.0,\n",
    "    label=\"Beta\"\n",
    ")\n",
    "plt.title(\"Joint density of (x₁, x₂): Dirichlet vs independent Beta\")\n",
    "plt.xlabel(\"x₁\")\n",
    "plt.ylabel(\"x₂\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta, dirichlet, norm\n",
    "\n",
    "# --- scale parameter ---\n",
    "p = 10\n",
    "alpha = 0.1\n",
    "alpha_vec = [alpha] * p\n",
    "\n",
    "# 1000 draws of 10-dim Dirichlet and independent Betas\n",
    "samples_A = dirichlet.rvs(alpha=alpha_vec, size=1000)               # shape (1000, 10)\n",
    "samples_B = beta.rvs(a=alpha, b=(p-1)*alpha, size=(1000, p))       # shape (1000, 10)\n",
    "\n",
    "# Convert \"variance\" factors into std deviations for the normals\n",
    "std_A = np.sqrt(samples_A)   # same shape (1000, 10)\n",
    "std_B = np.sqrt(samples_B)   # same shape (1000, 10)\n",
    "\n",
    "# Draw normals with variance given by samples_A / samples_B\n",
    "# np.random.normal broadcasts over the array of stds\n",
    "norm_A = np.random.normal(loc=0.0, scale=std_A)   # shape (1000, 10)\n",
    "norm_B = np.random.normal(loc=0.0, scale=std_B)   # shape (1000, 10)\n",
    "\n",
    "print(norm_A.shape, norm_B.shape)\n",
    "# -> (1000, 10) (1000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between coordinates for the *scales* themselves\n",
    "corr_xi_dir = np.corrcoef(samples_A, rowvar=False)   # 10x10\n",
    "corr_xi_beta = np.corrcoef(samples_B, rowvar=False)  # 10x10\n",
    "\n",
    "# Correlation between coordinates for the *normals*\n",
    "corr_norm_dir = np.corrcoef(norm_A, rowvar=False)    # 10x10\n",
    "corr_norm_beta = np.corrcoef(norm_B, rowvar=False)   # 10x10\n",
    "\n",
    "print(\"Mean off-diagonal corr (Dirichlet scales):\", \n",
    "      (corr_xi_dir - np.eye(p))[np.triu_indices(p, 1)].mean())\n",
    "print(\"Mean off-diagonal corr (Beta scales):\", \n",
    "      (corr_xi_beta - np.eye(p))[np.triu_indices(p, 1)].mean())\n",
    "\n",
    "print(\"Mean off-diagonal corr (Dirichlet normals):\", \n",
    "      (corr_norm_dir - np.eye(p))[np.triu_indices(p, 1)].mean())\n",
    "print(\"Mean off-diagonal corr (Beta normals):\", \n",
    "      (corr_norm_beta - np.eye(p))[np.triu_indices(p, 1)].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper to extract average off-diagonal correlation ---\n",
    "def offdiag_mean_corr(M):\n",
    "    return (M - np.eye(M.shape[0]))[np.triu_indices(M.shape[0], 1)].mean()\n",
    "\n",
    "# --- investigate dependence in magnitudes and higher moments ---\n",
    "\n",
    "# 1. Correlation of |x|, x^2, x^3 for normals from Dirichlet scales\n",
    "corr_abs_A = np.corrcoef(np.abs(norm_A), rowvar=False)\n",
    "corr_sq_A  = np.corrcoef(norm_A**2,      rowvar=False)\n",
    "corr_cu_A  = np.corrcoef(norm_A**4,      rowvar=False)\n",
    "\n",
    "# 2. Same for normals from Beta scales (should be ~0)\n",
    "corr_abs_B = np.corrcoef(np.abs(norm_B), rowvar=False)\n",
    "corr_sq_B  = np.corrcoef(norm_B**2,      rowvar=False)\n",
    "corr_cu_B  = np.corrcoef(norm_B**4,      rowvar=False)\n",
    "\n",
    "print(\"Dirichlet scales → normals:\")\n",
    "print(\"  mean corr(|x|):\", offdiag_mean_corr(corr_abs_A))\n",
    "print(\"  mean corr(x^2):\", offdiag_mean_corr(corr_sq_A))\n",
    "print(\"  mean corr(x^4):\", offdiag_mean_corr(corr_cu_A))\n",
    "\n",
    "print(\"\\nIndependent Beta scales → normals:\")\n",
    "print(\"  mean corr(|x|):\", offdiag_mean_corr(corr_abs_B))\n",
    "print(\"  mean corr(x^2):\", offdiag_mean_corr(corr_sq_B))\n",
    "print(\"  mean corr(x^4):\", offdiag_mean_corr(corr_cu_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_linreg_dataset, generate_linreg_simple_data\n",
    "rho=0.9\n",
    "X_train, X_test, y_train, y_test, _, _, _ = load_linreg_dataset(\n",
    "    path=f\"datasets/linreg/linreg_data_rho_{rho}.npz\",\n",
    "    test_fraction=0.2,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "_, _, beta_true = generate_linreg_simple_data(rho=rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/linreg\"\n",
    "results_dir_linreg = \"results/regression/linreg/high_corr\"\n",
    "#results_dir_linreg_prior = \"results/regression/linreg/prior\"\n",
    "#model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names = [\"Linreg Gaussian\", \"Linreg Regularized Horseshoe\", \"Linreg Dirichlet Horseshoe\", \"Linreg Dirichlet Student T\"]\n",
    "\n",
    "\n",
    "full_config_path = f\"linreg_N200_p10_rho_{rho}\"\n",
    "linreg_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_linreg,\n",
    "    models=model_names,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "beta_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "beta_GLS = np.linalg.pinv((X_train.T@X_train))@X_train.T@y_train\n",
    "\n",
    "posterior_mean_rmse_gauss = np.sqrt(np.mean((y_test - X_test@np.mean(beta_gauss, axis=0))**2))\n",
    "posterior_mean_rmse_RHS = np.sqrt(np.mean((y_test - X_test@np.mean(beta_RHS, axis=0))**2))\n",
    "posterior_mean_rmse_DHS = np.sqrt(np.mean((y_test - X_test@np.mean(beta_DHS, axis=0))**2))\n",
    "posterior_mean_rmse_DST = np.sqrt(np.mean((y_test - X_test@np.mean(beta_DST, axis=0))**2))\n",
    "rmse_GLS = np.sqrt(np.mean((y_test - X_test@beta_GLS)**2))\n",
    "\n",
    "print(\"Gauss:\", posterior_mean_rmse_gauss,\n",
    "      \"\\nRHS:\", posterior_mean_rmse_RHS, \n",
    "      \"\\nDHS\", posterior_mean_rmse_DHS, \n",
    "      \"\\nDST\", posterior_mean_rmse_DST,\n",
    "      \"\\nGLS:\", rmse_GLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Make sure y_train is 1D shape (N,)\n",
    "y_vec = np.asarray(y_test).reshape(-1)\n",
    "N = X_train.shape[0]\n",
    "\n",
    "def rmse_per_sample(beta_samples, X, y):\n",
    "    \"\"\"\n",
    "    beta_samples: (S, P)\n",
    "    X: (N, P)\n",
    "    y: (N,)\n",
    "    Returns: array (S,) of RMSEs, one per posterior draw\n",
    "    \"\"\"\n",
    "    # Predictions for all samples at once: (N, S)\n",
    "    preds = X @ beta_samples.T\n",
    "    # Broadcast y to (N, S)\n",
    "    errors = preds - y[:, None]\n",
    "    mse = np.mean(errors**2, axis=0)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "rmse_gauss_samps = rmse_per_sample(beta_gauss, X_test, y_vec)\n",
    "rmse_RHS_samps   = rmse_per_sample(beta_RHS,   X_test, y_vec)\n",
    "rmse_DHS_samps   = rmse_per_sample(beta_DHS,   X_test, y_vec)\n",
    "rmse_DST_samps   = rmse_per_sample(beta_DST,   X_test, y_vec)\n",
    "\n",
    "\n",
    "# -------- Density plot of RMSEs --------\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "def plot_rmse_kde(rmse_samples, label, posterior_mean_rmse, color):\n",
    "    kde = gaussian_kde(rmse_samples)\n",
    "    xs = np.linspace(np.percentile(rmse_samples, 1),\n",
    "                     np.percentile(rmse_samples, 99), 200)\n",
    "    plt.plot(xs, kde(xs), label=label, color=color)\n",
    "    plt.axvline(x=posterior_mean_rmse, color=color, linestyle=\"--\")\n",
    "    plt.axvline(x=np.mean(rmse_samples), color=color, linestyle=\"-\")\n",
    "\n",
    "plot_rmse_kde(rmse_gauss_samps, \"Gaussian\", posterior_mean_rmse_gauss, \"C0\")\n",
    "plot_rmse_kde(rmse_RHS_samps,   \"RHS\", posterior_mean_rmse_RHS, \"C1\")\n",
    "plot_rmse_kde(rmse_DHS_samps,   \"DHS\", posterior_mean_rmse_DHS, \"C2\")\n",
    "plot_rmse_kde(rmse_DST_samps,   \"DST\", posterior_mean_rmse_DST, \"C3\")\n",
    "\n",
    "plt.axvline(x=rmse_GLS, label=\"GLS\", color=\"black\", linestyle=\"dotted\")\n",
    "plt.xlabel(\"RMSE on training data\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(\"Posterior distribution of RMSE per model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S, P = beta_gauss.shape  # number of draws, number of coefficients\n",
    "# Put all draws into one long DataFrame\n",
    "def beta_to_long_df(beta_array, model_name):\n",
    "    \"\"\"\n",
    "    beta_array: (S, P)\n",
    "    returns DataFrame with columns: model, draw, coeff, beta\n",
    "    \"\"\"\n",
    "    S, P = beta_array.shape\n",
    "    df = pd.DataFrame(\n",
    "        beta_array.reshape(S * P),\n",
    "        columns=[\"beta\"]\n",
    "    )\n",
    "    df[\"draw\"] = np.repeat(np.arange(S), P)\n",
    "    df[\"coeff\"] = np.tile(np.arange(P), S)\n",
    "    df[\"model\"] = model_name\n",
    "    return df\n",
    "\n",
    "df_gauss = beta_to_long_df(beta_gauss, \"Gaussian\")\n",
    "df_RHS   = beta_to_long_df(beta_RHS,   \"Regularized Horseshoe\")\n",
    "df_DHS   = beta_to_long_df(beta_DHS,   \"Dirichlet Horseshoe\")\n",
    "df_DST   = beta_to_long_df(beta_DST,   \"Dirichlet Student-t\")\n",
    "\n",
    "beta_df = pd.concat([df_gauss, df_RHS, df_DHS, df_DST], ignore_index=True)\n",
    "\n",
    "# Optional: attach true beta if you have it loaded from the dataset\n",
    "if \"beta_true\" in globals():\n",
    "    beta_true_series = pd.Series(beta_true, index=np.arange(len(beta_true)))\n",
    "    beta_df[\"beta_true\"] = beta_df[\"coeff\"].map(beta_true_series)\n",
    "else:\n",
    "    beta_true_series = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot per coefficient, grouped by model\n",
    "fig, axes = plt.subplots(5, int(np.ceil(P / 5)), figsize=(16, 16), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for j in range(P):\n",
    "    ax = axes[j]\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "    # Make a simple boxplot of posterior for beta_j under each model\n",
    "    data = [df_j[df_j[\"model\"] == m][\"beta\"].values\n",
    "            for m in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student-t\"]]\n",
    "    ax.boxplot(data, showfliers=False)\n",
    "    ax.set_xticks([1, 2, 3, 4])\n",
    "    ax.set_xticklabels([\"Gauss\", \"RHS\", \"DHS\", \"DST\"], rotation=30)\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "\n",
    "    # If true beta is known, add a horizontal line\n",
    "    if beta_true_series is not None:\n",
    "        ax.axhline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Hide unused axes if P is odd\n",
    "for k in range(P, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Posterior distributions of β_j by prior (boxplots)\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_beta_kde_for_coeff(j, ax):\n",
    "    \"\"\"\n",
    "    j: coefficient index\n",
    "    ax: matplotlib axis\n",
    "    \"\"\"\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "\n",
    "    for model_name, label in [\n",
    "        (\"Gaussian\", \"Gauss\"),\n",
    "        (\"Regularized Horseshoe\", \"RHS\"),\n",
    "        (\"Dirichlet Horseshoe\", \"DHS\"),\n",
    "        (\"Dirichlet Student-t\", \"DST\"),\n",
    "    ]:\n",
    "        samples = df_j[df_j[\"model\"] == model_name][\"beta\"].values\n",
    "        kde = gaussian_kde(samples)\n",
    "        xs = np.linspace(np.percentile(samples, 1),\n",
    "                         np.percentile(samples, 99), 200)\n",
    "        ax.plot(xs, kde(xs), label=label, alpha=0.8)\n",
    "\n",
    "    if beta_true_series is not None:\n",
    "        ax.axvline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Choose which coefficients to inspect more closely\n",
    "coeffs_to_plot = [0, 1, 2, 3, 4, 5]  # likely non-zero in your synthetic setup\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, j in enumerate(coeffs_to_plot):\n",
    "    plot_beta_kde_for_coeff(j, axes[idx])\n",
    "\n",
    "fig.suptitle(\"Marginal posterior densities of selected β_j\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "sigma_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "\n",
    "sigma_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "sigma_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "xi_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"phi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, N, p = 4000, 200, 10\n",
    "\n",
    "kappa_RHS = np.zeros((S, p))\n",
    "kappa_DHS = np.zeros((S, p))\n",
    "kappa_DST = np.zeros((S, p))\n",
    "\n",
    "meff_RHS = np.zeros((S))\n",
    "meff_DHS = np.zeros((S))\n",
    "meff_DST = np.zeros((S))\n",
    "\n",
    "for i in range(S):\n",
    "    kappa_RHS[i] = 1/(1+(N*sigma_RHS[i]**(-2)*tau_RHS[i]**2*lambda_RHS[i]))\n",
    "    kappa_DHS[i] = 1/(1+(N*sigma_DHS[i]**(-2)*tau_DHS[i]**2*lambda_DHS[i]*xi_DHS[i]))\n",
    "    kappa_DST[i] = 1/(1+(N*sigma_DST[i]**(-2)*tau_DST[i]**2*lambda_DST[i]*xi_DST[i]))\n",
    "    \n",
    "    meff_RHS[i] = np.sum(1 - kappa_RHS[i])\n",
    "    meff_DHS[i] = np.sum(1 - kappa_DHS[i])\n",
    "    meff_DST[i] = np.sum(1 - kappa_DST[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S, p = 4000, 10  # as before\n",
    "\n",
    "# Indices of coefficients to visualize\n",
    "idxs = [0, 1, 2, 3, 4, 5]\n",
    "beta_true_vals = {0: 3, 1: -2, 2: 1.5, 3:0.8, 4:0.2, 5:0.0}   # your ground truth\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\", 3: r\"$\\beta_4$\", 4: r\"$\\beta_5$\", 5: r\"$\\beta_6$\"}  # optional niceness\n",
    "\n",
    "def common_bins(*arrays, bins=40, range=None):\n",
    "    \"\"\"Compute common histogram bin edges for multiple arrays.\"\"\"\n",
    "    data = np.concatenate([a.ravel() for a in arrays])\n",
    "    return np.histogram_bin_edges(data, bins=bins, range=range)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(8, 12), sharex=False, sharey=\"row\")\n",
    "fig.suptitle(\"Posterior distributions of shrinkage ($\\\\kappa$) and coefficients ($\\\\beta$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax_kappa = axes[row, 0]\n",
    "    ax_beta  = axes[row, 1]\n",
    "\n",
    "    # --- Kappa posterior ---\n",
    "    bins_kappa = common_bins(kappa_RHS[:, j], kappa_DHS[:, j], kappa_DST[:, j], bins=40, range=(0, 1.0))\n",
    "    ax_kappa.hist(kappa_RHS[:, j], bins=bins_kappa, alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax_kappa.hist(kappa_DHS[:, j], bins=bins_kappa, alpha=0.6, label=\"DHS\", density=True)\n",
    "    ax_kappa.hist(kappa_DST[:, j], bins=bins_kappa, alpha=0.6, label=\"DST\", density=True)\n",
    "    ax_kappa.set_xlabel(r\"$\\kappa$\")\n",
    "    ax_kappa.set_ylabel(\"Density\" if row == 0 else \"\")\n",
    "    ax_kappa.set_title(f\"Kappa, {titles[j]}\")\n",
    "\n",
    "    # --- Beta posterior ---\n",
    "    bins_beta = common_bins(beta_RHS[:, j], beta_DHS[:, j], bins=40)  # auto range\n",
    "    ax_beta.hist(beta_RHS[:, j], bins=bins_beta, alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax_beta.hist(beta_DHS[:, j], bins=bins_beta, alpha=0.6, label=\"DHS\", density=True)\n",
    "    ax_beta.hist(beta_DST[:, j], bins=bins_beta, alpha=0.6, label=\"DHS\", density=True)\n",
    "\n",
    "    # Add true and GLS lines\n",
    "    ax_beta.axvline(beta_true_vals[j], alpha=0.9, label=\"Beta_true\", color=\"green\", linestyle=\"--\")\n",
    "    ax_beta.axvline(beta_GLS[j], alpha=0.9, label=\"Beta_GLS\", color=\"red\", linestyle=\":\")\n",
    "    ax_beta.set_xlabel(r\"$\\beta$\")\n",
    "    ax_beta.set_title(f\"Beta, {titles[j]}\")\n",
    "\n",
    "# Put a single legend outside\n",
    "handles, labels = axes[0, 1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "P = 10  # number of covariates\n",
    "bins = np.arange(0, P + 2) - 0.5  # bin edges at integers\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "sns.histplot(meff_RHS, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"RHS\")\n",
    "sns.histplot(meff_DHS, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"DHS\")\n",
    "sns.histplot(meff_DST, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"DST\")\n",
    "\n",
    "# vertical line at true number of active coefficients\n",
    "plt.axvline(4, color=\"black\", linestyle=\"--\", linewidth=1.5,\n",
    "            label=\"True active = 4\")\n",
    "\n",
    "# add posterior means as markers\n",
    "for Meff, label, color in [\n",
    "    (meff_RHS, \"RHS\", \"C0\"),\n",
    "    (meff_DHS, \"DHS\", \"C1\"),\n",
    "    (meff_DST, \"DST\", \"C2\"),\n",
    "]:\n",
    "    mean_val = np.mean(Meff)\n",
    "    plt.axvline(mean_val, color=color, linestyle=\":\",\n",
    "                linewidth=1.5)\n",
    "    plt.text(mean_val + 0.1, plt.ylim()[1]*0.8,\n",
    "             f\"{label} mean={mean_val:.1f}\",\n",
    "             color=\"black\", fontsize=9, rotation=90, va=\"top\")\n",
    "\n",
    "plt.xticks(range(0, P + 1))\n",
    "plt.xlabel(r\"Effective number of parameters $m_{\\mathrm{eff}}$\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(\"Posterior distribution of effective parameters\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(7, 9), sharex=True)\n",
    "fig.suptitle(r\"Joint posterior of ($\\kappa_j$, $\\beta_j$) for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "    ax.scatter(kappa_RHS[:, j], beta_RHS[:, j],\n",
    "               alpha=0.2, s=8, label=\"RHS\")\n",
    "    ax.scatter(kappa_DHS[:, j], beta_DHS[:, j],\n",
    "               alpha=0.2, s=8, label=\"DHS\")\n",
    "    ax.scatter(kappa_DST[:, j], beta_DST[:, j],\n",
    "               alpha=0.2, s=8, label=\"DST\")\n",
    "    ax.axhline(y=beta_true_vals[j])\n",
    "\n",
    "    #ax.set_title(titles[j])\n",
    "    ax.set_ylabel(titles[j])\n",
    "    if row == len(idxs) - 1:\n",
    "        ax.set_xlabel(r\"$\\kappa_j$\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "sigma_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "\n",
    "sigma_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, p = 4000, 10\n",
    "\n",
    "kappa_RHS_prior = np.zeros((S, p))\n",
    "kappa_DHS_prior = np.zeros((S, p))\n",
    "\n",
    "for i in range(S):\n",
    "    kappa_RHS_prior[i] = 1/(1+(sigma_RHS_prior[i]**2*tau_RHS_prior[i]**2*lambda_RHS_prior[i]))\n",
    "    kappa_DHS_prior[i] = 1/(1+(sigma_DHS_prior[i]**2*tau_DHS_prior[i]**2*lambda_DHS_prior[i]*xi_DHS_prior[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(8, 7), sharex=True, sharey=True)\n",
    "fig.suptitle(\"Prior distributions of shrinkage ($\\\\kappa$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "\n",
    "    bins_kappa_prior = common_bins(\n",
    "        kappa_RHS_prior[:, j],\n",
    "        kappa_DHS_prior[:, j],\n",
    "        bins=40,\n",
    "        range=(0, 0.3)\n",
    "    )\n",
    "\n",
    "    ax.hist(kappa_RHS_prior[:, j], bins=bins_kappa_prior,\n",
    "            alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax.hist(kappa_DHS_prior[:, j], bins=bins_kappa_prior,\n",
    "            alpha=0.6, label=\"DHS\", density=True)\n",
    "\n",
    "    ax.set_xlim(0, 0.2)  # focus on strong shrinkage region\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(f\"Prior kappa, {titles[j]}\")\n",
    "\n",
    "axes[-1].set_xlabel(r\"$\\kappa$\")\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RHS\", \"DHS\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), len(models),\n",
    "                         figsize=(10, 8),\n",
    "                         sharex=True, sharey=True)\n",
    "fig.suptitle(\"Prior vs posterior shrinkage ($\\\\kappa$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    for col, model in enumerate(models):\n",
    "        ax = axes[row, col] if len(idxs) > 1 else axes[col]\n",
    "\n",
    "        if model == \"RHS\":\n",
    "            prior = kappa_RHS_prior[:, j]\n",
    "            post  = kappa_RHS[:, j]\n",
    "        else:  # \"DHS\"\n",
    "            prior = kappa_DHS_prior[:, j]\n",
    "            post  = kappa_DHS[:, j]\n",
    "\n",
    "        # Common bins for fair comparison\n",
    "        bins_kappa = common_bins(prior, post, bins=40, range=(0, 1.0))\n",
    "\n",
    "        ax.hist(prior, bins=bins_kappa, alpha=0.5, density=True, label=\"Prior\")\n",
    "        ax.hist(post,  bins=bins_kappa, alpha=0.5, density=True, label=\"Posterior\")\n",
    "\n",
    "        ax.set_xlim(0, 1.0)\n",
    "        if row == len(idxs) - 1:\n",
    "            ax.set_xlabel(r\"$\\kappa$\")\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Density\")\n",
    "\n",
    "        ax.set_title(f\"{model}, {titles[j]}\")\n",
    "\n",
    "# One shared legend\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "phi_prior = xi_DHS_prior  # (S, p)\n",
    "phi_post  = xi_DHS        # (S, p)\n",
    "\n",
    "p = phi_prior.shape[1]\n",
    "j_idx = np.arange(p)\n",
    "\n",
    "prior_mean = phi_prior.mean(axis=0)\n",
    "post_mean  = phi_post.mean(axis=0)\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(j_idx - width/2, prior_mean, width=width, label=\"Prior\", alpha=0.7)\n",
    "plt.bar(j_idx + width/2, post_mean,  width=width, label=\"Posterior\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Predictor index j\")\n",
    "plt.ylabel(r\"Mean $\\xi_j$\")\n",
    "plt.title(r\"Dirichlet weights $\\xi_j$: prior vs posterior\")\n",
    "plt.xticks(j_idx)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [0, 1, 2]  # or whatever indices you care about\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\"}  # optional\n",
    "\n",
    "def common_bins(*arrays, bins=40, rng=None):\n",
    "    data = np.concatenate([a.ravel() for a in arrays])\n",
    "    return np.histogram_bin_edges(data, bins=bins, range=rng)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(8, 8), sharex=True, sharey=True)\n",
    "fig.suptitle(r\"Prior vs posterior distributions of $\\xi_j$ (DHS)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "\n",
    "    prior_j = phi_prior[:, j]\n",
    "    post_j  = phi_post[:, j]\n",
    "\n",
    "    bins = common_bins(prior_j, post_j, bins=40, rng=(0, 1))\n",
    "\n",
    "    ax.hist(prior_j, bins=bins, alpha=0.5, density=True, label=\"Prior\")\n",
    "    ax.hist(post_j,  bins=bins, alpha=0.5, density=True, label=\"Posterior\")\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(fr\"$\\xi_{{{j+1}}}$ ({titles.get(j, f'j={j}')})\")\n",
    "\n",
    "axes[-1].set_xlabel(r\"$\\xi_j$\")\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_RHS     = linreg_fit['Linreg Regularized Horseshoe Centered']['posterior'].stan_variable(\"beta\")\n",
    "beta_sd_RHS  = linreg_fit['Linreg Regularized Horseshoe Centered']['posterior'].stan_variable(\"beta_sd\")\n",
    "\n",
    "beta_DHS     = linreg_fit['Linreg Dirichlet Horseshoe Centered']['posterior'].stan_variable(\"beta\")\n",
    "beta_sd_DHS  = linreg_fit['Linreg Dirichlet Horseshoe Centered']['posterior'].stan_variable(\"beta_sd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "idxs   = [0, 1, 2, 7]  # whatever you like\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\", 7: r\"$\\beta_8$\"}\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(10, 10), sharex=True, sharey='row')\n",
    "fig.suptitle(r\"Posterior scales: $\\log \\beta_{\\text{sd},j}$ for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    # RHS\n",
    "    ax_rhs = axes[row, 0]\n",
    "    log_sd_rhs = (beta_sd_RHS[:, j] + eps)\n",
    "    ax_rhs.hist(log_sd_rhs, bins=40, density=True, alpha=0.7)\n",
    "    ax_rhs.set_title(f\"RHS, {titles[j]}\")\n",
    "    ax_rhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "    ax_rhs.set_ylabel(\"Density\")\n",
    "\n",
    "    # DHS\n",
    "    ax_dhs = axes[row, 1]\n",
    "    log_sd_dhs = (beta_sd_DHS[:, j] + eps)\n",
    "    ax_dhs.hist(log_sd_dhs, bins=40, density=True, alpha=0.7, color=\"tab:orange\")\n",
    "    ax_dhs.set_title(f\"DHS, {titles[j]}\")\n",
    "    ax_dhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(10, 10), sharex=True, sharey='row')\n",
    "fig.suptitle(r\"Joint posterior: $(\\log \\beta_{\\text{sd},j}, \\beta_j)$\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    # RHS\n",
    "    ax_rhs = axes[row, 0]\n",
    "    log_sd_rhs = np.log(beta_sd_RHS[:, j] + eps)\n",
    "    ax_rhs.scatter(log_sd_rhs, beta_RHS[:, j], alpha=0.2, s=8)\n",
    "    ax_rhs.set_title(f\"RHS, {titles[j]}\")\n",
    "    ax_rhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "    ax_rhs.set_ylabel(r\"$\\beta_j$\")\n",
    "\n",
    "    # DHS\n",
    "    ax_dhs = axes[row, 1]\n",
    "    log_sd_dhs = np.log(beta_sd_DHS[:, j] + eps)\n",
    "    ax_dhs.scatter(log_sd_dhs, beta_DHS[:, j], alpha=0.2, s=8, color=\"tab:orange\")\n",
    "    ax_dhs.set_title(f\"DHS, {titles[j]}\")\n",
    "    ax_dhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want κ ignoring sigma (pure coef shrinkage):\n",
    "kappa_RHS = 1 / (1 + beta_sd_RHS**2)\n",
    "kappa_DHS = 1 / (1 + beta_sd_DHS**2)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(7, 9), sharex=True)\n",
    "fig.suptitle(r\"Joint posterior of $(\\kappa_j, \\beta_j)$ for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "    ax.scatter(kappa_RHS[:, j], beta_RHS[:, j], alpha=0.2, s=8, label=\"RHS\")\n",
    "    ax.scatter(kappa_DHS[:, j], beta_DHS[:, j], alpha=0.2, s=8, label=\"DHS\")\n",
    "    ax.set_title(titles[j])\n",
    "    ax.set_ylabel(r\"$\\beta_j$\")\n",
    "    if row == len(idxs) - 1:\n",
    "        ax.set_xlabel(r\"$\\kappa_j$\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
