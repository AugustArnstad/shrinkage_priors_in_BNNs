{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "N = 250              # slightly larger sample\n",
    "P = 10               # fixed number of covariates\n",
    "\n",
    "# --- Sparse true coefficients ---\n",
    "beta_true = np.array([3.0, -2.0, 0.0, 0.0, 1.5, 0.0, 0.8, 0.0, 0.0, 0.0])\n",
    "\n",
    "# --- AR(1) correlated predictors ---\n",
    "rho = 0.7\n",
    "Sigma = rho ** np.abs(np.subtract.outer(np.arange(P), np.arange(P)))\n",
    "L = np.linalg.cholesky(Sigma)\n",
    "X = np.random.normal(size=(N, P)) @ L.T\n",
    "\n",
    "# --- Inject some covariate outliers ---\n",
    "outlier_fraction = 0.05\n",
    "num_outliers = int(outlier_fraction * N)\n",
    "outlier_rows = np.random.choice(N, num_outliers, replace=False)\n",
    "X[outlier_rows] += np.random.normal(0, 8.0, size=(num_outliers, P))\n",
    "\n",
    "# --- Heavy-tailed noise for y ---\n",
    "# Student-t with small df (df=3)\n",
    "df = 3\n",
    "noise = np.random.standard_t(df, size=N)\n",
    "\n",
    "# Scale noise to moderate amplitude\n",
    "sigma_true = 0.7\n",
    "noise *= sigma_true\n",
    "\n",
    "# --- Generate y ---\n",
    "y = X @ beta_true + noise\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from utils.generate_data import load_linreg_dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test, meta = load_linreg_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/linreg\"\n",
    "results_dir_linreg = \"results/regression/linreg/alpha_learned\"\n",
    "results_dir_linreg_prior = \"results/regression/linreg/prior\"\n",
    "#model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names = [\"Linreg Gaussian\", \"Linreg Regularized Horseshoe\", \"Linreg Dirichlet Horseshoe\", \"Linreg Dirichlet Student T\"]\n",
    "\n",
    "\n",
    "full_config_path = \"linreg_N200_p10\"\n",
    "linreg_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_linreg,\n",
    "    models=model_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "# prior_linreg_fit = get_model_fits(\n",
    "#     config=full_config_path,\n",
    "#     results_dir=results_dir_linreg_prior,\n",
    "#     models=model_names,\n",
    "#     include_prior=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "beta_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")\n",
    "beta_GLS = np.linalg.pinv((X_train.T@X_train))@X_train.T@y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Make sure y_train is 1D shape (N,)\n",
    "y_vec = np.asarray(y_test).reshape(-1)\n",
    "N = X_train.shape[0]\n",
    "\n",
    "def rmse_per_sample(beta_samples, X, y):\n",
    "    \"\"\"\n",
    "    beta_samples: (S, P)\n",
    "    X: (N, P)\n",
    "    y: (N,)\n",
    "    Returns: array (S,) of RMSEs, one per posterior draw\n",
    "    \"\"\"\n",
    "    # Predictions for all samples at once: (N, S)\n",
    "    preds = X @ beta_samples.T\n",
    "    # Broadcast y to (N, S)\n",
    "    errors = preds - y[:, None]\n",
    "    mse = np.mean(errors**2, axis=0)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "rmse_gauss_samps = rmse_per_sample(beta_gauss, X_test, y_vec)\n",
    "rmse_RHS_samps   = rmse_per_sample(beta_RHS,   X_test, y_vec)\n",
    "rmse_DHS_samps   = rmse_per_sample(beta_DHS,   X_test, y_vec)\n",
    "rmse_DST_samps   = rmse_per_sample(beta_DST,   X_test, y_vec)\n",
    "\n",
    "posterior_mean_rmse_gauss = np.sqrt(np.mean((y_test - X_test@np.mean(beta_gauss, axis=0))**2))\n",
    "posterior_mean_rmse_RHS = np.sqrt(np.mean((y_test - X_test@np.mean(beta_RHS, axis=0))**2))\n",
    "posterior_mean_rmse_DHS = np.sqrt(np.mean((y_test - X_test@np.mean(beta_DHS, axis=0))**2))\n",
    "posterior_mean_rmse_DST = np.sqrt(np.mean((y_test - X_test@np.mean(beta_DST, axis=0))**2))\n",
    "rmse_GLS = np.sqrt(np.mean((y_test - X_test@beta_GLS)**2))\n",
    "\n",
    "# -------- Density plot of RMSEs --------\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "def plot_rmse_kde(rmse_samples, label, posterior_mean_rmse, color):\n",
    "    kde = gaussian_kde(rmse_samples)\n",
    "    xs = np.linspace(np.percentile(rmse_samples, 1),\n",
    "                     np.percentile(rmse_samples, 99), 200)\n",
    "    plt.plot(xs, kde(xs), label=label, color=color)\n",
    "    plt.axvline(x=posterior_mean_rmse, color=color, linestyle=\"--\")\n",
    "    plt.axvline(x=np.mean(rmse_samples), color=color, linestyle=\"-\")\n",
    "\n",
    "plot_rmse_kde(rmse_gauss_samps, \"Gaussian\", posterior_mean_rmse_gauss, \"C0\")\n",
    "plot_rmse_kde(rmse_RHS_samps,   \"RHS\", posterior_mean_rmse_RHS, \"C1\")\n",
    "plot_rmse_kde(rmse_DHS_samps,   \"DHS\", posterior_mean_rmse_DHS, \"C2\")\n",
    "plot_rmse_kde(rmse_DST_samps,   \"DST\", posterior_mean_rmse_DST, \"C3\")\n",
    "\n",
    "plt.axvline(x=rmse_GLS, label=\"GLS\")\n",
    "plt.xlabel(\"RMSE on training data\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(\"Posterior distribution of RMSE per model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S, P = beta_gauss.shape  # number of draws, number of coefficients\n",
    "\n",
    "# Put all draws into one long DataFrame\n",
    "def beta_to_long_df(beta_array, model_name):\n",
    "    \"\"\"\n",
    "    beta_array: (S, P)\n",
    "    returns DataFrame with columns: model, draw, coeff, beta\n",
    "    \"\"\"\n",
    "    S, P = beta_array.shape\n",
    "    df = pd.DataFrame(\n",
    "        beta_array.reshape(S * P),\n",
    "        columns=[\"beta\"]\n",
    "    )\n",
    "    df[\"draw\"] = np.repeat(np.arange(S), P)\n",
    "    df[\"coeff\"] = np.tile(np.arange(P), S)\n",
    "    df[\"model\"] = model_name\n",
    "    return df\n",
    "\n",
    "df_gauss = beta_to_long_df(beta_gauss, \"Gaussian\")\n",
    "df_RHS   = beta_to_long_df(beta_RHS,   \"Regularized Horseshoe\")\n",
    "df_DHS   = beta_to_long_df(beta_DHS,   \"Dirichlet Horseshoe\")\n",
    "df_DST   = beta_to_long_df(beta_DST,   \"Dirichlet Student-t\")\n",
    "\n",
    "beta_df = pd.concat([df_gauss, df_RHS, df_DHS, df_DST], ignore_index=True)\n",
    "\n",
    "# Optional: attach true beta if you have it loaded from the dataset\n",
    "if \"beta_true\" in globals():\n",
    "    beta_true_series = pd.Series(beta_true, index=np.arange(len(beta_true)))\n",
    "    beta_df[\"beta_true\"] = beta_df[\"coeff\"].map(beta_true_series)\n",
    "else:\n",
    "    beta_true_series = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot per coefficient, grouped by model\n",
    "fig, axes = plt.subplots(5, int(np.ceil(P / 5)), figsize=(16, 16), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for j in range(P):\n",
    "    ax = axes[j]\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "    # Make a simple boxplot of posterior for beta_j under each model\n",
    "    data = [df_j[df_j[\"model\"] == m][\"beta\"].values\n",
    "            for m in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student-t\"]]\n",
    "    ax.boxplot(data, showfliers=False)\n",
    "    ax.set_xticks([1, 2, 3, 4])\n",
    "    ax.set_xticklabels([\"Gauss\", \"RHS\", \"DHS\", \"DST\"], rotation=30)\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "\n",
    "    # If true beta is known, add a horizontal line\n",
    "    if beta_true_series is not None:\n",
    "        ax.axhline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Hide unused axes if P is odd\n",
    "for k in range(P, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Posterior distributions of β_j by prior (boxplots)\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_beta_kde_for_coeff(j, ax):\n",
    "    \"\"\"\n",
    "    j: coefficient index\n",
    "    ax: matplotlib axis\n",
    "    \"\"\"\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "\n",
    "    for model_name, label in [\n",
    "        (\"Gaussian\", \"Gauss\"),\n",
    "        (\"Regularized Horseshoe\", \"RHS\"),\n",
    "        (\"Dirichlet Horseshoe\", \"DHS\"),\n",
    "        (\"Dirichlet Student-t\", \"DST\"),\n",
    "    ]:\n",
    "        samples = df_j[df_j[\"model\"] == model_name][\"beta\"].values\n",
    "        kde = gaussian_kde(samples)\n",
    "        xs = np.linspace(np.percentile(samples, 1),\n",
    "                         np.percentile(samples, 99), 200)\n",
    "        ax.plot(xs, kde(xs), label=label, alpha=0.8)\n",
    "\n",
    "    if beta_true_series is not None:\n",
    "        ax.axvline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Choose which coefficients to inspect more closely\n",
    "coeffs_to_plot = [0, 1, 2, 3]  # likely non-zero in your synthetic setup\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, j in enumerate(coeffs_to_plot):\n",
    "    plot_beta_kde_for_coeff(j, axes[idx])\n",
    "\n",
    "fig.suptitle(\"Marginal posterior densities of selected β_j\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "sigma_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "\n",
    "sigma_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_data\")\n",
    "\n",
    "sigma_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "xi_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"phi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, N, p = 4000, 200, 10\n",
    "\n",
    "kappa_RHS = np.zeros((S, p))\n",
    "kappa_DHS = np.zeros((S, p))\n",
    "kappa_DST = np.zeros((S, p))\n",
    "\n",
    "meff_RHS = np.zeros((S))\n",
    "meff_DHS = np.zeros((S))\n",
    "meff_DST = np.zeros((S))\n",
    "\n",
    "for i in range(S):\n",
    "    kappa_RHS[i] = 1/(1+(N*sigma_RHS[i]**(-2)*tau_RHS[i]**2*lambda_RHS[i]))\n",
    "    kappa_DHS[i] = 1/(1+(N*sigma_DHS[i]**(-2)*tau_DHS[i]**2*lambda_DHS[i]*xi_DHS[i]))\n",
    "    kappa_DST[i] = 1/(1+(N*sigma_DST[i]**(-2)*tau_DHS[i]**2*lambda_DST[i]*xi_DST[i]))\n",
    "    \n",
    "    meff_RHS[i] = np.sum(1 - kappa_RHS[i])\n",
    "    meff_DHS[i] = np.sum(1 - kappa_DHS[i])\n",
    "    meff_DST[i] = np.sum(1 - kappa_DST[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S, p = 4000, 10  # as before\n",
    "\n",
    "# Indices of coefficients to visualize\n",
    "idxs = [0, 1, 2, 6]\n",
    "beta_true_vals = {0: 3, 1: -2, 2: 0, 6:0.8}   # your ground truth\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\", 6: r\"$\\beta_7$\"}  # optional niceness\n",
    "\n",
    "def common_bins(*arrays, bins=40, range=None):\n",
    "    \"\"\"Compute common histogram bin edges for multiple arrays.\"\"\"\n",
    "    data = np.concatenate([a.ravel() for a in arrays])\n",
    "    return np.histogram_bin_edges(data, bins=bins, range=range)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(12, 8), sharex=False, sharey=\"row\")\n",
    "fig.suptitle(\"Posterior distributions of shrinkage ($\\\\kappa$) and coefficients ($\\\\beta$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax_kappa = axes[row, 0]\n",
    "    ax_beta  = axes[row, 1]\n",
    "\n",
    "    # --- Kappa posterior ---\n",
    "    bins_kappa = common_bins(kappa_RHS[:, j], kappa_DHS[:, j], kappa_DST[:, j], bins=40, range=(0, 1.0))\n",
    "    ax_kappa.hist(kappa_RHS[:, j], bins=bins_kappa, alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax_kappa.hist(kappa_DHS[:, j], bins=bins_kappa, alpha=0.6, label=\"DHS\", density=True)\n",
    "    ax_kappa.hist(kappa_DST[:, j], bins=bins_kappa, alpha=0.6, label=\"DST\", density=True)\n",
    "    ax_kappa.set_xlabel(r\"$\\kappa$\")\n",
    "    ax_kappa.set_ylabel(\"Density\" if row == 0 else \"\")\n",
    "    ax_kappa.set_title(f\"Kappa, {titles[j]}\")\n",
    "\n",
    "    # --- Beta posterior ---\n",
    "    bins_beta = common_bins(beta_RHS[:, j], beta_DHS[:, j], bins=40)  # auto range\n",
    "    ax_beta.hist(beta_RHS[:, j], bins=bins_beta, alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax_beta.hist(beta_DHS[:, j], bins=bins_beta, alpha=0.6, label=\"DHS\", density=True)\n",
    "    ax_beta.hist(beta_DST[:, j], bins=bins_beta, alpha=0.6, label=\"DHS\", density=True)\n",
    "\n",
    "    # Add true and GLS lines\n",
    "    ax_beta.axvline(beta_true_vals[j], alpha=0.9, label=\"Beta_true\", color=\"green\", linestyle=\"--\")\n",
    "    ax_beta.axvline(beta_GLS[j], alpha=0.9, label=\"Beta_GLS\", color=\"red\", linestyle=\":\")\n",
    "    ax_beta.set_xlabel(r\"$\\beta$\")\n",
    "    ax_beta.set_title(f\"Beta, {titles[j]}\")\n",
    "\n",
    "# Put a single legend outside\n",
    "handles, labels = axes[0, 1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "P = 10  # number of covariates\n",
    "bins = np.arange(0, P + 2) - 0.5  # bin edges at integers\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "sns.histplot(meff_RHS, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"RHS\")\n",
    "sns.histplot(meff_DHS, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"DHS\")\n",
    "sns.histplot(meff_DST, bins=bins, stat=\"density\", element=\"step\",\n",
    "             fill=True, label=\"DST\")\n",
    "\n",
    "# vertical line at true number of active coefficients\n",
    "plt.axvline(4, color=\"black\", linestyle=\"--\", linewidth=1.5,\n",
    "            label=\"True active = 4\")\n",
    "\n",
    "# add posterior means as markers\n",
    "for Meff, label, color in [\n",
    "    (meff_RHS, \"RHS\", \"C0\"),\n",
    "    (meff_DHS, \"DHS\", \"C1\"),\n",
    "    (meff_DST, \"DST\", \"C2\"),\n",
    "]:\n",
    "    mean_val = np.mean(Meff)\n",
    "    plt.axvline(mean_val, color=color, linestyle=\":\",\n",
    "                linewidth=1.5)\n",
    "    plt.text(mean_val + 0.1, plt.ylim()[1]*0.8,\n",
    "             f\"{label} mean={mean_val:.1f}\",\n",
    "             color=\"black\", fontsize=9, rotation=90, va=\"top\")\n",
    "\n",
    "plt.xticks(range(0, P + 1))\n",
    "plt.xlabel(r\"Effective number of parameters $m_{\\mathrm{eff}}$\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(\"Posterior distribution of effective parameters\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idxs   = [0, 1, 2, 6]\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\", 6: r\"$\\beta_7$\"}\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(7, 9), sharex=True)\n",
    "fig.suptitle(r\"Joint posterior of ($\\kappa_j$, $\\beta_j$) for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "    ax.scatter(kappa_RHS[:, j], beta_RHS[:, j],\n",
    "               alpha=0.2, s=8, label=\"RHS\")\n",
    "    ax.scatter(kappa_DHS[:, j], beta_DHS[:, j],\n",
    "               alpha=0.2, s=8, label=\"DHS\")\n",
    "    ax.scatter(kappa_DST[:, j], beta_DST[:, j],\n",
    "               alpha=0.2, s=8, label=\"DST\")\n",
    "    ax.axhline(y=beta_true_vals[j])\n",
    "\n",
    "    ax.set_title(titles[j])\n",
    "    ax.set_ylabel(r\"$\\beta_j$\")\n",
    "    if row == len(idxs) - 1:\n",
    "        ax.set_xlabel(r\"$\\kappa_j$\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"alpha\")\n",
    "alpha_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"alpha\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# alpha_DHS, alpha_DST : shape (n_draws, H)\n",
    "n_draws, H = alpha_DHS.shape\n",
    "\n",
    "# Long-format DataFrame\n",
    "df_list = []\n",
    "\n",
    "for h in range(H):\n",
    "    df_list.append(pd.DataFrame({\n",
    "        \"alpha\": alpha_DHS[:, h],\n",
    "        \"unit\": h,\n",
    "        \"model\": \"DHS\"\n",
    "    }))\n",
    "    df_list.append(pd.DataFrame({\n",
    "        \"alpha\": alpha_DST[:, h],\n",
    "        \"unit\": h,\n",
    "        \"model\": \"DST\"\n",
    "    }))\n",
    "\n",
    "df_alpha = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Optionally: log-scale because alpha can be small\n",
    "df_alpha[\"log_alpha\"] = np.log(df_alpha[\"alpha\"])\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1) Raw alpha\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.violinplot(\n",
    "    data=df_alpha, x=\"unit\", y=\"alpha\", hue=\"model\",\n",
    "    cut=0, inner=\"quartile\", scale=\"width\"\n",
    ")\n",
    "plt.yscale(\"log\")           # often sensible for α\n",
    "plt.title(\"Posterior of α per unit (log scale)\")\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"α\")\n",
    "plt.legend(title=\"Model\")\n",
    "\n",
    "# 2) Directly plot log α (nicer shape)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(\n",
    "    data=df_alpha, x=\"unit\", y=\"log_alpha\", hue=\"model\",\n",
    "    cut=0, inner=\"quartile\", scale=\"width\"\n",
    ")\n",
    "plt.title(\"Posterior of log(α) per unit\")\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"log α\")\n",
    "plt.legend(title=\"Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "sigma_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_RHS_prior = prior_linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "\n",
    "sigma_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"sigma\")\n",
    "tau_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"tau\")\n",
    "lambda_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_data\")\n",
    "xi_DHS_prior = prior_linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, p = 4000, 10\n",
    "\n",
    "kappa_RHS_prior = np.zeros((S, p))\n",
    "kappa_DHS_prior = np.zeros((S, p))\n",
    "\n",
    "for i in range(S):\n",
    "    kappa_RHS_prior[i] = 1/(1+(sigma_RHS_prior[i]**2*tau_RHS_prior[i]**2*lambda_RHS_prior[i]))\n",
    "    kappa_DHS_prior[i] = 1/(1+(sigma_DHS_prior[i]**2*tau_DHS_prior[i]**2*lambda_DHS_prior[i]*xi_DHS_prior[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(8, 7), sharex=True, sharey=True)\n",
    "fig.suptitle(\"Prior distributions of shrinkage ($\\\\kappa$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "\n",
    "    bins_kappa_prior = common_bins(\n",
    "        kappa_RHS_prior[:, j],\n",
    "        kappa_DHS_prior[:, j],\n",
    "        bins=40,\n",
    "        range=(0, 0.3)\n",
    "    )\n",
    "\n",
    "    ax.hist(kappa_RHS_prior[:, j], bins=bins_kappa_prior,\n",
    "            alpha=0.6, label=\"RHS\", density=True)\n",
    "    ax.hist(kappa_DHS_prior[:, j], bins=bins_kappa_prior,\n",
    "            alpha=0.6, label=\"DHS\", density=True)\n",
    "\n",
    "    ax.set_xlim(0, 0.2)  # focus on strong shrinkage region\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(f\"Prior kappa, {titles[j]}\")\n",
    "\n",
    "axes[-1].set_xlabel(r\"$\\kappa$\")\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RHS\", \"DHS\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), len(models),\n",
    "                         figsize=(10, 8),\n",
    "                         sharex=True, sharey=True)\n",
    "fig.suptitle(\"Prior vs posterior shrinkage ($\\\\kappa$)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    for col, model in enumerate(models):\n",
    "        ax = axes[row, col] if len(idxs) > 1 else axes[col]\n",
    "\n",
    "        if model == \"RHS\":\n",
    "            prior = kappa_RHS_prior[:, j]\n",
    "            post  = kappa_RHS[:, j]\n",
    "        else:  # \"DHS\"\n",
    "            prior = kappa_DHS_prior[:, j]\n",
    "            post  = kappa_DHS[:, j]\n",
    "\n",
    "        # Common bins for fair comparison\n",
    "        bins_kappa = common_bins(prior, post, bins=40, range=(0, 1.0))\n",
    "\n",
    "        ax.hist(prior, bins=bins_kappa, alpha=0.5, density=True, label=\"Prior\")\n",
    "        ax.hist(post,  bins=bins_kappa, alpha=0.5, density=True, label=\"Posterior\")\n",
    "\n",
    "        ax.set_xlim(0, 1.0)\n",
    "        if row == len(idxs) - 1:\n",
    "            ax.set_xlabel(r\"$\\kappa$\")\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Density\")\n",
    "\n",
    "        ax.set_title(f\"{model}, {titles[j]}\")\n",
    "\n",
    "# One shared legend\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "phi_prior = xi_DHS_prior  # (S, p)\n",
    "phi_post  = xi_DHS        # (S, p)\n",
    "\n",
    "p = phi_prior.shape[1]\n",
    "j_idx = np.arange(p)\n",
    "\n",
    "prior_mean = phi_prior.mean(axis=0)\n",
    "post_mean  = phi_post.mean(axis=0)\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(j_idx - width/2, prior_mean, width=width, label=\"Prior\", alpha=0.7)\n",
    "plt.bar(j_idx + width/2, post_mean,  width=width, label=\"Posterior\", alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Predictor index j\")\n",
    "plt.ylabel(r\"Mean $\\xi_j$\")\n",
    "plt.title(r\"Dirichlet weights $\\xi_j$: prior vs posterior\")\n",
    "plt.xticks(j_idx)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [0, 1, 2]  # or whatever indices you care about\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\"}  # optional\n",
    "\n",
    "def common_bins(*arrays, bins=40, rng=None):\n",
    "    data = np.concatenate([a.ravel() for a in arrays])\n",
    "    return np.histogram_bin_edges(data, bins=bins, range=rng)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(8, 8), sharex=True, sharey=True)\n",
    "fig.suptitle(r\"Prior vs posterior distributions of $\\xi_j$ (DHS)\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "\n",
    "    prior_j = phi_prior[:, j]\n",
    "    post_j  = phi_post[:, j]\n",
    "\n",
    "    bins = common_bins(prior_j, post_j, bins=40, rng=(0, 1))\n",
    "\n",
    "    ax.hist(prior_j, bins=bins, alpha=0.5, density=True, label=\"Prior\")\n",
    "    ax.hist(post_j,  bins=bins, alpha=0.5, density=True, label=\"Posterior\")\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(fr\"$\\xi_{{{j+1}}}$ ({titles.get(j, f'j={j}')})\")\n",
    "\n",
    "axes[-1].set_xlabel(r\"$\\xi_j$\")\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_RHS     = linreg_fit['Linreg Regularized Horseshoe Centered']['posterior'].stan_variable(\"beta\")\n",
    "beta_sd_RHS  = linreg_fit['Linreg Regularized Horseshoe Centered']['posterior'].stan_variable(\"beta_sd\")\n",
    "\n",
    "beta_DHS     = linreg_fit['Linreg Dirichlet Horseshoe Centered']['posterior'].stan_variable(\"beta\")\n",
    "beta_sd_DHS  = linreg_fit['Linreg Dirichlet Horseshoe Centered']['posterior'].stan_variable(\"beta_sd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-12\n",
    "idxs   = [0, 1, 2, 7]  # whatever you like\n",
    "titles = {0: r\"$\\beta_1$\", 1: r\"$\\beta_2$\", 2: r\"$\\beta_3$\", 7: r\"$\\beta_8$\"}\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(10, 10), sharex=True, sharey='row')\n",
    "fig.suptitle(r\"Posterior scales: $\\log \\beta_{\\text{sd},j}$ for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    # RHS\n",
    "    ax_rhs = axes[row, 0]\n",
    "    log_sd_rhs = (beta_sd_RHS[:, j] + eps)\n",
    "    ax_rhs.hist(log_sd_rhs, bins=40, density=True, alpha=0.7)\n",
    "    ax_rhs.set_title(f\"RHS, {titles[j]}\")\n",
    "    ax_rhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "    ax_rhs.set_ylabel(\"Density\")\n",
    "\n",
    "    # DHS\n",
    "    ax_dhs = axes[row, 1]\n",
    "    log_sd_dhs = (beta_sd_DHS[:, j] + eps)\n",
    "    ax_dhs.hist(log_sd_dhs, bins=40, density=True, alpha=0.7, color=\"tab:orange\")\n",
    "    ax_dhs.set_title(f\"DHS, {titles[j]}\")\n",
    "    ax_dhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(idxs), 2, figsize=(10, 10), sharex=True, sharey='row')\n",
    "fig.suptitle(r\"Joint posterior: $(\\log \\beta_{\\text{sd},j}, \\beta_j)$\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    # RHS\n",
    "    ax_rhs = axes[row, 0]\n",
    "    log_sd_rhs = np.log(beta_sd_RHS[:, j] + eps)\n",
    "    ax_rhs.scatter(log_sd_rhs, beta_RHS[:, j], alpha=0.2, s=8)\n",
    "    ax_rhs.set_title(f\"RHS, {titles[j]}\")\n",
    "    ax_rhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "    ax_rhs.set_ylabel(r\"$\\beta_j$\")\n",
    "\n",
    "    # DHS\n",
    "    ax_dhs = axes[row, 1]\n",
    "    log_sd_dhs = np.log(beta_sd_DHS[:, j] + eps)\n",
    "    ax_dhs.scatter(log_sd_dhs, beta_DHS[:, j], alpha=0.2, s=8, color=\"tab:orange\")\n",
    "    ax_dhs.set_title(f\"DHS, {titles[j]}\")\n",
    "    ax_dhs.set_xlabel(r\"$\\log \\beta_{\\text{sd},j}$\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want κ ignoring sigma (pure coef shrinkage):\n",
    "kappa_RHS = 1 / (1 + beta_sd_RHS**2)\n",
    "kappa_DHS = 1 / (1 + beta_sd_DHS**2)\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1, figsize=(7, 9), sharex=True)\n",
    "fig.suptitle(r\"Joint posterior of $(\\kappa_j, \\beta_j)$ for RHS vs DHS\")\n",
    "\n",
    "for row, j in enumerate(idxs):\n",
    "    ax = axes[row]\n",
    "    ax.scatter(kappa_RHS[:, j], beta_RHS[:, j], alpha=0.2, s=8, label=\"RHS\")\n",
    "    ax.scatter(kappa_DHS[:, j], beta_DHS[:, j], alpha=0.2, s=8, label=\"DHS\")\n",
    "    ax.set_title(titles[j])\n",
    "    ax.set_ylabel(r\"$\\beta_j$\")\n",
    "    if row == len(idxs) - 1:\n",
    "        ax.set_xlabel(r\"$\\kappa_j$\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
