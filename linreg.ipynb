{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "N = 250              # slightly larger sample\n",
    "P = 10               # fixed number of covariates\n",
    "\n",
    "# --- Sparse true coefficients ---\n",
    "beta_true = np.array([3.0, -2.0, 0.0, 0.0, 1.5, 0.0, 0.8, 0.0, 0.0, 0.0])\n",
    "\n",
    "# --- AR(1) correlated predictors ---\n",
    "rho = 0.7\n",
    "Sigma = rho ** np.abs(np.subtract.outer(np.arange(P), np.arange(P)))\n",
    "L = np.linalg.cholesky(Sigma)\n",
    "X = np.random.normal(size=(N, P)) @ L.T\n",
    "\n",
    "# --- Inject some covariate outliers ---\n",
    "outlier_fraction = 0.05\n",
    "num_outliers = int(outlier_fraction * N)\n",
    "outlier_rows = np.random.choice(N, num_outliers, replace=False)\n",
    "X[outlier_rows] += np.random.normal(0, 8.0, size=(num_outliers, P))\n",
    "\n",
    "# --- Heavy-tailed noise for y ---\n",
    "# Student-t with small df (df=3)\n",
    "df = 3\n",
    "noise = np.random.standard_t(df, size=N)\n",
    "\n",
    "# Scale noise to moderate amplitude\n",
    "sigma_true = 0.7\n",
    "noise *= sigma_true\n",
    "\n",
    "# --- Generate y ---\n",
    "y = X @ beta_true + noise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.generate_data import load_linreg_dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test, meta = load_linreg_dataset()\n",
    "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/linreg\"\n",
    "results_dir_relu = \"results/regression/linreg\"\n",
    "#model_names_relu = [\"Dirichlet Student T\"]\n",
    "model_names_relu = [\"Linreg Gaussian\", \"Linreg Regularized Horseshoe\", \"Linreg Dirichlet Horseshoe\", \"Linreg Dirichlet Student T\"]\n",
    "\n",
    "\n",
    "full_config_path = \"linreg_N200_p10\"\n",
    "linreg_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_gauss = linreg_fit['Linreg Gaussian']['posterior'].stan_variable(\"beta\")\n",
    "beta_RHS = linreg_fit['Linreg Regularized Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DHS = linreg_fit['Linreg Dirichlet Horseshoe']['posterior'].stan_variable(\"beta\")\n",
    "beta_DST = linreg_fit['Linreg Dirichlet Student T']['posterior'].stan_variable(\"beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Make sure y_train is 1D shape (N,)\n",
    "y_vec = np.asarray(y_train).reshape(-1)\n",
    "N = X_train.shape[0]\n",
    "\n",
    "def rmse_per_sample(beta_samples, X, y):\n",
    "    \"\"\"\n",
    "    beta_samples: (S, P)\n",
    "    X: (N, P)\n",
    "    y: (N,)\n",
    "    Returns: array (S,) of RMSEs, one per posterior draw\n",
    "    \"\"\"\n",
    "    # Predictions for all samples at once: (N, S)\n",
    "    preds = X @ beta_samples.T\n",
    "    # Broadcast y to (N, S)\n",
    "    errors = preds - y[:, None]\n",
    "    mse = np.mean(errors**2, axis=0)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "rmse_gauss_samps = rmse_per_sample(beta_gauss, X_train, y_vec)\n",
    "rmse_RHS_samps   = rmse_per_sample(beta_RHS,   X_train, y_vec)\n",
    "rmse_DHS_samps   = rmse_per_sample(beta_DHS,   X_train, y_vec)\n",
    "rmse_DST_samps   = rmse_per_sample(beta_DST,   X_train, y_vec)\n",
    "\n",
    "print(\"Posterior mean RMSEs:\")\n",
    "print(\"  Gaussian:               \", rmse_gauss_samps.mean())\n",
    "print(\"  Regularized Horseshoe:  \", rmse_RHS_samps.mean())\n",
    "print(\"  Dirichlet Horseshoe:    \", rmse_DHS_samps.mean())\n",
    "print(\"  Dirichlet Student-t:    \", rmse_DST_samps.mean())\n",
    "\n",
    "# -------- Density plot of RMSEs --------\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "def plot_rmse_kde(rmse_samples, label):\n",
    "    kde = gaussian_kde(rmse_samples)\n",
    "    xs = np.linspace(np.percentile(rmse_samples, 1),\n",
    "                     np.percentile(rmse_samples, 99), 200)\n",
    "    plt.plot(xs, kde(xs), label=label)\n",
    "\n",
    "plot_rmse_kde(rmse_gauss_samps, \"Gaussian\")\n",
    "plot_rmse_kde(rmse_RHS_samps,   \"Regularized Horseshoe\")\n",
    "plot_rmse_kde(rmse_DHS_samps,   \"Dirichlet Horseshoe\")\n",
    "plot_rmse_kde(rmse_DST_samps,   \"Dirichlet Student-t\")\n",
    "\n",
    "plt.xlabel(\"RMSE on training data\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(\"Posterior distribution of RMSE per model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sanity: check shapes\n",
    "print(\"Gauss:\", beta_gauss.shape)\n",
    "print(\"RHS:\", beta_RHS.shape)\n",
    "print(\"DHS:\", beta_DHS.shape)\n",
    "print(\"DST:\", beta_DST.shape)\n",
    "\n",
    "S, P = beta_gauss.shape  # number of draws, number of coefficients\n",
    "\n",
    "# Put all draws into one long DataFrame\n",
    "def beta_to_long_df(beta_array, model_name):\n",
    "    \"\"\"\n",
    "    beta_array: (S, P)\n",
    "    returns DataFrame with columns: model, draw, coeff, beta\n",
    "    \"\"\"\n",
    "    S, P = beta_array.shape\n",
    "    df = pd.DataFrame(\n",
    "        beta_array.reshape(S * P),\n",
    "        columns=[\"beta\"]\n",
    "    )\n",
    "    df[\"draw\"] = np.repeat(np.arange(S), P)\n",
    "    df[\"coeff\"] = np.tile(np.arange(P), S)\n",
    "    df[\"model\"] = model_name\n",
    "    return df\n",
    "\n",
    "df_gauss = beta_to_long_df(beta_gauss, \"Gaussian\")\n",
    "df_RHS   = beta_to_long_df(beta_RHS,   \"Regularized Horseshoe\")\n",
    "df_DHS   = beta_to_long_df(beta_DHS,   \"Dirichlet Horseshoe\")\n",
    "df_DST   = beta_to_long_df(beta_DST,   \"Dirichlet Student-t\")\n",
    "\n",
    "beta_df = pd.concat([df_gauss, df_RHS, df_DHS, df_DST], ignore_index=True)\n",
    "\n",
    "# Optional: attach true beta if you have it loaded from the dataset\n",
    "if \"beta_true\" in globals():\n",
    "    beta_true_series = pd.Series(beta_true, index=np.arange(len(beta_true)))\n",
    "    beta_df[\"beta_true\"] = beta_df[\"coeff\"].map(beta_true_series)\n",
    "else:\n",
    "    beta_true_series = None\n",
    "\n",
    "beta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot per coefficient, grouped by model\n",
    "fig, axes = plt.subplots(2, int(np.ceil(P / 2)), figsize=(16, 6), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for j in range(P):\n",
    "    ax = axes[j]\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "    # Make a simple boxplot of posterior for beta_j under each model\n",
    "    data = [df_j[df_j[\"model\"] == m][\"beta\"].values\n",
    "            for m in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student-t\"]]\n",
    "    ax.boxplot(data, showfliers=False)\n",
    "    ax.set_xticks([1, 2, 3, 4])\n",
    "    ax.set_xticklabels([\"Gauss\", \"RHS\", \"DHS\", \"DST\"], rotation=30)\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "\n",
    "    # If true beta is known, add a horizontal line\n",
    "    if beta_true_series is not None:\n",
    "        ax.axhline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Hide unused axes if P is odd\n",
    "for k in range(P, len(axes)):\n",
    "    axes[k].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Posterior distributions of β_j by prior (boxplots)\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_beta_kde_for_coeff(j, ax):\n",
    "    \"\"\"\n",
    "    j: coefficient index\n",
    "    ax: matplotlib axis\n",
    "    \"\"\"\n",
    "    df_j = beta_df[beta_df[\"coeff\"] == j]\n",
    "\n",
    "    for model_name, label in [\n",
    "        (\"Gaussian\", \"Gauss\"),\n",
    "        (\"Regularized Horseshoe\", \"RHS\"),\n",
    "        (\"Dirichlet Horseshoe\", \"DHS\"),\n",
    "        (\"Dirichlet Student-t\", \"DST\"),\n",
    "    ]:\n",
    "        samples = df_j[df_j[\"model\"] == model_name][\"beta\"].values\n",
    "        kde = gaussian_kde(samples)\n",
    "        xs = np.linspace(np.percentile(samples, 1),\n",
    "                         np.percentile(samples, 99), 200)\n",
    "        ax.plot(xs, kde(xs), label=label, alpha=0.8)\n",
    "\n",
    "    if beta_true_series is not None:\n",
    "        ax.axvline(beta_true_series[j], linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"β_{j+1}\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Choose which coefficients to inspect more closely\n",
    "coeffs_to_plot = [0, 1, 2, 3]  # likely non-zero in your synthetic setup\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, j in enumerate(coeffs_to_plot):\n",
    "    plot_beta_kde_for_coeff(j, axes[idx])\n",
    "\n",
    "fig.suptitle(\"Marginal posterior densities of selected β_j\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior means per coefficient and model\n",
    "mean_df = (\n",
    "    beta_df\n",
    "    .groupby([\"model\", \"coeff\"])[\"beta\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"coeff\", columns=\"model\", values=\"beta\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for model_name in [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student-t\"]:\n",
    "    plt.plot(mean_df.index + 1, mean_df[model_name], marker=\"o\", label=model_name)\n",
    "\n",
    "if beta_true_series is not None:\n",
    "    plt.plot(np.arange(1, P+1), beta_true_series.values, \"k--\", label=\"True β\")\n",
    "\n",
    "plt.xlabel(\"Coefficient index j\")\n",
    "plt.ylabel(\"Posterior mean of β_j\")\n",
    "plt.title(\"Posterior means per coefficient and prior\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
