{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = 1\n",
    "data_dir = f\"datasets/type_{data_config}\"\n",
    "results_dir_relu = \"results_relu\"\n",
    "results_dir_large = \"results_relu_large\"\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_large = [\"Dirichlet Horseshoe\"]\n",
    "\n",
    "relu_fits = {}\n",
    "large_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\"GAM_N100_p8_sigma1.00_seed1.npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path_relu = f\"type_{data_config}/{base_config_name}\"  # â†’ \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=model_names_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    full_config_path_large = f\"{base_config_name}\"\n",
    "    large_fit = get_model_fits(\n",
    "        config=full_config_path_large,\n",
    "        results_dir=results_dir_large,\n",
    "        models=model_names_large,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    relu_fits[base_config_name] = relu_fit  # use clean key\n",
    "    large_fits[base_config_name] = large_fit  # use clean key\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the largest values of weights for each model\n",
    "largest_weights = {}\n",
    "\n",
    "for model_name in model_names_relu:\n",
    "    W1_samples = relu_fits['GAM_N100_p8_sigma1.00_seed1'][model_name]['posterior'].stan_variable(\"W_1\")\n",
    "    largest_weights[model_name] = [np.max(np.abs(W1_samples[i, :, :].flatten())) for i in range(W1_samples.shape[0])]\n",
    "    \n",
    "W1_large = large_fits['GAM_N100_p8_sigma1.00_seed1']['Dirichlet Horseshoe']['posterior'].stan_variable(\"W_1\")\n",
    "largest_weights['Dirichlet Horseshoe large'] = [np.max(np.abs(W1_large[i, :, :].flatten())) for i in range(W1_large.shape[0])]\n",
    "\n",
    "# Visualize the weight sizes in a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name, weights in largest_weights.items():\n",
    "    sns.histplot(weights, kde=True, label=model_name, bins=30)\n",
    "\n",
    "plt.xlabel(\"Largest Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Largest Weight Values Across Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the largest values of weights for each model\n",
    "largest_weights = {}\n",
    "\n",
    "for model_name in model_names_relu:\n",
    "    W1_samples = relu_fits['GAM_N100_p8_sigma1.00_seed1'][model_name]['posterior'].stan_variable(\"W_L\")\n",
    "    largest_weights[model_name] = [np.max(np.abs(W1_samples[i, :, :].flatten())) for i in range(W1_samples.shape[0])]\n",
    "\n",
    "# Visualize the weight sizes in a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name, weights in largest_weights.items():\n",
    "    sns.histplot(weights, kde=True, label=model_name, bins=30)\n",
    "\n",
    "plt.xlabel(\"Largest Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Largest Weight Values Across Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "def forward_pass_relu(X, W1, b1, W2, b2):\n",
    "    pre_act_1 = X @ W1 + b1.reshape(1, -1)\n",
    "    post_act_1 = np.maximum(0, pre_act_1)\n",
    "    output = post_act_1 @ W2 + b2.reshape(1, -1)\n",
    "    return output\n",
    "\n",
    "# Load dataset\n",
    "dataset_key = f'GAM_N100_p8_sigma{1:.2f}_seed{1}'\n",
    "x_star = np.load(f\"datasets/type_{1}/{dataset_key}.npz\")[\"X_test\"][2].reshape(1, -1)\n",
    "\n",
    "# Set up priors to compare\n",
    "priors = ['Gaussian', 'Regularized Horseshoe', 'Dirichlet Horseshoe', 'Dirichlet Horseshoe large', 'Dirichlet Student T']\n",
    "results = {}\n",
    "\n",
    "for prior in priors:\n",
    "    if prior == 'Dirichlet Horseshoe large':\n",
    "        posterior = large_fits[dataset_key]['Dirichlet Horseshoe']['posterior']\n",
    "        W1 = posterior.stan_variable(\"W_1\")\n",
    "        b1 = posterior.stan_variable(\"hidden_bias\")\n",
    "        W2 = posterior.stan_variable(\"W_L\")\n",
    "        b2 = posterior.stan_variable(\"output_bias\")\n",
    "    \n",
    "    else:\n",
    "        posterior = relu_fits[dataset_key][prior]['posterior']\n",
    "        W1 = posterior.stan_variable(\"W_1\")\n",
    "        b1 = posterior.stan_variable(\"hidden_bias\")\n",
    "        W2 = posterior.stan_variable(\"W_L\")\n",
    "        b2 = posterior.stan_variable(\"output_bias\")\n",
    "\n",
    "    S = W1.shape[0]\n",
    "    preds = np.zeros(S)\n",
    "    \n",
    "    for s in range(S):\n",
    "        f_xs = forward_pass_relu(x_star, W1[s], b1[s], W2[s], b2[s])\n",
    "        preds[s] = f_xs.item()\n",
    "\n",
    "    mu_hat, sigma_hat = np.mean(preds), np.std(preds)\n",
    "    kurt = stats.kurtosis(preds, fisher=False)\n",
    "    y_sorted = np.sort(preds)\n",
    "    k = int(S * 0.1)\n",
    "    tail = y_sorted[-k:]\n",
    "    hill_est = (1 / (k - 1)) * np.sum(np.log(tail / tail.min()))\n",
    "\n",
    "    results[prior] = {\n",
    "        'preds': preds,\n",
    "        'mu': mu_hat,\n",
    "        'sigma': sigma_hat,\n",
    "        'kurtosis': kurt,\n",
    "        'hill': hill_est\n",
    "    }\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for prior in priors:\n",
    "    preds = results[prior]['preds']\n",
    "    plt.hist(preds, bins=50, density=True, histtype='step', label=prior)\n",
    "plt.title(\"Predictive Posterior Distributions at x*\")\n",
    "plt.xlabel('f(x*)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- QQ-plot Grid across Inputs ----\n",
    "from matplotlib import gridspec\n",
    "dataset_key = f'GAM_N100_p8_sigma{1:.2f}_seed{1}'\n",
    "X_test = np.load(f\"datasets/type_{1}/{dataset_key}.npz\")[\"X_test\"]\n",
    "\n",
    "test_indices = np.linspace(0, len(X_test)-1, 16, dtype=int)  # choose 9 spread-out test points\n",
    "\n",
    "for prior in priors:\n",
    "\n",
    "    if prior == 'Dirichlet Horseshoe large':\n",
    "        posterior = large_fits[dataset_key]['Dirichlet Horseshoe']['posterior']\n",
    "        W1 = posterior.stan_variable(\"W_1\")\n",
    "        b1 = posterior.stan_variable(\"hidden_bias\")\n",
    "        W2 = posterior.stan_variable(\"W_L\")\n",
    "        b2 = posterior.stan_variable(\"output_bias\")\n",
    "        S = W1.shape[0]\n",
    "    else:\n",
    "        posterior = relu_fits[dataset_key][prior]['posterior']\n",
    "        W1 = posterior.stan_variable(\"W_1\")\n",
    "        b1 = posterior.stan_variable(\"hidden_bias\")\n",
    "        W2 = posterior.stan_variable(\"W_L\")\n",
    "        b2 = posterior.stan_variable(\"output_bias\")\n",
    "        S = W1.shape[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(f'{prior}: QQ-Plots Across 9 Test Inputs', fontsize=16)\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "\n",
    "    for i, idx in enumerate(test_indices):\n",
    "        x_star = X_test[idx].reshape(1, -1)\n",
    "        preds = np.zeros(S)\n",
    "        for s in range(S):\n",
    "            f_xs = forward_pass_relu(x_star, W1[s], b1[s], W2[s], b2[s])\n",
    "            preds[s] = f_xs.item()\n",
    "\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        stats.probplot(preds, dist=\"norm\", plot=ax)\n",
    "        ax.set_title(f'x[{idx}]', fontsize=10)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
