{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/friedman\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/friedman\"\n",
    "#model_names_relu = [\"Dirichlet Horseshoe\"]\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "\n",
    "relu_fits = {}\n",
    "tanh_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # â†’ \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=model_names_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh,\n",
    "        models=model_names_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "    relu_fits[base_config_name] = relu_fit  # use clean key\n",
    "    tanh_fits[base_config_name] = tanh_fit  # use clean key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import compute_sparse_rmse_results, forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "seeds = [1, 2]\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    N = 100 if seed == 1 else 200\n",
    "    sigma = 1\n",
    "    return N, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_relu, df_posterior_rmse_relu = {}, {}\n",
    "df_rmse_tanh, df_posterior_rmse_tanh = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    df_rmse_relu[sparsity], df_posterior_rmse_relu[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds, model_names_relu, relu_fits, get_N_sigma, forward_pass_relu,\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )\n",
    "    \n",
    "    df_rmse_tanh[sparsity], df_posterior_rmse_tanh[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds, model_names_tanh, tanh_fits, get_N_sigma, forward_pass_tanh,\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_rmse_full_relu = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_tanh = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_tanh.items()],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Clean model names\n",
    "df_rmse_full_relu = df_rmse_full_relu.copy()\n",
    "df_rmse_full_relu[\"model\"] = df_rmse_full_relu[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "df_rmse_full_tanh = df_rmse_full_tanh.copy()\n",
    "df_rmse_full_tanh[\"model\"] = df_rmse_full_tanh[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "# Define consistent color palette\n",
    "custom_palette = {\n",
    "    \"Gaussian\": \"C0\",\n",
    "    \"Regularized Horseshoe\": \"C1\",\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Student T\": \"C3\",\n",
    "}\n",
    "\n",
    "# Set up plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), sharex=True, sharey=True)\n",
    "\n",
    "activation_data = [(\"ReLU\", df_rmse_full_relu), (\"tanh\", df_rmse_full_tanh)]\n",
    "all_handles_labels = []\n",
    "\n",
    "# Plot\n",
    "for idx, (name, df) in enumerate(activation_data):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x='sparsity', y='rmse',\n",
    "        hue='model', style='N', marker='o', errorbar=None, ax=ax,\n",
    "        palette=custom_palette\n",
    "    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    all_handles_labels.extend(zip(handles, labels))\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax.set_title(f\"{name} activation\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_xlabel(\"Sparsity Level\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Clean legend\n",
    "legend_dict = OrderedDict()\n",
    "for handle, label in all_handles_labels:\n",
    "    if label not in {\"model\", \"N\"} and label not in legend_dict:\n",
    "        legend_dict[label] = handle\n",
    "\n",
    "desired_order = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "filtered = [(legend_dict[label], label) for label in desired_order if label in legend_dict]\n",
    "\n",
    "if filtered:\n",
    "    filtered_handles, filtered_labels = zip(*filtered)\n",
    "    fig.legend(\n",
    "        filtered_handles,\n",
    "        filtered_labels,\n",
    "        title=\"Model\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=2,\n",
    "    )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize_networks import compute_activation_frequency, extract_all_pruned_means, plot_all_networks_subplots_activations\n",
    "path = \"datasets/friedman/Friedman_N100_p10_sigma1.00_seed1.npz\"\n",
    "data = np.load(path)\n",
    "x_train = data[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_activation_colors = {\n",
    "    model_name: compute_activation_frequency(fit, x_train)\n",
    "    for model_name, fit in relu_fits['Friedman_N100_p10_sigma1.00_seed1'].items()\n",
    "}\n",
    "\n",
    "# Flatten and find the global maximum\n",
    "all_freqs = np.concatenate(list(node_activation_colors.values()))\n",
    "global_max = all_freqs.max()\n",
    "print(global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 10\n",
    "H = 16\n",
    "L = 1\n",
    "out_nodes = 1\n",
    "layer_sizes = [P] + [H]*L + [out_nodes]\n",
    "\n",
    "layer_structure = {\n",
    "    'input_to_hidden': {'name': 'W_1', 'shape': (P, H)},\n",
    "    'hidden_to_output': {'name': 'W_L', 'shape': (H, out_nodes)}\n",
    "}\n",
    "\n",
    "sparsity_level = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_means = extract_all_pruned_means(relu_fits['Friedman_N100_p10_sigma1.00_seed1'], layer_structure, sparsity_level)\n",
    "\n",
    "p1, widths_1 = plot_all_networks_subplots_activations(pruned_model_means, layer_sizes, node_activation_colors, activation_color_max=global_max, signed_colors=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move Networks.ipynb into this file to show the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import compute_sparse_rmse_results, prune_nodes_by_output_weights\n",
    "\n",
    "df_rmse_node_relu, df_posterior_rmse_node_relu = {}, {}\n",
    "df_rmse_node_tanh, df_posterior_rmse_node_tanh = {}, {}\n",
    "\n",
    "def nodes_to_sparsity(nodes_to_prune_list, total_nodes):\n",
    "    \"\"\"\n",
    "    Convert a list of node counts to prune into sparsity levels.\n",
    "\n",
    "    Args:\n",
    "        nodes_to_prune_list: list of integers (number of nodes to prune).\n",
    "        total_nodes: total number of nodes in the layer.\n",
    "\n",
    "    Returns:\n",
    "        List of sparsity levels between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    sparsity_levels = [round(n_prune / total_nodes, 4) for n_prune in nodes_to_prune_list]\n",
    "    return sparsity_levels\n",
    "\n",
    "# Suppose you have 16 nodes in the hidden layer\n",
    "total_nodes = 16\n",
    "nodes_to_prune = [0, 1, 2, 4, 6, 8, 10, 12, 14]\n",
    "\n",
    "node_sparsity = nodes_to_sparsity(nodes_to_prune, total_nodes)\n",
    "print(node_sparsity)  \n",
    "# Output: [0.0, 0.0625, 0.125, 0.25, 0.5, 0.75, 0.875]\n",
    "\n",
    "for sparsity in node_sparsity:\n",
    "    df_rmse_node_relu[sparsity], df_posterior_rmse_node_relu[sparsity] = compute_sparse_rmse_results(\n",
    "    seeds, model_names_relu, relu_fits, get_N_sigma, forward_pass_relu,\n",
    "    sparsity=sparsity, prune_fn=prune_nodes_by_output_weights\n",
    ")\n",
    "    \n",
    "    df_rmse_node_tanh[sparsity], df_posterior_rmse_node_tanh[sparsity] = compute_sparse_rmse_results(\n",
    "    seeds, model_names_tanh, tanh_fits, get_N_sigma, forward_pass_tanh,\n",
    "    sparsity=sparsity, prune_fn=prune_nodes_by_output_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_rmse_full_node_relu = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_node_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_node_tanh = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_node_tanh.items()],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nodes = 16  # adjust this if needed\n",
    "\n",
    "df_rmse_full_node_relu['nodes_pruned'] = (df_rmse_full_node_relu['sparsity'] * total_nodes).astype(int)\n",
    "df_rmse_full_node_tanh['nodes_pruned'] = (df_rmse_full_node_tanh['sparsity'] * total_nodes).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Clean model names\n",
    "df_rmse_full_node_relu = df_rmse_full_node_relu.copy()\n",
    "df_rmse_full_node_relu[\"model\"] = df_rmse_full_node_relu[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "df_rmse_full_node_tanh = df_rmse_full_node_tanh.copy()\n",
    "df_rmse_full_node_tanh[\"model\"] = df_rmse_full_node_tanh[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "# Define consistent color palette\n",
    "custom_palette = {\n",
    "    \"Gaussian\": \"C0\",\n",
    "    \"Regularized Horseshoe\": \"C1\",\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Student T\": \"C3\",\n",
    "}\n",
    "\n",
    "# Set up plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), sharex=True, sharey=True)\n",
    "\n",
    "activation_data = [(\"ReLU\", df_rmse_full_node_relu), (\"tanh\", df_rmse_full_node_tanh)]\n",
    "all_handles_labels = []\n",
    "\n",
    "# Plot\n",
    "for idx, (name, df) in enumerate(activation_data):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x='nodes_pruned', y='rmse',\n",
    "        hue='model', style='N', marker='o', errorbar=None, ax=ax,\n",
    "        palette=custom_palette\n",
    "    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    all_handles_labels.extend(zip(handles, labels))\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax.set_title(f\"{name} activation\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_xlabel(\"Nodes pruned\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Clean legend\n",
    "legend_dict = OrderedDict()\n",
    "for handle, label in all_handles_labels:\n",
    "    if label not in {\"model\", \"N\"} and label not in legend_dict:\n",
    "        legend_dict[label] = handle\n",
    "\n",
    "desired_order = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "filtered = [(legend_dict[label], label) for label in desired_order if label in legend_dict]\n",
    "\n",
    "if filtered:\n",
    "    filtered_handles, filtered_labels = zip(*filtered)\n",
    "    fig.legend(\n",
    "        filtered_handles,\n",
    "        filtered_labels,\n",
    "        title=\"Model\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=2,\n",
    "    )\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize_networks import compute_activation_frequency, extract_all_pruned_means, plot_all_networks_subplots_activations\n",
    "path = \"datasets/friedman/Friedman_N100_p10_sigma1.00_seed1.npz\"\n",
    "data = np.load(path)\n",
    "x_train = data[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_activation_colors = {\n",
    "    model_name: compute_activation_frequency(fit, x_train)\n",
    "    for model_name, fit in relu_fits['Friedman_N100_p10_sigma1.00_seed1'].items()\n",
    "}\n",
    "\n",
    "# Flatten and find the global maximum\n",
    "all_freqs = np.concatenate(list(node_activation_colors.values()))\n",
    "global_max = all_freqs.max()\n",
    "print(global_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NODE PRUNE VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize_networks import extract_all_pruned_node_means, plot_all_networks_subplots_activations\n",
    "num_nodes_to_prune = 14  # for example\n",
    "pruned_model_means_nodes = extract_all_pruned_node_means(relu_fits['Friedman_N100_p10_sigma1.00_seed1'], layer_structure, num_nodes_to_prune)\n",
    "\n",
    "p_nodes, widths_nodes = plot_all_networks_subplots_activations(\n",
    "    pruned_model_means_nodes, layer_sizes, node_activation_colors,\n",
    "    activation_color_max=global_max, signed_colors=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
