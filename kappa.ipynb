{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_priors = \"results/priors/single_layer/tanh/friedman\"\n",
    "results_dir_posteriors = \"results/regression/single_layer/tanh/friedman\"\n",
    "#results_dir_posteriors_dst = \"results/regression/single_layer/tanh/friedman/full_regularization\"\n",
    "\n",
    "prior_names_and_configs = {\"Dirichlet Horseshoe\": \"dir_hs\", \"Dirichlet Student T\": \"dir_stud_t\", \"Gaussian\": \"gauss\", \"Regularized Horseshoe\": \"reg_hs\", \"Dirichlet Gamma\": \"dir_gam\"}\n",
    "posterior_names = [\"Dirichlet Horseshoe tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Gaussian tanh\"]\n",
    "#posterior_names_and_configs_dst = [\"Dirichlet Student T tanh\"]\n",
    "   \n",
    "prior_fits = {}\n",
    "posterior_fits = {}\n",
    "\n",
    "for key, value in prior_names_and_configs.items():\n",
    "    prior_fit = get_model_fits(\n",
    "        config=value,\n",
    "        results_dir=results_dir_priors,\n",
    "        models=key,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    prior_fits[key] = prior_fit\n",
    "    \n",
    "#for key, value in posterior_names_and_configs.items():\n",
    "posterior_N100_fits = get_model_fits(\n",
    "    config=\"Friedman_N100_p10_sigma1.00_seed1\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "posterior_N200_fits = get_model_fits(\n",
    "    config=\"Friedman_N200_p10_sigma1.00_seed2\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "posterior_N500_fits = get_model_fits(\n",
    "    config=\"Friedman_N500_p10_sigma1.00_seed11\",\n",
    "    results_dir=results_dir_posteriors,\n",
    "    models=posterior_names,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpmath import hyper\n",
    "from mpmath import gamma\n",
    "from scipy.special import poch\n",
    "\n",
    "\n",
    "p=10\n",
    "alpha=1.0\n",
    "beta=(p-1)*alpha\n",
    "\n",
    "\n",
    "def p_kappa_dirichlet_horseshoe(kappa, alpha, beta, a_j=1.0):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    prefactor = (1/np.pi) * (a_j / ((1-kappa) * np.sqrt(kappa) * np.sqrt(1-kappa)))# * (1/p)\n",
    "    c = (kappa / (1-kappa))*(a_j**2)\n",
    "    # {}_3F_2([1, 1.1/2, 2.1/1], [1, 3/2], z)\n",
    "    gamma_const = (gamma(alpha+1/2)/gamma(alpha))*(gamma(alpha+beta)/(gamma(alpha+beta+1/2)))\n",
    "    hyper_val = hyper([1, alpha+1/2], [alpha+beta+1/2], -c)\n",
    "    return float(prefactor * gamma_const * hyper_val)\n",
    "\n",
    "# def p_kappa_dirichlet_horseshoe(kappa, a_j=1.0, p=10):\n",
    "#     if kappa <= 0 or kappa >= 1:\n",
    "#         return 0.0\n",
    "#     prefactor = (1/np.pi) * (a_j / ((1-kappa) * np.sqrt(kappa) * np.sqrt(1-kappa))) * (1/p)\n",
    "#     c = (-kappa / (1-kappa))*(a_j**2)\n",
    "#     # {}_3F_2([1, 1.1/2, 2.1/1], [1, 3/2], z)\n",
    "#     hyper_val = hyper([1, (alpha+1)/2, alpha/2 + 1], [(p*alpha+1)/2, p*alpha/2 + 1], c)\n",
    "#     return float(prefactor * hyper_val)\n",
    "\n",
    "def p_kappa_dirichlet_student_t(kappa, alpha, beta, nu=3.0, a_j=1.0):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    C = gamma((nu+1)/2) * 1/(np.sqrt(np.pi * nu) * gamma(nu/2))\n",
    "    prefactor = ((a_j**nu) * nu**((nu+1)/2) * kappa**(nu/2 - 1)) / ((1-kappa)**(nu/2 + 1)) # * poch(alpha, nu) / poch(p*alpha, nu)\n",
    "    c = (-kappa / (1-kappa))*(a_j**2)\n",
    "    gamma_const = (gamma(alpha+nu/2)/gamma(alpha))*(gamma(alpha+beta)/(gamma(alpha+beta+nu/2)))\n",
    "    hyper_val = hyper([(nu+1)/2, alpha + nu/2], [alpha+beta+nu/2], c)\n",
    "    return float(C * prefactor * gamma_const * hyper_val)\n",
    "\n",
    "# def p_kappa_dirichlet_student_t(kappa, nu=3.0, a_j=1.0, p=10):\n",
    "#     if kappa <= 0 or kappa >= 1:\n",
    "#         return 0.0\n",
    "#     C = gamma((nu+1)/2) * 1/(np.sqrt(np.pi * nu) * gamma(nu/2))\n",
    "#     prefactor = ((a_j**nu) * nu**((nu+1)/2) * kappa**(nu/2 - 1)) / ((1-kappa)**(nu/2 + 1))  * poch(alpha, nu) / poch(p*alpha, nu)\n",
    "#     c = (-kappa / (1-kappa))*(a_j**2)\n",
    "#     # {}_3F_2([1, 1.1/2, 2.1/1], [1, 3/2], z)\n",
    "#     hyper_val = hyper([(nu+1)/2, (alpha+nu)/2, (alpha+nu+1)/2], [(p*alpha+nu)/2, (p*alpha+nu+1)/2], c)\n",
    "#     return float(C * prefactor * hyper_val)\n",
    "\n",
    "def p_kappa_horseshoe(kappa, a_j=1.0):\n",
    "    if kappa <= 0 or kappa >= 1:\n",
    "        return 0.0\n",
    "    prefactor = (1/np.pi) * (a_j / ((a_j**2-1)*kappa + 1)) * 1/(np.sqrt(kappa) * np.sqrt(1-kappa))\n",
    "    return float(prefactor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have updated the density plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\frac{1}{\\pi} \\frac{\\sqrt{q_{j}} \\tau}{(1-\\kappa_j)\\sqrt{\\kappa_j}\\sqrt{1-\\kappa_j}} \\frac{\\Gamma(\\alpha+\\frac{1}{2})}{\\Gamma(\\alpha)}\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha+\\beta+\\frac{1}{2})}{}_2F_1\\!\\left(\\begin{matrix} 1, \\alpha+\\frac{1}{2} \\\\ \\alpha + \\beta + \\frac{1}{2} \\end{matrix}; -c \\right)\n",
    "\\end{aligned} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})}  \\frac{1}{(1-\\kappa)^{\\frac{\\nu}{2}+1}}\\nu^{\\frac{\\nu + 1}{2}} \\kappa^{\\frac{\\nu}{2}-1}q_{j}^{\\frac{\\nu}{2}}\\tau^{\\nu} \\mathbb{E}_{\\xi_j}\\left[\\frac{\\xi_j^{\\nu/2}}{\\left(1+c\\xi_j\\right)^{\\frac{\\nu+1}{2}}}\\right]\n",
    "\\end{aligned} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag kappa-grid\n",
    "kappa_vals = np.linspace(0.001, 0.999, 500)\n",
    "p_vals_dirichlet_horseshoe = [p_kappa_dirichlet_horseshoe(k, alpha, beta) for k in kappa_vals]\n",
    "p_vals_dirichlet_horseshoe_medium_low = [p_kappa_dirichlet_horseshoe(k, alpha, beta, a_j=0.7) for k in kappa_vals]\n",
    "p_vals_dirichlet_horseshoe_medium_high = [p_kappa_dirichlet_horseshoe(k, alpha, beta, a_j=2) for k in kappa_vals]\n",
    "p_vals_dirichlet_horseshoe_low = [p_kappa_dirichlet_horseshoe(k, alpha, beta, a_j=0.1) for k in kappa_vals]\n",
    "p_vals_dirichlet_horseshoe_high = [p_kappa_dirichlet_horseshoe(k, alpha, beta, a_j=5) for k in kappa_vals]\n",
    "\n",
    "p_vals_dirichlet_student_t = [p_kappa_dirichlet_student_t(k, alpha, beta) for k in kappa_vals]\n",
    "p_vals_dirichlet_student_t_medium_low = [p_kappa_dirichlet_student_t(k, alpha, beta, a_j=0.7) for k in kappa_vals]\n",
    "p_vals_dirichlet_student_t_medium_high = [p_kappa_dirichlet_student_t(k, alpha, beta, a_j=2) for k in kappa_vals]\n",
    "p_vals_dirichlet_student_t_low = [p_kappa_dirichlet_student_t(k, alpha, beta, a_j=0.1) for k in kappa_vals]\n",
    "p_vals_dirichlet_student_t_high = [p_kappa_dirichlet_student_t(k, alpha, beta, a_j=5) for k in kappa_vals]\n",
    "\n",
    "p_vals_horseshoe = [p_kappa_horseshoe(k) for k in kappa_vals]\n",
    "p_vals_horseshoe_medium_low = [p_kappa_horseshoe(k, a_j=0.7) for k in kappa_vals]\n",
    "p_vals_horseshoe_medium_high = [p_kappa_horseshoe(k, a_j=2) for k in kappa_vals]\n",
    "p_vals_horseshoe_low = [p_kappa_horseshoe(k, a_j=0.1) for k in kappa_vals]\n",
    "p_vals_horseshoe_high = [p_kappa_horseshoe(k, a_j=5) for k in kappa_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6), sharex=True, sharey=False)\n",
    "\n",
    "axes[0].plot(kappa_vals, p_vals_dirichlet_horseshoe_low)#, label=r\"$a_j = 0.1$\")\n",
    "axes[0].plot(kappa_vals, p_vals_dirichlet_horseshoe_medium_low)#, label=r\"$a_j = 0.7$\")\n",
    "axes[0].plot(kappa_vals, p_vals_dirichlet_horseshoe)#, label=r\"$a_j = 1$\")\n",
    "axes[0].plot(kappa_vals, p_vals_dirichlet_horseshoe_medium_high)#, label=r\"$a_j = 2$\")\n",
    "axes[0].plot(kappa_vals, p_vals_dirichlet_horseshoe_high)#, label=r\"$a_j = 5$\")\n",
    "axes[0].set_ylabel(r\"$p(\\kappa \\mid \\sigma, \\tau)$\")\n",
    "axes[0].set_xlabel(r\"$\\kappa$\")\n",
    "axes[0].set_title(\"Dirichlet–Horseshoe\")\n",
    "axes[0].set_ylim((0, 7))\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(kappa_vals, p_vals_dirichlet_student_t_low, label=r\"$a_j = 0.1$\")\n",
    "axes[1].plot(kappa_vals, p_vals_dirichlet_student_t_medium_low, label=r\"$a_j = 0.7$\")\n",
    "axes[1].plot(kappa_vals, p_vals_dirichlet_student_t, label=r\"$a_j = 1$\")\n",
    "axes[1].plot(kappa_vals, p_vals_dirichlet_student_t_medium_high, label=r\"$a_j = 2$\")\n",
    "axes[1].plot(kappa_vals, p_vals_dirichlet_student_t_high, label=r\"$a_j = 5$\")\n",
    "#axes[1].set_ylabel(r\"$p(\\kappa \\mid \\sigma, \\tau)$\")\n",
    "axes[1].set_xlabel(r\"$\\kappa$\")\n",
    "axes[1].set_title(\"Dirichlet–Student T\")\n",
    "axes[1].set_ylim((0, 7))\n",
    "axes[1].legend(loc='upper center')\n",
    "\n",
    "axes[2].plot(kappa_vals, p_vals_horseshoe_low)#, label=r\"$a_j = 0.1$\")\n",
    "axes[2].plot(kappa_vals, p_vals_horseshoe_medium_low)#, label=r\"$a_j = 0.7$\")\n",
    "axes[2].plot(kappa_vals, p_vals_horseshoe)#, label=r\"$a_j = 1$\")\n",
    "axes[2].plot(kappa_vals, p_vals_horseshoe_medium_high)#, label=r\"$a_j = 2$\")\n",
    "axes[2].plot(kappa_vals, p_vals_horseshoe_high)#, label=r\"$a_j = 5$\")\n",
    "#axes[2].set_ylabel(r\"$p(\\kappa \\mid \\sigma, \\tau)$\")\n",
    "axes[2].set_xlabel(r\"$\\kappa$\")\n",
    "axes[2].set_title(\"Horseshoe\")\n",
    "axes[2].set_ylim((0, 7))\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=100\n",
    "\n",
    "a= np.linspace(0.001, 10, S)\n",
    "\n",
    "diff = np.zeros(S)\n",
    "\n",
    "for i in range(S):\n",
    "    hyper_val_test = (1/2)*hyper([1, 1/2], [2], 1-a[i]**2)\n",
    "    E_k = 1/(1+a[i])\n",
    "    \n",
    "    diff[i] = hyper_val_test - E_k\n",
    "\n",
    "print(np.sum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_expectation_theory(alpha, beta, a, k, s):\n",
    "    poch = lambda x, n: gamma(x + n) / gamma(x)   # (x)_n for real n\n",
    "    return poch(alpha, k) / poch(alpha + beta, k) * hyper([a, k + alpha], [alpha + beta + k], -s)\n",
    "\n",
    "# --- set parameters ---\n",
    "p=10\n",
    "alpha, beta = 0.1, (p-1)*alpha\n",
    "a, k, s     = 1, 1/2, 1.0      # require s > -1\n",
    "n, seed     = 100_000, 123\n",
    "# ----------------------\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "xi = rng.beta(alpha, beta, size=n)\n",
    "vals = xi**k / (1 + s*xi)**a\n",
    "emp_mean = float(vals.mean())\n",
    "emp_std  = float(vals.std(ddof=1))\n",
    "se       = emp_std / np.sqrt(n)\n",
    "theory   = float(beta_expectation_theory(alpha, beta, a, k, s))\n",
    "diff, z  = emp_mean - theory, (emp_mean - theory) / se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, mpmath as mp\n",
    "\n",
    "def poch(x, n):  # rising factorial (x)_n for real n\n",
    "    return mp.gamma(x + n) / mp.gamma(x)\n",
    "\n",
    "def theory_beta_sqrt(alpha, beta, s):\n",
    "    t1 = mp.hyp2f1(1, alpha, alpha + beta, s**2)\n",
    "    t2 = s * poch(alpha, 0.5) / poch(alpha + beta, 0.5) * mp.hyp2f1(1, alpha + 0.5, alpha + beta + 0.5, s**2)\n",
    "    return t1 - t2\n",
    "\n",
    "def empirical_estimate(alpha, beta, s, n=100_000, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    xi = rng.beta(alpha, beta, size=n)\n",
    "    vals = 1.0 / (1.0 + s * np.sqrt(xi))\n",
    "    m = float(vals.mean())\n",
    "    se = float(vals.std(ddof=1) / np.sqrt(n))\n",
    "    return m, se\n",
    "\n",
    "# --- set parameters ---\n",
    "p=10\n",
    "alpha, beta = 0.1, (p-1)*alpha\n",
    "s, n, seed  = 1.0, 100_000, 123  # require s > -1\n",
    "# ----------------------\n",
    "\n",
    "theory = float(theory_beta_sqrt(alpha, beta, s))\n",
    "emp, se = empirical_estimate(alpha, beta, s, n, seed)\n",
    "diff, z = emp - theory, (emp - theory) / se\n",
    "\n",
    "\n",
    "print(\"theory\", np.round(theory, 5), \"\\nempirical\", np.round(emp, 5), \"\\nabs_diff\", np.round(diff, 5), \"\\nSE_MC\", np.round(se, 5), \"\\nz_score\", np.round(z, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/friedman/Friedman_N100_p10_sigma1.00_seed1.npz\"\n",
    "data = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------- 1) Simuler X ----------\n",
    "def simulate_X(n, P, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.uniform(0.0, 1.0, size=(n, P))\n",
    "\n",
    "# ---------- 2) Aktivering og derivert ----------\n",
    "def get_activation(activation=\"tanh\"):\n",
    "    if activation == \"tanh\":\n",
    "        phi = np.tanh\n",
    "        def dphi(a): return 1.0 - np.tanh(a)**2\n",
    "    elif activation == \"relu\":\n",
    "        def phi(a): return np.maximum(0.0, a)\n",
    "        def dphi(a): return (a > 0.0).astype(a.dtype)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation: {activation}\")\n",
    "    return phi, dphi\n",
    "\n",
    "# ---------- 3) Hovedfunksjon: q for alle trekk ----------\n",
    "def compute_q_for_fit(cmdstan_mcmc, N=1000, activation=\"tanh\", seed=1, output_index=0, X=None):\n",
    "    \"\"\"\n",
    "    Beregn q_{ell, j} for første-lagsvektene for hver trekk (draw).\n",
    "    Returnerer:\n",
    "      q_draws:  (n_draws, H, P)\n",
    "      q_mean:   (H, P)  – gjennomsnitt over trekk\n",
    "      X:        (N, P)  – datasettet brukt i beregningen\n",
    "    \"\"\"\n",
    "    # Hent ut variabler fra Stan\n",
    "    W1_all = cmdstan_mcmc.stan_variable(\"W_1\")            # (draws, P, H)\n",
    "    WL_all = cmdstan_mcmc.stan_variable(\"W_L\")             # (draws, H, O)\n",
    "    hb_all = cmdstan_mcmc.stan_variable(\"hidden_bias\")     # (draws, L, H)\n",
    "    sigma_all = cmdstan_mcmc.stan_variable(\"sigma\")        # (draws,)\n",
    "    Wint_all = cmdstan_mcmc.stan_variable(\"W_internal\")    # (draws, max(L-1,1), H, H)\n",
    "\n",
    "    draws, P, H = W1_all.shape\n",
    "    O = WL_all.shape[2]\n",
    "    L = hb_all.shape[1]\n",
    "\n",
    "    if O == 0:\n",
    "        raise ValueError(\"W_L has zero output nodes. Expected at least 1.\")\n",
    "    if output_index < 0 or output_index >= O:\n",
    "        raise ValueError(f\"output_index {output_index} out of range 0..{O-1}\")\n",
    "\n",
    "    if X is None:\n",
    "        X = simulate_X(N, P, seed=seed)\n",
    "\n",
    "    X_sq = X**2\n",
    "    phi, dphi = get_activation(activation)\n",
    "\n",
    "    q_draws = np.empty((draws, H, P), dtype=float)\n",
    "\n",
    "    for s in range(draws):\n",
    "        W1 = W1_all[s]            # (P, H)\n",
    "        WL = WL_all[s]            # (H, O)\n",
    "        hb = hb_all[s]            # (L, H)\n",
    "        Wints = Wint_all[s]       # (max(L-1,1), H, H)\n",
    "        sigma = float(sigma_all[s])\n",
    "\n",
    "        # ----- Forward pass -----\n",
    "        a_list = []\n",
    "        h_list = []\n",
    "\n",
    "        a = X @ W1 + hb[0]        # (N, H)\n",
    "        h = phi(a)\n",
    "        a_list.append(a); h_list.append(h)\n",
    "\n",
    "        for l in range(1, L):\n",
    "            Wl = Wints[l-1]       # (H, H)\n",
    "            a = h @ Wl + hb[l]    # (N, H)\n",
    "            h = phi(a)\n",
    "            a_list.append(a); h_list.append(h)\n",
    "\n",
    "        # ----- Backward: delta_L = d f / d a^(L) -----\n",
    "        # lineær utgang: df/dh^(L) = WL[:, output_index]\n",
    "        v = WL[:, output_index]           # (H,)\n",
    "        delta = dphi(a_list[-1]) * v      # (N, H), broadcast over N\n",
    "\n",
    "        # Bakover gjennom skjulte lag\n",
    "        for l in range(L-2, -1, -1):\n",
    "            Wnext = Wints[l]              # (H, H) – brukes bare hvis L>1\n",
    "            delta = (delta @ Wnext.T) * dphi(a_list[l]) if L > 1 else delta\n",
    "\n",
    "        delta1 = delta  # (N, H) == ∂f/∂a^(1)\n",
    "\n",
    "        # ----- q: (1/sigma^2) * sum_i (delta1[i,ell]^2 * X[i,j]^2) -----\n",
    "        D_sq = delta1**2                  # (N, H)\n",
    "        Q = (X_sq.T @ D_sq) / (sigma**2)  # (P, H)\n",
    "        q_draws[s] = Q.T                  # (H, P)\n",
    "\n",
    "    q_mean = q_draws.mean(axis=0)         # (H, P)\n",
    "    return q_draws, q_mean, X\n",
    "\n",
    "# ---------- 4) Eksempelbruk ----------\n",
    "# Velg riktig fit-objekt (CmdStanMCMC) fra dict-en din:\n",
    "prior_q_dhs, prior_q_mean_dhs, X_train = compute_q_for_fit(\n",
    "    prior_fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "posterior_q_dhs, posterior_q_mean_dhs, X_train = compute_q_for_fit(\n",
    "    posterior_N100_fits['Dirichlet Horseshoe tanh']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "prior_q_dst, prior_q_mean_dst, X_train = compute_q_for_fit(\n",
    "    prior_fits['Dirichlet Student T']['Dirichlet Student T']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "posterior_q_dst, posterior_q_mean_dst, X_train = compute_q_for_fit(\n",
    "    posterior_N100_fits['Dirichlet Student T tanh']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "prior_q_rhs, prior_q_mean_rhs, X_train = compute_q_for_fit(\n",
    "    prior_fits['Regularized Horseshoe']['Regularized Horseshoe']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "posterior_q_rhs, posterior_q_mean_rhs, X_train = compute_q_for_fit(\n",
    "    posterior_N100_fits['Regularized Horseshoe tanh']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "prior_q_gauss, prior_q_mean_gauss, X_train = compute_q_for_fit(\n",
    "    prior_fits['Gaussian']['Gaussian']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "posterior_q_gauss, posterior_q_mean_gauss, X_train = compute_q_for_fit(\n",
    "    posterior_N100_fits['Gaussian tanh']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")\n",
    "\n",
    "prior_q_gamma, prior_q_mean_gamma, X_train = compute_q_for_fit(\n",
    "    prior_fits['Dirichlet Gamma']['Dirichlet Gamma']['posterior'],\n",
    "    N=1000,             \n",
    "    activation='tanh',  \n",
    "    seed=123,\n",
    "    output_index=0,\n",
    "    X = data[\"X_train\"]      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- choose which node/input to inspect ----\n",
    "node_idx = 1\n",
    "input_idx = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Horseshoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- PRIOR --------\n",
    "prior_fit = prior_fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior']\n",
    "tau_prior = prior_fit.stan_variable(\"tau\")                                   # (draws_prior,)\n",
    "lam_prior = prior_fit.stan_variable(\"lambda_tilde_data\")[:, :, node_idx][:, input_idx]  # (draws_prior,)\n",
    "phi_prior = prior_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]           # (draws_prior,)\n",
    "q_prior   = prior_q_dhs[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "\n",
    "# -------- POSTERIOR --------\n",
    "post_fit = posterior_N100_fits['Dirichlet Horseshoe tanh']['posterior']\n",
    "tau_post = post_fit.stan_variable(\"tau\")                                      # (draws_post,)\n",
    "lam_post = post_fit.stan_variable(\"lambda_tilde_data\")[:, :, node_idx][:, input_idx]    # (draws_post,)\n",
    "phi_post = post_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]             # (draws_post,)\n",
    "q_post   = posterior_q_dhs[:, node_idx, input_idx]                           # (draws_post,)\n",
    "\n",
    "kappa_DHS_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * (lam_prior**2) * (phi_prior**2))\n",
    "kappa_DHS_post = 1.0 / (1.0 + q_post * (tau_post**2) * (lam_post**2) * (phi_post**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Student T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- PRIOR --------\n",
    "prior_fit = prior_fits['Dirichlet Student T']['Dirichlet Student T']['posterior']\n",
    "tau_prior = prior_fit.stan_variable(\"tau\")                                   # (draws_prior,)\n",
    "lam_prior = prior_fit.stan_variable(\"lambda_tilde\")[:, :, node_idx][:, input_idx]  # (draws_prior,)\n",
    "phi_prior = prior_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]           # (draws_prior,)\n",
    "q_prior   = prior_q_dhs[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "\n",
    "# -------- POSTERIOR --------\n",
    "post_fit = posterior_N100_fits['Dirichlet Student T tanh']['posterior']\n",
    "tau_post = post_fit.stan_variable(\"tau\")                                      # (draws_post,)\n",
    "lam_post = post_fit.stan_variable(\"lambda_tilde_data\")[:, :, node_idx][:, input_idx]    # (draws_post,)\n",
    "phi_post = post_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]             # (draws_post,)\n",
    "q_post   = posterior_q_dhs[:, node_idx, input_idx]                           # (draws_post,)\n",
    "\n",
    "\n",
    "kappa_DST_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * (lam_prior**2) * (phi_prior**2))\n",
    "kappa_DST_post = 1.0 / (1.0 + q_post * (tau_post**2) * (lam_post**2) * (phi_post**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- PRIOR --------\n",
    "prior_fit = prior_fits['Dirichlet Gamma']['Dirichlet Gamma']['posterior']\n",
    "tau_prior = prior_fit.stan_variable(\"tau\")                                   # (draws_prior,)\n",
    "lam_prior = prior_fit.stan_variable(\"lambda_data\")[:, :, node_idx][:, input_idx]  # (draws_prior,)\n",
    "phi_prior = prior_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]           # (draws_prior,)\n",
    "q_prior   = prior_q_gamma[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "\n",
    "\n",
    "kappa_DG_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * (lam_prior**2) * (phi_prior**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Horseshoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_fit = prior_fits['Regularized Horseshoe']['Regularized Horseshoe']['posterior']\n",
    "tau_prior = prior_fit.stan_variable(\"tau\")                                   # (draws_prior,)\n",
    "lam_prior = prior_fit.stan_variable(\"lambda_tilde\")[:, :, node_idx][:, input_idx]  # (draws_prior,)\n",
    "q_prior   = prior_q_rhs[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "\n",
    "post_rhs_fit = posterior_N100_fits['Regularized Horseshoe tanh']['posterior']\n",
    "tau_rhs_post = post_rhs_fit.stan_variable(\"tau\")                                      # (draws_post,)\n",
    "lam_rhs_post = post_rhs_fit.stan_variable(\"lambda_tilde\")[:, :, node_idx][:, input_idx]    # (draws_post,)\n",
    "q_rhs_post   = posterior_q_rhs[:, node_idx, input_idx]                           # (draws_post,)\n",
    "\n",
    "kappa_HS_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * (lam_prior**2))\n",
    "kappa_HS_post = 1.0 / (1.0 + q_rhs_post * (tau_rhs_post**2) * (lam_rhs_post**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_prior   = prior_q_gauss[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "\n",
    "q_gauss_post   = posterior_q_gauss[:, node_idx, input_idx]                           # (draws_post,)\n",
    "\n",
    "kappa_gauss_prior = 1.0 / (1.0 + q_prior)\n",
    "kappa_gauss_post = 1.0 / (1.0 + q_gauss_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Plot: prior vs posterior overlays --------\n",
    "bins = np.linspace(0.0, 1.0, 40)  # common bins so densities are comparable\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "# Horseshoe\n",
    "axes[0, 0].hist(kappa_gauss_prior, bins=bins, density=True, alpha=0.45, label=\"Prior\")\n",
    "axes[0, 0].hist(kappa_gauss_post,  bins=bins, density=True, alpha=0.45, label=\"Posterior\")\n",
    "axes[0, 0].set_title(\"Gaussian\")\n",
    "axes[0, 0].set_xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Horseshoe\n",
    "axes[0, 1].hist(kappa_HS_prior, bins=bins, density=True, alpha=0.45, label=\"Prior\")\n",
    "axes[0, 1].hist(kappa_HS_post,  bins=bins, density=True, alpha=0.45, label=\"Posterior\")\n",
    "axes[0, 1].set_title(\"RHS\")\n",
    "axes[0, 1].set_xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Dirichlet–Horseshoe\n",
    "axes[1, 0].hist(kappa_DHS_prior, bins=bins, density=True, alpha=0.45, label=\"Prior\")\n",
    "axes[1, 0].hist(kappa_DHS_post,  bins=bins, density=True, alpha=0.45, label=\"Posterior\")\n",
    "axes[1, 0].set_title(\"DHS\")\n",
    "axes[1, 0].set_xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "axes[1, 0].set_ylabel(\"Density\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Dirichlet–Horseshoe\n",
    "axes[1, 1].hist(kappa_DST_prior, bins=bins, density=True, alpha=0.45, label=\"Prior\")\n",
    "axes[1, 1].hist(kappa_DST_post,  bins=bins, density=True, alpha=0.45, label=\"Posterior\")\n",
    "axes[1, 1].set_title(\"DS-T\")\n",
    "axes[1, 1].set_xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "\n",
    "plt.suptitle(f\"Node {node_idx}, input {input_idx}\")#: Prior vs Posterior\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.hist(kappa_DG_prior, bins=50, density=True, alpha=0.45, label=\"Dirichlet Gamma prior\")\n",
    "plt.legend()\n",
    "#plt.xlim(3, 50)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "colors = {\n",
    "    \"Gaussian\": \"C0\",\n",
    "    \"RHS\": \"C1\",\n",
    "    \"DHS\": \"C2\",\n",
    "    \"DS-T\": \"C3\",\n",
    "}\n",
    "\n",
    "# Plot linjene\n",
    "sns.kdeplot(kappa_gauss_prior, linestyle=\"--\", color=colors[\"Gaussian\"])\n",
    "sns.kdeplot(kappa_gauss_post, linestyle=\"-\",  color=colors[\"Gaussian\"])\n",
    "sns.kdeplot(kappa_HS_prior, linestyle=\"--\", color=colors[\"RHS\"])\n",
    "sns.kdeplot(kappa_HS_post, linestyle=\"-\",  color=colors[\"RHS\"])\n",
    "sns.kdeplot(kappa_DHS_prior, linestyle=\"--\", color=colors[\"DHS\"])\n",
    "sns.kdeplot(kappa_DHS_post, linestyle=\"-\",  color=colors[\"DHS\"])\n",
    "sns.kdeplot(kappa_DST_prior, linestyle=\"--\", color=colors[\"DS-T\"])\n",
    "sns.kdeplot(kappa_DST_post, linestyle=\"-\",  color=colors[\"DS-T\"])\n",
    "\n",
    "plt.xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Prior shrinkage factors – KDE\")\n",
    "\n",
    "# --- Lag legend ---\n",
    "# Farger (modeller)\n",
    "model_handles = [Line2D([0], [0], color=color, lw=2, label=model) \n",
    "                 for model, color in colors.items()]\n",
    "\n",
    "# Linjestil (prior/posterior)\n",
    "style_handles = [\n",
    "    Line2D([0], [0], color=\"black\", linestyle=\"--\", lw=2, label=\"Prior\"),\n",
    "    Line2D([0], [0], color=\"black\", linestyle=\"-\",  lw=2, label=\"Posterior\")\n",
    "]\n",
    "\n",
    "# Kombiner\n",
    "handles = model_handles + style_handles\n",
    "labels = [h.get_label() for h in handles]\n",
    "\n",
    "plt.legend(handles=handles, labels=labels, title=\"Model / Distribution\", ncol=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(x):\n",
    "    x = np.sort(x)\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    return x, y\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for data, name in [(kappa_gauss_prior,\"Gaussian\"),\n",
    "                   (kappa_HS_prior,\"RHS\"),\n",
    "                   (kappa_DHS_prior,\"DHS\"),\n",
    "                   (kappa_DST_prior,\"DS-T\")]:\n",
    "    x,y = ecdf(data)\n",
    "    plt.plot(x,y,label=name)\n",
    "plt.xlabel(r\"$\\kappa_{\\ell j}$\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.title(\"Empirical CDFs of $\\kappa$ under priors\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized versions\n",
    "\n",
    "For the Regularized Horseshoe, when $c<\\infty$. the shrinkage profile becomes approximately equivalent to that of the horseshoe shifted from the interval $(0, 1)$ to $(b_{\\ell, j}, 1)$ where $b_{\\ell, j}=\\frac{1}{q_{\\ell, j}\\tau{\\ell}^2c^2}$. The shrinkage factor then approximately satisfies $\\tilde{\\kappa}_{\\ell, j}=(1-b_j)\\kappa_{\\ell, j} + b_j$ where $\\tilde{\\kappa}_{\\ell, j}$ is the shrinkage factor of the original horseshoe. From this we get $1-\\tilde{\\kappa}_{\\ell, j}=(1-b_j)(1-\\kappa_{\\ell, j})$. Assuming roughly the same scale of inputs, then $b_{\\ell, j}=b_{\\ell}$ and the effective model complexity becomes $\\tilde{m}_{\\ell, eff}=(1-b_{\\ell}) m_{\\ell, eff}$ where $m_{\\ell, eff}=\\sum_{j=1}^p(1-\\kappa_{\\ell, j})$ denotes the effective number of nonzero weights into node $l$ (I THINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- PRIOR --------\n",
    "prior_fit = prior_fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior']\n",
    "tau_prior = prior_fit.stan_variable(\"tau\")                                   # (draws_prior,)\n",
    "lam_prior = prior_fit.stan_variable(\"lambda_tilde_data\")[:, :, node_idx][:, input_idx]  # (draws_prior,)\n",
    "phi_prior = prior_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]           # (draws_prior,)\n",
    "q_prior   = prior_q_dhs[:, node_idx, input_idx]                               # (draws_prior,)\n",
    "c_sq = prior_fit.stan_variable(\"c_sq\")[:, node_idx]\n",
    "\n",
    "b_j_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * c_sq)\n",
    "\n",
    "# -------- POSTERIOR --------\n",
    "post_fit = posterior_N100_fits['Dirichlet Horseshoe tanh']['posterior']\n",
    "tau_post = post_fit.stan_variable(\"tau\")                                      # (draws_post,)\n",
    "lam_post = post_fit.stan_variable(\"lambda_tilde_data\")[:, :, node_idx][:, input_idx]    # (draws_post,)\n",
    "phi_post = post_fit.stan_variable(\"phi_data\")[:, :, node_idx][:, input_idx]             # (draws_post,)\n",
    "q_post   = posterior_q_dhs[:, node_idx, input_idx]                           # (draws_post,)\n",
    "\n",
    "\n",
    "kappa_DHS_prior = 1.0 / (1.0 + q_prior * (tau_prior**2) * (lam_prior**2) * (phi_prior**2))\n",
    "kappa_DHS_post = 1.0 / (1.0 + q_post * (tau_post**2) * (lam_post**2) * (phi_post**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.hist(b_j_prior, bins=50, density=True, alpha=0.45, label=\"b_j\")\n",
    "plt.legend()\n",
    "#plt.xlim(3, 50)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(kappa_DHS_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
