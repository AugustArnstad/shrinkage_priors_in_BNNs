{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = 1\n",
    "data_dir = f\"datasets/type_{data_config}\"\n",
    "#results_dir_relu_extremely_slow = \"results_relu_exhaustive/extremely_slow\"\n",
    "#results_dir_relu_slow = \"results_relu_exhaustive/slow\"\n",
    "results_dir_relu = \"results_relu_exhaustive\"\n",
    "\n",
    "model_names_relu = [\"Dirichlet Horseshoe\", \"Regularized Horseshoe\", \"Gaussian\"] #[\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Gaussian\", \"Dirichlet Student T\"]\n",
    "\n",
    "relu_fits = {}\n",
    "relu_slow_fits = {}\n",
    "relu_extremely_slow_fits = {}\n",
    "\n",
    "for model in model_names_relu:\n",
    "    base_config_name = \"GAM_N100_p8_sigma3.00_seed4\" #fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"type_{data_config}/{base_config_name}\"  # → \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    \n",
    "    fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=[model],\n",
    "        include_prior=False,\n",
    "    )\n",
    "\n",
    "    # slow_fit = get_model_fits(\n",
    "    #     config=full_config_path,\n",
    "    #     results_dir=results_dir_relu_slow,\n",
    "    #     models=[model],\n",
    "    #     include_prior=False,\n",
    "    # )    \n",
    "    \n",
    "    # extremely_slow_fit = get_model_fits(\n",
    "    #     config=full_config_path,\n",
    "    #     results_dir=results_dir_relu_extremely_slow,\n",
    "    #     models=[model],\n",
    "    #     include_prior=False,\n",
    "    # )\n",
    "    \n",
    "    relu_fits[model] = fit\n",
    "    #relu_slow_fits[model] = slow_fit\n",
    "    #relu_extremely_slow_fits[model] = extremely_slow_fit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmdstanpy \n",
    "import arviz as az\n",
    "\n",
    "gauss_fit = relu_fits['Gaussian']['Gaussian']['posterior']\n",
    "idata = az.from_cmdstanpy(gauss_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent gaussian transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "\n",
    "rhs_fit = relu_fits['Regularized Horseshoe']['Regularized Horseshoe']['posterior']\n",
    "idata = az.from_cmdstanpy(rhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent RHS transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "\n",
    "dhs_fit = relu_fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior']\n",
    "idata = az.from_cmdstanpy(dhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent DHS transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 1: Load your fit and diagnostics\n",
    "idata = az.from_cmdstanpy(dhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values.flatten()  # shape: (n_draws,)\n",
    "\n",
    "# Step 2: Extract output of interest — shape (n_draws, N_test)\n",
    "output_test = dhs_fit.stan_variable(\"output_test\")  # shape: (samples, N_test)\n",
    "\n",
    "# Choose a subset of outputs to visualize\n",
    "selected_outputs = {\n",
    "    f\"Ey[{i}]\": output_test[:, i]\n",
    "    for i in range(min(4, output_test.shape[1]))  # Limit to 4 for clarity\n",
    "}\n",
    "\n",
    "# Step 3: Convert to InferenceData\n",
    "idata_output = az.from_dict(\n",
    "    posterior=selected_outputs,\n",
    "    sample_stats={\"diverging\": divergent.astype(bool)}\n",
    ")\n",
    "\n",
    "# Step 4: Plot pairwise comparisons for the output\n",
    "az.plot_pair(\n",
    "    idata_output,\n",
    "    var_names=list(selected_outputs.keys()),\n",
    "    kind='scatter',\n",
    "    divergences=True,\n",
    "    marginal_kwargs={'fill_last': True}\n",
    ")\n",
    "plt.suptitle(\"Divergences in output_test space\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    N = 100 if seed in [1, 2, 3, 4] else 200\n",
    "    sigma = 1.0 if seed in [1, 2, 7, 8] else 3.0\n",
    "    if seed == 19:\n",
    "        N, sigma = 1000, 1.0\n",
    "    return N, sigma\n",
    "\n",
    "def get_all_convergence_diagnostics(all_fits):\n",
    "    diagnostics = []\n",
    "\n",
    "\n",
    "    for model_name, fit in all_fits.items():\n",
    "        try:\n",
    "            idata = az.from_cmdstanpy(fit[model_name]['posterior'])\n",
    "            y_pred = fit[model_name]['posterior'].stan_variable('output_test')\n",
    "            \n",
    "            path = f'datasets/type_{data_config}/GAM_N100_p8_sigma3.00_seed4.npz'\n",
    "            try:\n",
    "                data = np.load(path)\n",
    "                y_test = data[\"y_test\"]\n",
    "            except FileNotFoundError:\n",
    "                print(f\"[SKIP] File not found: {path}\")\n",
    "                continue\n",
    "            \n",
    "            #idata = az.from_cmdstanpy(fit)\n",
    "            divergent = idata.sample_stats[\"diverging\"].values  # shape: (n_chains, n_draws)\n",
    "            divergent_flat = divergent.flatten()  # shape: (8000,)\n",
    "            y_pred_no_div = y_pred[~divergent_flat]\n",
    "            \n",
    "            S = y_pred.shape[0]\n",
    "            rmses = np.zeros(S)\n",
    "            rmses_no_div = np.zeros(S - np.sum(divergent_flat))\n",
    "            \n",
    "            for i in range(S):\n",
    "                rmses[i] = np.sqrt(np.mean((y_pred[i].squeeze() - y_test.squeeze()) ** 2))\n",
    "            \n",
    "            for i in range(S - np.sum(divergent_flat)):\n",
    "                rmses_no_div[i] = np.sqrt(np.mean((y_pred_no_div[i].squeeze() - y_test.squeeze()) ** 2))\n",
    "\n",
    "            summary = az.summary(idata, var_names=[\"output\"], round_to=3)\n",
    "            \n",
    "            rhat = summary[\"r_hat\"]\n",
    "\n",
    "            ess_bulk = summary[\"ess_bulk\"]\n",
    "            ess_tail = summary[\"ess_tail\"]\n",
    "            \n",
    "\n",
    "            N, sigma = 100, 1\n",
    "\n",
    "            diagnostics.append({\n",
    "                #\"config\": config_name,\n",
    "                \"model\": model_name,\n",
    "                \"max_rhat\": rhat.max(),\n",
    "                \"median_rhat\": rhat.median(),\n",
    "                #\"p95_rhat\": rhat.quantile(0.95),\n",
    "                \"rmse\": np.mean(rmses, axis=0),\n",
    "                \"rmse_no_div\": np.mean(rmses_no_div, axis=0),\n",
    "                #\"min_ess_bulk\": ess_bulk.min(),\n",
    "                \"median_ess_bulk\": ess_bulk.median(),\n",
    "                #\"p05_ess_bulk\": ess_bulk.quantile(0.05),\n",
    "                #\"min_ess_tail\": ess_tail.min(),\n",
    "                \"median_ess_tail\": ess_tail.median(),\n",
    "                \"N\": N,\n",
    "                \"sigma\": sigma,\n",
    "                #\"p05_ess_tail\": ess_tail.quantile(0.05),\n",
    "                #\"n_divergent\": divergences\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            diagnostics.append({\n",
    "                #\"config\": config_name,\n",
    "                \"model\": model_name,\n",
    "                \"max_rhat\": np.nan,\n",
    "                \"median_rhat\": np.nan,\n",
    "                #\"p95_rhat\": np.nan,\n",
    "                #\"min_ess_bulk\": np.nan,\n",
    "                #\"min_ess_tail\": np.nan,\n",
    "                #\"n_divergent\": np.nan,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(diagnostics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_diagostic = get_all_convergence_diagnostics(relu_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_diagostic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
