{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = 1\n",
    "data_dir = f\"datasets/type_{data_config}\"\n",
    "results_dir = \"results_relu_exhaustive\"\n",
    "model_names = [\"Dirichlet Horseshoe\"]\n",
    "\n",
    "dhs_08_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"type_{data_config}/{base_config_name}\"  # → \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    fits = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir,\n",
    "        models=model_names,\n",
    "        include_prior=False,\n",
    "    )\n",
    "\n",
    "    dhs_08_fits[base_config_name] = fits  # use clean key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = 1\n",
    "data_dir = f\"datasets/type_{data_config}\"\n",
    "results_dir = \"results_relu_exhaustive/slow\"\n",
    "model_names = [\"Dirichlet Horseshoe\"]\n",
    "\n",
    "dhs_095_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"type_{data_config}/{base_config_name}\"  # → \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    fits = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir,\n",
    "        models=model_names,\n",
    "        include_prior=False,\n",
    "    )\n",
    "\n",
    "    dhs_095_fits[base_config_name] = fits  # use clean key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    N = 100 if seed in [1, 2, 3, 4] else 200\n",
    "    sigma = 1.0 if seed in [1, 2, 7, 8] else 3.0\n",
    "    if seed == 19:\n",
    "        N, sigma = 1000, 1.0\n",
    "    return N, sigma\n",
    "\n",
    "def get_all_convergence_diagnostics(all_fits):\n",
    "    diagnostics = []\n",
    "\n",
    "    for config_name, model_fits in all_fits.items():\n",
    "        for model_name, fit in model_fits.items():\n",
    "            try:\n",
    "                # ArviZ inference data\n",
    "                idata = az.from_cmdstanpy(fit['posterior'])\n",
    "                y_pred = fit['posterior'].stan_variable('output_test')\n",
    "                \n",
    "                path = f'datasets/type_{data_config}/{config_name}.npz'\n",
    "                try:\n",
    "                    data = np.load(path)\n",
    "                    y_test = data[\"y_test\"]\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"[SKIP] File not found: {path}\")\n",
    "                    continue\n",
    "                \n",
    "                S = y_pred.shape[0]\n",
    "                rmses = np.zeros(S)\n",
    "                for i in range(S):\n",
    "                   rmses[i] = np.sqrt(np.mean((y_pred.squeeze() - y_test.squeeze()) ** 2))\n",
    "\n",
    "                # Summary statistics\n",
    "                summary = az.summary(idata, var_names=[\"output\"], round_to=3)\n",
    "                \n",
    "                # R-hat and ESS per parameter\n",
    "                rhat = summary[\"r_hat\"]\n",
    "                \n",
    "                #rhat_max = summary[\"r_hat\"].max()\n",
    "                ess_bulk = summary[\"ess_bulk\"]\n",
    "                ess_tail = summary[\"ess_tail\"]\n",
    "                \n",
    "                # Parse seed from config_name\n",
    "                try:\n",
    "                    seed = int(config_name.split(\"_seed\")[-1])\n",
    "                    N, sigma = get_N_sigma(seed)\n",
    "                except:\n",
    "                    N, sigma = np.nan, np.nan\n",
    "\n",
    "                # diagnostics.append({\n",
    "                #     \"model\": model_name,\n",
    "                #     \"seed\": seed,\n",
    "                #     \"N\": N,\n",
    "                #     \"sigma\": sigma,\n",
    "                #     \"max_rhat\": rhat.max(),\n",
    "                #     \"median_rhat\": rhat.median(),\n",
    "                #     \"p95_rhat\": rhat.quantile(0.95),\n",
    "                #     \"rmse\": np.mean(rmses)\n",
    "                # })\n",
    "\n",
    "                diagnostics.append({\n",
    "                    #\"config\": config_name,\n",
    "                    \"model\": model_name,\n",
    "                    \"max_rhat\": rhat.max(),\n",
    "                    \"median_rhat\": rhat.median(),\n",
    "                    \"p95_rhat\": rhat.quantile(0.95),\n",
    "                    \"rmse\": np.mean(rmses, axis=0),\n",
    "                    #\"min_ess_bulk\": ess_bulk.min(),\n",
    "                    \"median_ess_bulk\": ess_bulk.median(),\n",
    "                    #\"p05_ess_bulk\": ess_bulk.quantile(0.05),\n",
    "                    #\"min_ess_tail\": ess_tail.min(),\n",
    "                    \"median_ess_tail\": ess_tail.median(),\n",
    "                    #\"p05_ess_tail\": ess_tail.quantile(0.05),\n",
    "                    #\"n_divergent\": divergences\n",
    "                    \"N\": N,\n",
    "                    \"sigma\": sigma,\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                diagnostics.append({\n",
    "                    #\"config\": config_name,\n",
    "                    \"model\": model_name,\n",
    "                    \"max_rhat\": np.nan,\n",
    "                    \"median_rhat\": np.nan,\n",
    "                    \"p95_rhat\": np.nan,\n",
    "                    \"min_ess_bulk\": np.nan,\n",
    "                    \"min_ess_tail\": np.nan,\n",
    "                    #\"n_divergent\": np.nan,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(diagnostics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_08_diagostic = get_all_convergence_diagnostics(dhs_08_fits)\n",
    "dhs_095_diagostic = get_all_convergence_diagnostics(dhs_095_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_08_diagostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_095_diagostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a shared-axes figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# First subplot: δ = 0.8\n",
    "sns.scatterplot(\n",
    "    data=dhs_08_diagostic,\n",
    "    x=\"max_rhat\", y=\"rmse\",\n",
    "    hue=\"sigma\",\n",
    "    #style=\"model\",\n",
    "    size=\"N\", sizes=(100, 300),\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(r\"$\\delta = 0.8$\")\n",
    "axes[0].set_xlabel(r\"Max $\\hat{R}$\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "\n",
    "# Second subplot: δ = 0.95\n",
    "sns.scatterplot(\n",
    "    data=dhs_095_diagostic,\n",
    "    x=\"max_rhat\", y=\"rmse\",\n",
    "    hue=\"sigma\",\n",
    "    #style=\"model\",\n",
    "    size=\"N\", sizes=(100, 300),\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(r\"$\\delta = 0.95$\")\n",
    "axes[1].set_xlabel(r\"Max $\\hat{R}$\")\n",
    "axes[1].set_ylabel(\"\")  # shared y-axis, so don't repeat\n",
    "\n",
    "# Clean layout\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arviz as az\n",
    "dhs_08_fit = dhs_08_fits['GAM_N100_p8_sigma1.00_seed1']['Dirichlet Horseshoe']['posterior']\n",
    "dhs_095_fit = dhs_095_fits['GAM_N100_p8_sigma1.00_seed1']['Dirichlet Horseshoe']['posterior']\n",
    "# Suppose this is your array of shape (8000, 80, 1)\n",
    "output_samples_08 = dhs_08_fit.stan_variable(\"output\")  \n",
    "output_samples_08 = output_samples_08.squeeze(-1)  # Now shape (8000, 80)\n",
    "\n",
    "output_samples_095 = dhs_08_fit.stan_variable(\"output\")  \n",
    "output_samples_095 = output_samples_08.squeeze(-1)  # Now shape (8000, 80)\n",
    "\n",
    "# Create a dict: One key per observation\n",
    "output_dict_08 = {\n",
    "    f\"output[{i}]\": output_samples_08[:, i]\n",
    "    for i in range(output_samples_08.shape[1])\n",
    "}\n",
    "\n",
    "# Create a dict: One key per observation\n",
    "output_dict_095 = {\n",
    "    f\"output[{i}]\": output_samples_095[:, i]\n",
    "    for i in range(output_samples_095.shape[1])\n",
    "}\n",
    "\n",
    "# Convert to InferenceData object\n",
    "idata_output_08 = az.from_dict(posterior=output_dict_08)\n",
    "az.plot_trace(idata_output_08, var_names=[\"output[0]\"])\n",
    "\n",
    "# Convert to InferenceData object\n",
    "idata_output_095 = az.from_dict(posterior=output_dict_095)\n",
    "az.plot_trace(idata_output_095, var_names=[\"output[0]\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
