{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/friedman\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/friedman\"\n",
    "model_names_relu = [\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "model_names_tanh = [\"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "\n",
    "fits_relu = {}\n",
    "fits_tanh = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # â†’ \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=model_names_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    tanh_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh,\n",
    "        models=model_names_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "\n",
    "    fits_relu[base_config_name] = relu_fit \n",
    "    fits_tanh[base_config_name] = tanh_fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_correlated = f\"datasets/friedman_correlated\"\n",
    "results_dir_correlated_relu = \"results/regression/single_layer/relu/friedman_correlated\"\n",
    "results_dir_correlated_tanh = \"results/regression/single_layer/tanh/friedman_correlated\"\n",
    "model_names_correlated_relu = [\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "model_names_correlated_tanh = [\"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "\n",
    "relu_fits_correlated = {}\n",
    "tanh_fits_correlated = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir_correlated) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # â†’ \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit_correlated = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_correlated_relu,\n",
    "        models=model_names_correlated_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fit_correlated = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_correlated_tanh,\n",
    "        models=model_names_correlated_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "    relu_fits_correlated[base_config_name] = relu_fit_correlated\n",
    "    tanh_fits_correlated[base_config_name] = tanh_fit_correlated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils.generate_data import generate_Friedman_data, generate_correlated_Friedman_data\n",
    "from utils.sparsity import forward_pass_tanh, forward_pass_relu\n",
    "import numpy as np\n",
    "\n",
    "def crps_from_samples(y_test, y_pred, return_distribution=False):\n",
    "    \"\"\"\n",
    "    CRPS for posterior predictive samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : array, shape (N,)\n",
    "        True test targets\n",
    "    y_pred : array, shape (S, N)\n",
    "        Posterior predictive samples\n",
    "    return_distribution : bool\n",
    "        If True, also return CRPS per test point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    crps_mean : float\n",
    "        Mean CRPS across test points\n",
    "    crps_se : float\n",
    "        Standard error of CRPS across test points\n",
    "    crps_per_point : array, optional, shape (N,)\n",
    "        Returned if return_distribution=True\n",
    "    \"\"\"\n",
    "\n",
    "    y_test = np.asarray(y_test)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    S, N = y_pred.shape\n",
    "    assert y_test.shape[0] == N\n",
    "\n",
    "    # E|Y - y|\n",
    "    term1 = np.mean(np.abs(y_pred - y_test[None, :]), axis=0)\n",
    "\n",
    "    # E|Y - Y'|\n",
    "    # Efficient computation via sorting\n",
    "    term2 = np.empty(N)\n",
    "    for i in range(N):\n",
    "        ys = np.sort(y_pred[:, i])\n",
    "        term2[i] = np.mean(\n",
    "            np.abs(ys[:, None] - ys[None, :])\n",
    "        )\n",
    "\n",
    "    crps_per_point = term1 - 0.5 * term2\n",
    "\n",
    "    crps_mean = crps_per_point.mean()\n",
    "    crps_se = crps_per_point.std(ddof=1) / np.sqrt(N)\n",
    "\n",
    "    if return_distribution:\n",
    "        return crps_mean, crps_se, crps_per_point\n",
    "\n",
    "    return crps_mean, crps_se\n",
    "\n",
    "def evaluate_posterior_on_multiple_testsets(\n",
    "    fits,\n",
    "    models,\n",
    "    forward_pass,\n",
    "    seeds,\n",
    "    data_func = generate_Friedman_data\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for test_id in seeds:\n",
    "        _, X_test, _, y_test = data_func(\n",
    "            N=200, D=10, sigma=1.0, test_size=0.2, seed=test_id, standardize_y=True\n",
    "        )\n",
    "\n",
    "        X_test_np = X_test\n",
    "        y_test_np = y_test.reshape(-1)\n",
    "\n",
    "        for model in models:\n",
    "            fit = fits[model][\"posterior\"]\n",
    "\n",
    "            W1_samples = fit.stan_variable(\"W_1\")\n",
    "            W2_samples = fit.stan_variable(\"W_L\")\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")\n",
    "\n",
    "            S = W1_samples.shape[0]\n",
    "            y_hats = np.zeros((S, y_test_np.shape[0]))\n",
    "            rmse = np.zeros((S))\n",
    "\n",
    "            for i in range(S):\n",
    "                y_hat = forward_pass(\n",
    "                    X_test_np,\n",
    "                    W1_samples[i],\n",
    "                    np.asarray(b1_samples[i]).reshape(-1),\n",
    "                    W2_samples[i],\n",
    "                    np.asarray(b2_samples[i]).reshape(-1),\n",
    "                )\n",
    "                y_hats[i] = y_hat.squeeze()\n",
    "                \n",
    "                #rmse[i] = np.sqrt(mean_squared_error(y_test_np, y_hats[i]))\n",
    "                \n",
    "            #crps_mean, crps_std = crps_from_samples(y_test, y_hats)\n",
    "            y_mean = y_hats.mean(axis=0)\n",
    "            posterior_rmse = np.sqrt(mean_squared_error(y_test_np, y_mean))\n",
    "\n",
    "            rows.append({\n",
    "                \"model\": model,\n",
    "                \"test_set\": test_id,\n",
    "                \"posterior_rmse\": posterior_rmse,\n",
    "                #\"crps_mean\": crps_mean,\n",
    "                #\"crps_std\": crps_std\n",
    "                #\"mean_rmse\": rmse.mean(axis=0)\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # ðŸ”¹ THIS is the only new part\n",
    "    df_rmse_mean = (\n",
    "        df.groupby(\"model\", as_index=False)[\"posterior_rmse\"]\n",
    "          .mean()\n",
    "          .rename(columns={\"posterior_rmse\": \"mean_rmse_over_testsets\"})\n",
    "    )\n",
    "    df_crps_mean = pd.DataFrame(rows)\n",
    "    # df_crps_mean = (\n",
    "    #     df.groupby(\"model\", as_index=False)\n",
    "    #     .agg(\n",
    "    #         mean_crps_over_testsets=(\"crps_mean\", \"mean\"),\n",
    "    #         se_crps_over_testsets=(\"crps_std\",\n",
    "    #                                 lambda x: np.sqrt(np.sum(x**2)) / len(x))\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    return df_rmse_mean, df_crps_mean, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [100, 101, 102, 103, 104]\n",
    "\n",
    "friedman_fits_smallest_relu = list((fits_relu['Friedman_N50_p10_sigma1.00_seed16']).keys())\n",
    "friedman_fits_small_relu = list((fits_relu['Friedman_N100_p10_sigma1.00_seed1']).keys())\n",
    "friedman_fits_medium_relu = list((fits_relu['Friedman_N200_p10_sigma1.00_seed2']).keys())\n",
    "friedman_fits_large_relu = list((fits_relu['Friedman_N500_p10_sigma1.00_seed11']).keys())\n",
    "\n",
    "\n",
    "df_results_smallest_relu, df_crps_smallest_relu, df_smallest_relu = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_relu['Friedman_N50_p10_sigma1.00_seed16'],\n",
    "    models=friedman_fits_smallest_relu,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_small_relu, df_crps_small_relu, df_small_relu = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_relu['Friedman_N100_p10_sigma1.00_seed1'],\n",
    "    models=friedman_fits_small_relu,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_medium_relu, df_crps_medium_relu, df_medium_relu = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_relu['Friedman_N200_p10_sigma1.00_seed2'],\n",
    "    models=friedman_fits_medium_relu,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_large_relu, df_crps_large_relu, df_large_relu = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_relu['Friedman_N500_p10_sigma1.00_seed11'],\n",
    "    models=friedman_fits_large_relu,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "\n",
    "friedman_fits_smallest_tanh = list((fits_tanh['Friedman_N50_p10_sigma1.00_seed16']).keys())\n",
    "friedman_fits_small_tanh = list((fits_tanh['Friedman_N100_p10_sigma1.00_seed1']).keys())\n",
    "friedman_fits_medium_tanh = list((fits_tanh['Friedman_N200_p10_sigma1.00_seed2']).keys())\n",
    "friedman_fits_large_tanh = list((fits_tanh['Friedman_N500_p10_sigma1.00_seed11']).keys())\n",
    "\n",
    "\n",
    "df_results_smallest_tanh, df_crps_smallest_tanh, df_smallest_tanh = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_tanh['Friedman_N50_p10_sigma1.00_seed16'],\n",
    "    models=friedman_fits_smallest_tanh,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_small_tanh, df_crps_small_tanh, df_small_tanh = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_tanh['Friedman_N100_p10_sigma1.00_seed1'],\n",
    "    models=friedman_fits_small_tanh,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_medium_tanh, df_crps_medium_tanh, df_medium_tanh = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_tanh['Friedman_N200_p10_sigma1.00_seed2'],\n",
    "    models=friedman_fits_medium_tanh,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_large_tanh, df_crps_large_tanh, df_large_tanh = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=fits_tanh['Friedman_N500_p10_sigma1.00_seed11'],\n",
    "    models=friedman_fits_large_tanh,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [100, 101, 102, 103, 104]\n",
    "\n",
    "friedman_fits_smallest_relu_c = list((relu_fits_correlated['Friedman_N50_p10_sigma1.00_seed16']).keys())\n",
    "friedman_fits_small_relu_c = list((relu_fits_correlated['Friedman_N100_p10_sigma1.00_seed1']).keys())\n",
    "friedman_fits_medium_relu_c = list((relu_fits_correlated['Friedman_N200_p10_sigma1.00_seed6']).keys())\n",
    "friedman_fits_large_relu_c = list((relu_fits_correlated['Friedman_N500_p10_sigma1.00_seed11']).keys())\n",
    "\n",
    "\n",
    "df_results_smallest_relu_c, df_crps_smallest_relu_c, df_smallest_relu_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=relu_fits_correlated['Friedman_N50_p10_sigma1.00_seed16'],\n",
    "    models=friedman_fits_smallest_relu_c,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_small_relu_c, df_crps_small_relu_c, df_small_relu_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=relu_fits_correlated['Friedman_N100_p10_sigma1.00_seed1'],\n",
    "    models=friedman_fits_small_relu_c,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_medium_relu_c, df_crps_medium_relu_c, df_medium_relu_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=relu_fits_correlated['Friedman_N200_p10_sigma1.00_seed6'],\n",
    "    models=friedman_fits_medium_relu_c,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_large_relu_c, df_crps_large_relu_c, df_large_relu_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=relu_fits_correlated['Friedman_N500_p10_sigma1.00_seed11'],\n",
    "    models=friedman_fits_large_relu_c,\n",
    "    forward_pass=forward_pass_relu,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "\n",
    "friedman_fits_smallest_tanh_c = list((tanh_fits_correlated['Friedman_N50_p10_sigma1.00_seed16']).keys())\n",
    "friedman_fits_small_tanh_c = list((tanh_fits_correlated['Friedman_N100_p10_sigma1.00_seed1']).keys())\n",
    "friedman_fits_medium_tanh_c = list((tanh_fits_correlated['Friedman_N200_p10_sigma1.00_seed6']).keys())\n",
    "friedman_fits_large_tanh_c = list((tanh_fits_correlated['Friedman_N500_p10_sigma1.00_seed11']).keys())\n",
    "\n",
    "\n",
    "df_results_smallest_tanh_c, df_crps_smallest_tanh_c, df_smallest_tanh_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=tanh_fits_correlated['Friedman_N50_p10_sigma1.00_seed16'],\n",
    "    models=friedman_fits_smallest_tanh_c,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_small_tanh_c, df_crps_small_tanh_c, df_small_tanh_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=tanh_fits_correlated['Friedman_N100_p10_sigma1.00_seed1'],\n",
    "    models=friedman_fits_small_tanh_c,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_medium_tanh_c, df_crps_medium_tanh_c, df_medium_tanh_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=tanh_fits_correlated['Friedman_N200_p10_sigma1.00_seed6'],\n",
    "    models=friedman_fits_medium_tanh_c,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n",
    "\n",
    "df_results_large_tanh_c, df_crps_large_tanh_c, df_large_tanh_c = evaluate_posterior_on_multiple_testsets(\n",
    "    fits=tanh_fits_correlated['Friedman_N500_p10_sigma1.00_seed11'],\n",
    "    models=friedman_fits_large_tanh_c,\n",
    "    forward_pass=forward_pass_tanh,\n",
    "    seeds=seeds,\n",
    "    data_func=generate_Friedman_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_results_smallest_relu.assign(activation = \"relu\", N=50, setting='Original')\n",
    "df_2 = df_results_small_relu.assign(activation = \"relu\", N=100, setting='Original')\n",
    "df_3 = df_results_medium_relu.assign(activation = \"relu\", N=200, setting='Original')\n",
    "df_4 = df_results_large_relu.assign(activation = \"relu\", N=500, setting='Original')\n",
    "\n",
    "df_5 = df_results_smallest_relu_c.assign(activation = \"relu\", N=50, setting='Correlated')\n",
    "df_6 = df_results_small_relu_c.assign(activation = \"relu\", N=100, setting='Correlated')\n",
    "df_7 = df_results_medium_relu_c.assign(activation = \"relu\", N=200, setting='Correlated')\n",
    "df_8 = df_results_large_relu_c.assign(activation = \"relu\", N=500, setting='Correlated')\n",
    "\n",
    "df_9 = df_results_smallest_tanh.assign(activation = \"tanh\", N=50, setting='Original')\n",
    "df_10 = df_results_small_tanh.assign(activation = \"tanh\", N=100, setting='Original')\n",
    "df_11 = df_results_medium_tanh.assign(activation = \"tanh\", N=200, setting='Original')\n",
    "df_12 = df_results_large_tanh.assign(activation = \"tanh\", N=500, setting='Original')\n",
    "\n",
    "df_13 = df_results_smallest_tanh_c.assign(activation = \"tanh\", N=50, setting='Correlated')\n",
    "df_14 = df_results_small_tanh_c.assign(activation = \"tanh\", N=100, setting='Correlated')\n",
    "df_15 = df_results_medium_tanh_c.assign(activation = \"tanh\", N=200, setting='Correlated')\n",
    "df_16 = df_results_large_tanh_c.assign(activation = \"tanh\", N=500, setting='Correlated')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8,\n",
    "                    df_9, df_10, df_11, df_12, df_13, df_14, df_15, df_16], ignore_index=True)\n",
    "# df_all = pd.concat([df_1, df_2, df_5, df_6,\n",
    "#                      df_9, df_10, df_13, df_14], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# --- prepare data ---\n",
    "df = df_all.copy()\n",
    "\n",
    "abbr = {\n",
    "    \"Regularized Horseshoe\": \"RHS\",\n",
    "    \"Dirichlet Horseshoe\": \"DHS\",\n",
    "    \"Dirichlet Student T\": \"DST\",\n",
    "    \"Beta Horseshoe\": \"BHS\",\n",
    "    \"Beta Student T\": \"BST\",\n",
    "}\n",
    "\n",
    "# unify model names across activations (strip \" tanh\")\n",
    "df[\"model_clean\"] = df[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "#df[\"model_clean\"] = df[\"model_clean\"].str.replace(\" nodewise\", \"\", regex=False)\n",
    "# summary stats per (setting, N, model, activation)\n",
    "summary = (\n",
    "    df.groupby([\"setting\", \"N\", \"model_clean\", \"activation\"], as_index=False)[\"mean_rmse_over_testsets\"]\n",
    "      .agg(mean=\"mean\", std=\"std\")\n",
    ")\n",
    "\n",
    "# plotting order\n",
    "settings = [\"Original\", \"Correlated\"]\n",
    "Ns = [50, 100, 200, 500]\n",
    "models = [\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "\n",
    "# visuals\n",
    "markers = {\"tanh\": \"o\", \"relu\": \"X\"}            # shapes\n",
    "offsets = {\"tanh\": -0.12, \"relu\": +0.12}        # side-by-side jitter on x\n",
    "model_offsets = {\n",
    "    \"Regularized Horseshoe\": -0.07,\n",
    "    \"Dirichlet Horseshoe\": -0.03,\n",
    "    \"Dirichlet Student T\": 0.00,\n",
    "    \"Beta Horseshoe\": +0.03,\n",
    "    \"Beta Student T\": +0.07,\n",
    "}\n",
    "palette_list = plt.get_cmap(\"tab10\").colors\n",
    "palette = {m: palette_list[i+1] for i, m in enumerate(models)}\n",
    "\n",
    "# map N to base x positions and add offsets for activation\n",
    "xbase = {N: i for i, N in enumerate(Ns)}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "ax_num = 0\n",
    "for ax, setting in zip(axes, settings):\n",
    "    sub = summary[summary[\"setting\"] == setting]\n",
    "    # plot each model+activation with errorbars, without lines\n",
    "    for m in models:\n",
    "        for act in [\"tanh\", \"relu\"]:\n",
    "            g = sub[(sub[\"model_clean\"] == m) & (sub[\"activation\"] == act)]\n",
    "            if g.empty:\n",
    "                continue\n",
    "            #xs = [xbase[n] + offsets[act] for n in g[\"N\"]]\n",
    "            xs = [xbase[n] + offsets[act] + model_offsets[m] for n in g[\"N\"]]\n",
    "\n",
    "            ax.errorbar(\n",
    "                xs, g[\"mean\"], yerr=g[\"std\"],\n",
    "                fmt=markers[act], markersize=12,\n",
    "                linestyle=\"none\", capsize=3,\n",
    "                color=palette[m], markeredgecolor=\"black\"\n",
    "            )\n",
    "    ax.set_title(f\"{setting}\", fontsize=15)\n",
    "    ax.set_xticks(range(len(Ns)))\n",
    "    ax.set_xticklabels(Ns, fontsize=15)\n",
    "    ax.set_xlabel(\"N\", fontsize=15)\n",
    "    if ax_num == 0:\n",
    "        ax.set_ylabel(\"RMSE\", fontsize=15)\n",
    "    ax.grid()\n",
    "    ax_num += 1\n",
    "\n",
    "# --- legends ---\n",
    "model_handles = [\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\",\n",
    "        linestyle=\"none\",\n",
    "        color=palette[m],\n",
    "        markeredgecolor=\"black\",\n",
    "        markersize=12,\n",
    "        label=abbr.get(m, m)   # <- use abbreviation\n",
    "    )\n",
    "    for m in models\n",
    "]\n",
    "\n",
    "# activation legend (shapes)\n",
    "activation_handles = [\n",
    "    Line2D([0], [0], marker=markers[\"tanh\"], linestyle=\"none\", color=\"black\",\n",
    "           markersize=12, label=\"tanh\"),\n",
    "    Line2D([0], [0], marker=markers[\"relu\"], linestyle=\"none\", color=\"black\",\n",
    "           markersize=12, label=\"ReLU\"),\n",
    "]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend(\n",
    "        handles=model_handles + activation_handles,\n",
    "        title=None,\n",
    "        loc=\"upper right\",\n",
    "        frameon=False,\n",
    "        ncol=1,\n",
    "        fontsize=15\n",
    "    )\n",
    "plt.tight_layout(rect=(0, 0, 1, 1))\n",
    "#plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crps_1 = df_crps_smallest_relu.assign(activation = \"relu\", N=50, setting='Original')\n",
    "df_crps_2 = df_crps_small_relu.assign(activation = \"relu\", N=100, setting='Original')\n",
    "# df_crps_3 = df_crps_medium_relu.assign(activation = \"relu\", N=200, setting='Original')\n",
    "# df_crps_4 = df_crps_large_relu.assign(activation = \"relu\", N=500, setting='Original')\n",
    "\n",
    "df_crps_5 = df_crps_smallest_relu_c.assign(activation = \"relu\", N=50, setting='Correlated')\n",
    "df_crps_6 = df_crps_small_relu_c.assign(activation = \"relu\", N=100, setting='Correlated')\n",
    "# df_crps_7 = df_crps_medium_relu_c.assign(activation = \"relu\", N=200, setting='Correlated')\n",
    "# df_crps_8 = df_crps_large_relu_c.assign(activation = \"relu\", N=500, setting='Correlated')\n",
    "\n",
    "df_crps_9 = df_crps_smallest_tanh.assign(activation = \"tanh\", N=50, setting='Original')\n",
    "df_crps_10 = df_crps_small_tanh.assign(activation = \"tanh\", N=100, setting='Original')\n",
    "# df_crps_11 = df_crps_medium_tanh.assign(activation = \"tanh\", N=200, setting='Original')\n",
    "# df_crps_12 = df_crps_large_tanh.assign(activation = \"tanh\", N=500, setting='Original')\n",
    "\n",
    "df_crps_13 = df_crps_smallest_tanh_c.assign(activation = \"tanh\", N=50, setting='Correlated')\n",
    "df_crps_14 = df_crps_small_tanh_c.assign(activation = \"tanh\", N=100, setting='Correlated')\n",
    "# df_crps_15 = df_crps_medium_tanh_c.assign(activation = \"tanh\", N=200, setting='Correlated')\n",
    "# df_crps_16 = df_crps_large_tanh_c.assign(activation = \"tanh\", N=500, setting='Correlated')\n",
    "\n",
    "# df_crps = pd.concat([df_crps_1, df_crps_2, df_crps_3, df_crps_4, df_crps_5, df_crps_6, df_crps_7, df_crps_8,\n",
    "#                     df_crps_9, df_crps_10, df_crps_11, df_crps_12, df_crps_13, df_crps_14, df_crps_15, df_crps_16], ignore_index=True)\n",
    "\n",
    "df_crps = pd.concat([df_crps_1, df_crps_2, df_crps_5, df_crps_6,\n",
    "                     df_crps_9, df_crps_10, df_crps_13, df_crps_14], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# --- prepare data ---\n",
    "df = df_crps.copy()\n",
    "\n",
    "abbr = {\n",
    "    \"Regularized Horseshoe\": \"RHS\",\n",
    "    \"Dirichlet Horseshoe\": \"DHS\",\n",
    "    \"Dirichlet Student T\": \"DST\",\n",
    "    \"Beta Horseshoe\": \"BHS\",\n",
    "    \"Beta Student T\": \"BST\",\n",
    "}\n",
    "\n",
    "# unify model names across activations (strip \" tanh\")\n",
    "df[\"model_clean\"] = df[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "#df[\"model_clean\"] = df[\"model_clean\"].str.replace(\" nodewise\", \"\", regex=False)\n",
    "# summary stats per (setting, N, model, activation)\n",
    "# summary = (\n",
    "#     df.groupby([\"setting\", \"N\", \"model_clean\", \"activation\"], as_index=False)[\"mean_crps_over_testsets\"]\n",
    "#       .agg(mean=\"mean\", std=\"std\")\n",
    "# )\n",
    "\n",
    "# plotting order\n",
    "settings = [\"Original\", \"Correlated\"]\n",
    "Ns = [50, 100, 200, 500]\n",
    "models = [\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "\n",
    "# visuals\n",
    "markers = {\"tanh\": \"o\", \"relu\": \"X\"}            # shapes\n",
    "offsets = {\"tanh\": -0.12, \"relu\": +0.12}        # side-by-side jitter on x\n",
    "model_offsets = {\n",
    "    \"Regularized Horseshoe\": -0.07,\n",
    "    \"Dirichlet Horseshoe\": -0.03,\n",
    "    \"Dirichlet Student T\": 0.00,\n",
    "    \"Beta Horseshoe\": +0.03,\n",
    "    \"Beta Student T\": +0.07,\n",
    "}\n",
    "palette_list = plt.get_cmap(\"tab10\").colors\n",
    "palette = {m: palette_list[i+1] for i, m in enumerate(models)}\n",
    "\n",
    "# map N to base x positions and add offsets for activation\n",
    "xbase = {N: i for i, N in enumerate(Ns)}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "ax_num = 0\n",
    "for ax, setting in zip(axes, settings):\n",
    "    sub = df[df[\"setting\"] == setting]\n",
    "    # plot each model+activation with errorbars, without lines\n",
    "    for m in models:\n",
    "        for act in [\"tanh\", \"relu\"]:\n",
    "            g = sub[(sub[\"model_clean\"] == m) & (sub[\"activation\"] == act)]\n",
    "            if g.empty:\n",
    "                continue\n",
    "            #xs = [xbase[n] + offsets[act] for n in g[\"N\"]]\n",
    "            xs = [xbase[n] + offsets[act] + model_offsets[m] for n in g[\"N\"]]\n",
    "\n",
    "            ax.errorbar(\n",
    "                xs, g[\"mean_crps_over_testsets\"], yerr=g[\"se_crps_over_testsets\"],\n",
    "                fmt=markers[act], markersize=12,\n",
    "                linestyle=\"none\", capsize=3,\n",
    "                color=palette[m], markeredgecolor=\"black\"\n",
    "            )\n",
    "    ax.set_title(f\"{setting}\", fontsize=15)\n",
    "    ax.set_xticks(range(len(Ns)))\n",
    "    ax.set_xticklabels(Ns, fontsize=15)\n",
    "    ax.set_xlabel(\"N\", fontsize=15)\n",
    "    if ax_num == 0:\n",
    "        ax.set_ylabel(\"CRPS\", fontsize=15)\n",
    "    ax.grid()\n",
    "    ax_num += 1\n",
    "\n",
    "# --- legends ---\n",
    "model_handles = [\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\",\n",
    "        linestyle=\"none\",\n",
    "        color=palette[m],\n",
    "        markeredgecolor=\"black\",\n",
    "        markersize=12,\n",
    "        label=abbr.get(m, m)   # <- use abbreviation\n",
    "    )\n",
    "    for m in models\n",
    "]\n",
    "\n",
    "# activation legend (shapes)\n",
    "activation_handles = [\n",
    "    Line2D([0], [0], marker=markers[\"tanh\"], linestyle=\"none\", color=\"black\",\n",
    "           markersize=12, label=\"tanh\"),\n",
    "    Line2D([0], [0], marker=markers[\"relu\"], linestyle=\"none\", color=\"black\",\n",
    "           markersize=12, label=\"ReLU\"),\n",
    "]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend(\n",
    "        handles=model_handles + activation_handles,\n",
    "        title=None,\n",
    "        loc=\"upper right\",\n",
    "        frameon=False,\n",
    "        ncol=1,\n",
    "        fontsize=15\n",
    "    )\n",
    "plt.tight_layout(rect=(0, 0, 1, 1))\n",
    "#plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "def compute_sparse_rmse_results(seeds, models, all_fits, get_N_sigma, forward_pass, folder,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        N, sigma = get_N_sigma(seed)\n",
    "        dataset_key = f'Friedman_N{N}_p10_sigma{sigma:.2f}_seed{seed}'\n",
    "        path = f\"datasets/{folder}/{dataset_key}.npz\"\n",
    "\n",
    "        try:\n",
    "            data = np.load(path)\n",
    "            X_test, y_test = data[\"X_test\"], data[\"y_test\"]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[SKIP] File not found: {path}\")\n",
    "            continue\n",
    "\n",
    "        for model in models:\n",
    "            try:\n",
    "                fit = all_fits[dataset_key][model]['posterior']\n",
    "                W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "                W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "                b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "                b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "            except KeyError:\n",
    "                print(f\"[SKIP] Model or posterior not found: {dataset_key} -> {model}\")\n",
    "                continue\n",
    "\n",
    "            S = W1_samples.shape[0]\n",
    "            rmses = np.zeros(S)\n",
    "            #print(y_test.shape)\n",
    "            y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "            for i in range(S):\n",
    "                W1 = W1_samples[i]\n",
    "                W2 = W2_samples[i]\n",
    "\n",
    "                # Apply pruning mask if requested\n",
    "                if prune_fn is not None and sparsity > 0.0:\n",
    "                    masks = prune_fn([W1, W2], sparsity)\n",
    "                    W1 = W1 * masks[0]\n",
    "                    #W2 = W2 * masks[1]\n",
    "\n",
    "                y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "                y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "                rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "                \n",
    "            posterior_mean = np.mean(y_hats, axis=0)\n",
    "            posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "            posterior_means.append({\n",
    "                'seed': seed,\n",
    "                'N': N,\n",
    "                'sigma': sigma,\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'posterior_mean_rmse': posterior_mean_rmse\n",
    "            })\n",
    "\n",
    "            for i in range(S):\n",
    "                results.append({\n",
    "                    'seed': seed,\n",
    "                    'N': N,\n",
    "                    'sigma': sigma,\n",
    "                    'model': model,\n",
    "                    'sparsity': sparsity,\n",
    "                    'rmse': rmses[i]\n",
    "                })\n",
    "\n",
    "    df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    return df_rmse, df_posterior_rmse\n",
    "\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "seeds = [1, 2, 11, 16]\n",
    "seeds_correlated = [1, 6, 11, 16]\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    if seed == 1:\n",
    "        N=100\n",
    "    elif seed == 2:\n",
    "        N=200\n",
    "    elif seed == 16:\n",
    "        N=50\n",
    "    else:\n",
    "        N=500\n",
    "    sigma=1.00\n",
    "    return N, sigma\n",
    "\n",
    "def get_N_sigma_correlated(seed):\n",
    "    if seed == 1:\n",
    "        N=100\n",
    "    elif seed == 6:\n",
    "        N=200\n",
    "    elif seed == 16:\n",
    "        N=50\n",
    "    else:\n",
    "        N=500\n",
    "    sigma=1.00\n",
    "    return N, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_sparse, df_posterior_rmse_sparse = {}, {}\n",
    "df_rmse_sparse_correlated, df_posterior_rmse_sparse_correlated = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    df_rmse_sparse[sparsity], df_posterior_rmse_sparse[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds, model_names_correlated_tanh, fits_tanh, get_N_sigma, forward_pass_tanh, folder = \"friedman\",\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )\n",
    "    \n",
    "    df_rmse_sparse_correlated[sparsity], df_posterior_rmse_sparse_correlated[sparsity] = compute_sparse_rmse_results(\n",
    "        seeds_correlated, model_names_correlated_tanh, tanh_fits_correlated, get_N_sigma_correlated, forward_pass_tanh, folder = \"friedman_correlated\",\n",
    "        sparsity=sparsity, prune_fn=local_prune_weights\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_rmse_full = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_posterior_rmse_sparse.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_correlated = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_posterior_rmse_sparse_correlated.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_local_o = df_rmse_full.copy()\n",
    "df_local_o[\"model\"] = df_local_o[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "df_local_c = df_rmse_full_correlated.copy()\n",
    "df_local_c[\"model\"] = df_local_c[\"model\"].str.replace(\" tanh\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "palette_list = plt.get_cmap(\"tab10\").colors\n",
    "palette = {m: palette_list[i+1] for i, m in enumerate(models)}\n",
    "\n",
    "def make_merged_df(\n",
    "    df_local_o, df_local_c,\n",
    "    drop_tanh_suffix=True\n",
    "):\n",
    "    \"\"\"Return one long df with columns: N, sparsity, rmse, model, activation, setting.\"\"\"\n",
    "    dfs = []\n",
    "    for df, setting in [(df_local_o, \"Original\"), (df_local_c, \"Correlated\")]:\n",
    "        d = df.copy()\n",
    "        if drop_tanh_suffix and \" tanh\" in \"\".join(d[\"model\"].unique()):\n",
    "            d[\"model\"] = d[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "        d[\"activation\"] = \"Tanh\"\n",
    "        d[\"setting\"] = setting\n",
    "        dfs.append(d)\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Keep only models that exist in BOTH activations so legend doesn't show ghosts\n",
    "    models_local = set(out.loc[out.activation==\"Tanh\",\"model\"].unique())\n",
    "    if models_local:\n",
    "        out = out[out[\"model\"].isin(models_local)]\n",
    "    return out\n",
    "\n",
    "df_all = make_merged_df(df_local_o, df_local_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse_one_figure(\n",
    "    df_all,\n",
    "    Ns=(100, 200, 500),\n",
    "    figsize=(12, 7),\n",
    "    title=\"Original vs Correlated\"\n",
    "):\n",
    "    # Orderings\n",
    "    setting_order = [\"Original\", \"Correlated\"]\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams.update({\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"legend.frameon\": True,\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(2, len(Ns), figsize=figsize, sharex=True, sharey=\"col\")\n",
    "    if len(Ns) == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "\n",
    "    for j, Nval in enumerate(Ns):\n",
    "        for i, setting in enumerate(setting_order):\n",
    "            ax = axes[i, j]\n",
    "            dfN = df_all[(df_all[\"N\"] == Nval) & (df_all[\"setting\"] == setting)].copy()\n",
    "\n",
    "            # If empty, hide this subplot\n",
    "            if dfN.empty:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            # Abbreviated labels for models\n",
    "            dfN[\"model_abbr\"] = dfN[\"model\"].map(lambda m: abbr.get(m, m))\n",
    "\n",
    "            # Build a palette keyed by the *abbreviated* model names\n",
    "            color_map = {\n",
    "                abbr[m]: palette[m]\n",
    "                for m in dfN[\"model\"].unique()\n",
    "                if m in palette\n",
    "            }\n",
    "\n",
    "            hue_order = [\n",
    "                abbr[m]\n",
    "                for m in sorted(\n",
    "                    dfN[\"model\"].unique(),\n",
    "                    key=lambda x: list(palette).index(x) if x in palette else 999\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            sns.lineplot(\n",
    "                data=dfN,\n",
    "                x=\"sparsity\",\n",
    "                y=\"posterior_mean_rmse\",\n",
    "                hue=\"model_abbr\",       # color = prior (abbr)\n",
    "                markers=True,\n",
    "                dashes=True,           # single activation, keep lines simple\n",
    "                palette=color_map,\n",
    "                hue_order=hue_order,\n",
    "                errorbar=None,\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"N={Nval}\", fontweight=\"normal\")\n",
    "            ax.set_xlabel(\"Sparsity\")\n",
    "            ax.set_ylabel(\"RMSE\" if j == 0 else \"\")\n",
    "            ax.grid(True, which=\"major\", alpha=0.25)\n",
    "\n",
    "            # Remove per-axes legends; weâ€™ll add one global legend\n",
    "            if ax.legend_:\n",
    "                ax.legend_.remove()\n",
    "\n",
    "    # ---------- Global legend for priors (colors) ----------\n",
    "    models_present = []\n",
    "    for m in [\"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\",\n",
    "              \"Beta Horseshoe\", \"Beta Student T\"]:\n",
    "        if (df_all[\"model\"] == m).any():\n",
    "            models_present.append(m)\n",
    "\n",
    "    prior_handles = [\n",
    "        Line2D(\n",
    "            [0], [0],\n",
    "            color=palette[m],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2,\n",
    "            markersize=7\n",
    "        )\n",
    "        for m in models_present\n",
    "    ]\n",
    "    prior_labels = [abbr[m] for m in models_present]\n",
    "\n",
    "    if prior_handles:\n",
    "        fig.legend(\n",
    "            prior_handles,\n",
    "            prior_labels,\n",
    "            title=\"Prior\",\n",
    "            loc=\"upper center\",\n",
    "            ncol=len(prior_handles),\n",
    "            frameon=True,\n",
    "            bbox_to_anchor=(0.5, 1.02),\n",
    "        )\n",
    "\n",
    "    fig.suptitle(title, y=1.05)\n",
    "    plt.tight_layout(rect=[0.02, 0.02, 0.98, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_rmse_one_figure(df_all,\n",
    "                     Ns=(50, 100, 200, 500),\n",
    "                     title=\"Original vs Correlated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import dirichlet, beta, cauchy\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# dimensions\n",
    "P = 10          # number of coefficients\n",
    "S = 1_000      # prior samples\n",
    "\n",
    "# hyperparameters\n",
    "tau_scale = 1.0\n",
    "alpha_dir = 0.1        # Dirichlet concentration\n",
    "alpha_beta = 0.1      # Beta concentration\n",
    "\n",
    "from scipy.stats import invgamma\n",
    "\n",
    "def regularize_lambda(lambda_, tau, a=2.0, b=4.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Regularized horseshoe:\n",
    "    lambda_tilde = c^2 * lambda^2 / (c^2 + tau^2 * lambda^2)\n",
    "    \"\"\"\n",
    "    S, P = lambda_.shape\n",
    "    c_sq = invgamma.rvs(a=a, scale=b, size=S)  # shape=S\n",
    "\n",
    "    lambda_sq = lambda_**2\n",
    "    tau_sq = tau[:, None]**2\n",
    "\n",
    "    lambda_tilde = (\n",
    "        c_sq[:, None] * lambda_sq\n",
    "        / (c_sq[:, None] + tau_sq * lambda_sq)\n",
    "    )\n",
    "\n",
    "    return np.sqrt(np.maximum(lambda_tilde, eps))\n",
    "\n",
    "def sample_weights_rhs(P, S):\n",
    "    tau = np.abs(cauchy.rvs(scale=tau_scale, size=S))\n",
    "    lambda_ = np.abs(cauchy.rvs(scale=1.0, size=(S, P)))\n",
    "    lambda_reg = regularize_lambda(lambda_, tau)\n",
    "    #xi_raw = beta.rvs(alpha_beta, (P-1)*alpha_beta, size=(S, P))\n",
    "    #xi = xi_raw / xi_raw.sum(axis=1, keepdims=True)\n",
    "    z = np.random.randn(S, P)\n",
    "    w = tau[:, None] * lambda_reg * z\n",
    "    return w\n",
    "\n",
    "def sample_weights_dirichlet(P, S):\n",
    "    tau = np.abs(cauchy.rvs(scale=tau_scale, size=S))\n",
    "    lambda_ = np.abs(cauchy.rvs(scale=1.0, size=(S, P)))\n",
    "    lambda_reg = regularize_lambda(lambda_, tau)\n",
    "    xi = dirichlet.rvs([alpha_dir]*P, size=S)\n",
    "    z = np.random.randn(S, P)\n",
    "    w = tau[:, None] * lambda_reg * np.sqrt(xi) * z\n",
    "    return w\n",
    "\n",
    "def sample_weights_beta(P, S):\n",
    "    tau = np.abs(cauchy.rvs(scale=tau_scale, size=S))\n",
    "    lambda_ = np.abs(cauchy.rvs(scale=1.0, size=(S, P)))\n",
    "    lambda_reg = regularize_lambda(lambda_, tau)\n",
    "    xi_raw = beta.rvs(alpha_beta, (P-1)*alpha_beta, size=(S, P))\n",
    "    xi = xi_raw / xi_raw.sum(axis=1, keepdims=True)\n",
    "    z = np.random.randn(S, P)\n",
    "    w = tau[:, None] * lambda_reg * np.sqrt(xi) * z\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 50\n",
    "w_dir = sample_weights_dirichlet(P, S)\n",
    "w_beta = sample_weights_beta(P, S)\n",
    "w_rhs = sample_weights_rhs(P, S)\n",
    "bins = S/5\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(w_dir[:, 0], bins=int(bins), density=True, alpha=0.5, label=\"Dirichlet Î¾\")\n",
    "plt.hist(w_beta[:, 0], bins=int(bins), density=True, alpha=0.5, label=\"Beta Î¾\")\n",
    "#plt.hist(w_rhs[:, 0], bins=200, density=True, alpha=0.5, label=\"RHS\")\n",
    "#plt.xlim(-1,1)\n",
    "plt.ylim(0, 3)\n",
    "plt.legend()\n",
    "plt.title(\"Marginal prior distribution of weights\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_js_from_hist(samples_p, samples_q, bins=200, range=(-1, 1), eps=1e-12):\n",
    "    \"\"\"\n",
    "    Approximate KL(P||Q) and JS(P,Q) by discretizing both sample sets\n",
    "    onto the same histogram bins over a fixed range.\n",
    "\n",
    "    Returns:\n",
    "        kl_pq, kl_qp, js\n",
    "    \"\"\"\n",
    "    p_counts, bin_edges = np.histogram(samples_p, bins=bins, range=range, density=False)\n",
    "    q_counts, _         = np.histogram(samples_q, bins=bins, range=range, density=False)\n",
    "\n",
    "    # convert to probabilities (discrete)\n",
    "    p = p_counts.astype(float)\n",
    "    q = q_counts.astype(float)\n",
    "\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "\n",
    "    # smooth to avoid zeros (important for KL)\n",
    "    p = np.clip(p, eps, None)\n",
    "    q = np.clip(q, eps, None)\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "\n",
    "    # KL divergences\n",
    "    kl_pq = np.sum(p * np.log(p / q))\n",
    "    kl_qp = np.sum(q * np.log(q / p))\n",
    "\n",
    "    # Jensenâ€“Shannon divergence\n",
    "    m = 0.5 * (p + q)\n",
    "    js = 0.5 * np.sum(p * np.log(p / m)) + 0.5 * np.sum(q * np.log(q / m))\n",
    "\n",
    "    return kl_pq, kl_qp, js\n",
    "\n",
    "# Use the same range you plotted\n",
    "kl_dir_beta, kl_beta_dir, js = kl_js_from_hist(\n",
    "    w_dir[:, 0], w_beta[:, 0],\n",
    "    bins=200, range=(-1, 1), eps=1e-12\n",
    ")\n",
    "\n",
    "print(f\"KL(Dir || Beta) over [-1,1]: {kl_dir_beta:.6g}\")\n",
    "print(f\"KL(Beta || Dir) over [-1,1]: {kl_beta_dir:.6g}\")\n",
    "print(f\"JS(Dir, Beta) over [-1,1]:   {js:.6g}\")\n",
    "\n",
    "# Use the same range you plotted\n",
    "kl_dir_rhs, kl_rhs_dir, js = kl_js_from_hist(\n",
    "    w_dir[:, 0], w_rhs[:, 0],\n",
    "    bins=200, range=(-1, 1), eps=1e-12\n",
    ")\n",
    "\n",
    "print(f\"KL(Dir || RHS) over [-1,1]: {kl_dir_rhs:.6g}\")\n",
    "print(f\"KL(RHS || Dir) over [-1,1]: {kl_rhs_dir:.6g}\")\n",
    "print(f\"JS(Dir, RHS) over [-1,1]:   {js:.6g}\")\n",
    "\n",
    "# Use the same range you plotted\n",
    "kl_beta_rhs, kl_beta_dir, js = kl_js_from_hist(\n",
    "    w_beta[:, 0], w_rhs[:, 0],\n",
    "    bins=200, range=(-1, 1), eps=1e-12\n",
    ")\n",
    "\n",
    "print(f\"KL(Beta || RHS) over [-1,1]: {kl_beta_rhs:.6g}\")\n",
    "print(f\"KL(RHS || Beta) over [-1,1]: {kl_beta_dir:.6g}\")\n",
    "print(f\"JS(Beta, RHS) over [-1,1]:   {js:.6g}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABALONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/abalone\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/abalone\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/abalone\"\n",
    "\n",
    "model_names_relu = [\"Dirichlet Horseshoe\", \"Dirichlet Student T\", \"Beta Horseshoe\", \"Beta Student T\"]\n",
    "model_names_tanh = [\"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\", \"Beta Horseshoe tanh\", \"Beta Student T tanh\"]\n",
    "\n",
    "\n",
    "full_config_path = \"abalone_N3341_p8\"\n",
    "abalone_relu_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_relu,\n",
    "    models=model_names_relu,\n",
    "    include_prior=False,\n",
    ")\n",
    "\n",
    "abalone_tanh_fit = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir_tanh,\n",
    "    models=model_names_tanh,\n",
    "    include_prior=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORTANT: this y_test must correspond to the same test set used to make `output_test` in Stan,\n",
    "# otherwise scores wonâ€™t be comparable.\n",
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "\n",
    "rows = []\n",
    "for model_name, model_entry in abalone_relu_fit.items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    # (S, n_test)\n",
    "    y_samps = post.stan_variable(\"output_test\").squeeze(-1)\n",
    "\n",
    "    # Optional: limit to first S draws if desired\n",
    "    # S = min(4000, y_samps.shape[0])\n",
    "    # y_samps = y_samps[:S]\n",
    "\n",
    "    # Posterior-mean predictions and RMSE\n",
    "    y_mean = y_samps.mean(axis=0)                                   # (n_test,)\n",
    "    rmse_post_mean = float(np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "\n",
    "    # Per-draw RMSEs and their mean\n",
    "    per_draw_rmse = np.sqrt(((y_samps - y_test[None, :])**2).mean(axis=1))  # (S,)\n",
    "    rmse_draw_mean = float(per_draw_rmse.mean())\n",
    "\n",
    "    # CRPS across the ensemble (expects shape (n_test, S))\n",
    "    crps = float(np.mean(crps_ensemble(y_test, y_samps.T)))\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE_posterior_mean\": rmse_post_mean,\n",
    "        \"RMSE_mean_over_draws\": rmse_draw_mean,\n",
    "        \"CRPS\": crps,\n",
    "        \"n_draws\": y_samps.shape[0]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE_posterior_mean\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from properscoring import crps_ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORTANT: this y_test must correspond to the same test set used to make `output_test` in Stan,\n",
    "# otherwise scores wonâ€™t be comparable.\n",
    "from utils.generate_data import load_abalone_regression_data\n",
    "X_train, X_test, y_train, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "\n",
    "rows = []\n",
    "for model_name, model_entry in abalone_tanh_fit.items():\n",
    "    post = model_entry[\"posterior\"]\n",
    "\n",
    "    # (S, n_test)\n",
    "    y_samps = post.stan_variable(\"output_test\").squeeze(-1)\n",
    "\n",
    "    y_mean = y_samps.mean(axis=0)                                   # (n_test,)\n",
    "    rmse_post_mean = float(np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "\n",
    "    # Per-draw RMSEs and their mean\n",
    "    per_draw_rmse = np.sqrt(((y_samps - y_test[None, :])**2).mean(axis=1))  # (S,)\n",
    "    rmse_draw_mean = float(per_draw_rmse.mean())\n",
    "\n",
    "    # CRPS across the ensemble (expects shape (n_test, S))\n",
    "    crps = float(np.mean(crps_ensemble(y_test, y_samps.T)))\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"RMSE_posterior_mean\": rmse_post_mean,\n",
    "        \"RMSE_mean_over_draws\": rmse_draw_mean,\n",
    "        \"CRPS\": crps,\n",
    "        \"n_draws\": y_samps.shape[0]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"RMSE_posterior_mean\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_abalone_regression_data\n",
    "def compute_sparse_rmse_results_abalone(models, all_fits, forward_pass,\n",
    "                         sparsity=0.0, prune_fn=None):\n",
    "    results = []\n",
    "    posterior_means = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            fit = all_fits[model]['posterior']\n",
    "            W1_samples = fit.stan_variable(\"W_1\")           # (S, P, H)\n",
    "            W2_samples = fit.stan_variable(\"W_L\")           # (S, H, O)\n",
    "            b1_samples = fit.stan_variable(\"hidden_bias\")   # (S, O, H)\n",
    "            b2_samples = fit.stan_variable(\"output_bias\")   # (S, O)\n",
    "        except KeyError:\n",
    "            print(f\"[SKIP] Model or posterior not found:\")\n",
    "            continue\n",
    "\n",
    "        S = W1_samples.shape[0]\n",
    "        rmses = np.zeros(S)\n",
    "        #print(y_test.shape)\n",
    "        _, X_test, _, y_test = load_abalone_regression_data(standardized=False, frac=1.0)\n",
    "        y_hats = np.zeros((S, y_test.shape[0]))\n",
    "\n",
    "        for i in range(S):\n",
    "            W1 = W1_samples[i]\n",
    "            W2 = W2_samples[i]\n",
    "\n",
    "            # Apply pruning mask if requested\n",
    "            if prune_fn is not None and sparsity > 0.0:\n",
    "                masks = prune_fn([W1, W2], sparsity)\n",
    "                W1 = W1 * masks[0]\n",
    "                #W2 = W2 * masks[1]\n",
    "\n",
    "            y_hat = forward_pass(X_test, W1, b1_samples[i][0], W2, b2_samples[i])\n",
    "            y_hats[i] = y_hat.squeeze()  # Store the prediction for each sample\n",
    "            rmses[i] = np.sqrt(np.mean((y_hat.squeeze() - y_test)**2))\n",
    "            \n",
    "        posterior_mean = np.mean(y_hats, axis=0)\n",
    "        posterior_mean_rmse = np.sqrt(np.mean((posterior_mean - y_test.squeeze())**2))\n",
    "\n",
    "        posterior_means.append({\n",
    "            'model': model,\n",
    "            'sparsity': sparsity,\n",
    "            'posterior_mean_rmse': posterior_mean_rmse\n",
    "        })\n",
    "\n",
    "        for i in range(S):\n",
    "            results.append({\n",
    "                'model': model,\n",
    "                'sparsity': sparsity,\n",
    "                'rmse': rmses[i]\n",
    "            })\n",
    "\n",
    "    df_rmse = pd.DataFrame(results)\n",
    "    df_posterior_rmse = pd.DataFrame(posterior_means)\n",
    "\n",
    "    return df_rmse, df_posterior_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sparsity import forward_pass_relu, forward_pass_tanh, local_prune_weights\n",
    "\n",
    "sparsity_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "df_rmse_relu, df_posterior_rmse_relu = {}, {}\n",
    "df_rmse_tanh, df_posterior_rmse_tanh = {}, {}\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    df_rmse_relu[sparsity], df_posterior_rmse_relu[sparsity] = compute_sparse_rmse_results_abalone(\n",
    "        models = model_names_relu,\n",
    "        all_fits = abalone_relu_fit, \n",
    "        forward_pass = forward_pass_relu,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n",
    "\n",
    "    df_rmse_tanh[sparsity], df_posterior_rmse_tanh[sparsity] = compute_sparse_rmse_results_abalone(\n",
    "        models = model_names_tanh,\n",
    "        all_fits = abalone_tanh_fit, \n",
    "        forward_pass = forward_pass_tanh,\n",
    "        sparsity=sparsity, \n",
    "        prune_fn=local_prune_weights\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "df_rmse_full_relu = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_relu.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_rmse_full_tanh = pd.concat(\n",
    "    [df.assign(sparsity=sparsity) for sparsity, df in df_rmse_tanh.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Plot (simplified version)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "custom_palette = {\n",
    "    \"Dirichlet Horseshoe\": \"C2\",\n",
    "    \"Dirichlet Student T\": \"C3\",\n",
    "    \"Beta Horseshoe\": \"C4\",\n",
    "    \"Beta Student T\": \"C5\",\n",
    "}\n",
    "abbr = {\n",
    "    \"Dirichlet Horseshoe\": \"DHS\",\n",
    "    \"Dirichlet Student T\": \"DST\",\n",
    "    \"Beta Horseshoe\": \"BHS\",\n",
    "    \"Beta Student T\": \"BST\",\n",
    "    #\"Pred CP\": \"PCP\"\n",
    "}\n",
    "# Clean names\n",
    "df_rmse_full_relu[\"model\"] = df_rmse_full_relu[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "df_rmse_full_tanh[\"model\"] = df_rmse_full_tanh[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "activation_data = [(\"ReLU\", df_rmse_full_relu), (\"tanh\", df_rmse_full_tanh)]\n",
    "\n",
    "for ax, (name, df) in zip(axes, activation_data):\n",
    "    df[\"model_abbr\"] = df[\"model\"].map(lambda m: abbr.get(m, m))\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x='sparsity', y='rmse',\n",
    "        hue='model_abbr', marker='o', errorbar=None, ax=ax,\n",
    "        #palette=custom_palette,\n",
    "        palette={abbr[k]: v for k, v in custom_palette.items() if k in df[\"model\"].unique()},\n",
    "        hue_order=[abbr[m] for m in sorted(df[\"model\"].unique(), key=lambda x: list(custom_palette).index(x) if x in custom_palette else 999)],\n",
    "    )\n",
    "    \n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Sparsity level\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(title=\"Model\", loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
