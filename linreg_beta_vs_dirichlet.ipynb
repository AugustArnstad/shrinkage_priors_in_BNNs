{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import load_linreg_dataset\n",
    "def generate_linreg_simple_data(\n",
    "    N=250,\n",
    "    p=3,\n",
    "    rho=0.0,\n",
    "    sigma=1.0,\n",
    "    seed=123\n",
    "):\n",
    "\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- Sparse true coefficients ---\n",
    "    beta_true = np.array([0.2] + [0.0]*(p-1))\n",
    "    beta_true = beta_true[:p]  # ensure correct dimension\n",
    "\n",
    "    if rho == 0.0:\n",
    "        # Independent predictors\n",
    "        X = np.random.normal(0, 1, size=(N, p))\n",
    "    else:\n",
    "        # Correlated predictors\n",
    "        Sigma = rho ** np.abs(np.subtract.outer(np.arange(p), np.arange(p)))\n",
    "        L = np.linalg.cholesky(Sigma)\n",
    "        X = np.random.normal(size=(N, p)) @ L.T\n",
    "\n",
    "    # --- Generate y ---\n",
    "    noise = np.random.normal(0.0, sigma, size=N)\n",
    "    y = X @ beta_true + noise\n",
    "\n",
    "    return X, y, beta_true\n",
    "\n",
    "N=250\n",
    "seed=1\n",
    "X, y, beta_true = generate_linreg_simple_data(\n",
    "    N=N,\n",
    "    p=3,\n",
    "    rho=0.9,\n",
    "    sigma=1.0,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "save_dir = f\"datasets/linreg/linreg_data_beta_dirichlet_2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.savez(\n",
    "    f\"{save_dir}.npz\",\n",
    "    X=X,\n",
    "    y=y,\n",
    "    N=N,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test, meta, X, y = load_linreg_dataset(\n",
    "    path=\"datasets/linreg/linreg_data_beta_dirichlet_2.npz\",\n",
    "    test_fraction=0.2,\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/linreg\"\n",
    "results_dir = \"results/regression/linreg/beta_dirichlet_v2\"\n",
    "#model_names = [\"Linreg Gaussian\", \"Linreg Regularized Horseshoe\", \"Linreg Dirichlet Horseshoe\", \"Linreg Dirichlet Student T\", \"Linreg Beta Horseshoe\", \"Linreg Beta Student T\"]\n",
    "model_names = [\"Linreg Dirichlet Horseshoe\", \"Linreg Dirichlet Student T\", \"Linreg Beta Horseshoe\", \"Linreg Beta Student T\"]\n",
    "\n",
    "\n",
    "full_config_path = \"linreg_N200_p3_rho_0.0\"\n",
    "fits = get_model_fits(\n",
    "    config=full_config_path,\n",
    "    results_dir=results_dir,\n",
    "    models=model_names,\n",
    "    include_prior=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_data import make_grouped_duplicates_data, load_linreg_dataset\n",
    "N=250\n",
    "sigma=1\n",
    "seed=1\n",
    "# X, y, beta_true, signal_groups = make_grouped_duplicates_data(\n",
    "#     n=N, G=20, m=20, sigma=1.0, test_size=0.2, seed=seed\n",
    "# )\n",
    "\n",
    "X_train, X_test, y_train, y_test, _, _, _ = load_linreg_dataset(\n",
    "    path=\"datasets/linreg/linreg_data_beta_dirichlet_2.npz\",\n",
    "    test_fraction=0.2,\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def concentration_ratio(beta_samples, eps=1e-12):\n",
    "    \"\"\"\n",
    "    beta_samples: (S, p)\n",
    "    Returns: array (S,) of max/sum concentration ratios\n",
    "    \"\"\"\n",
    "    abs_beta = np.abs(beta_samples)\n",
    "    num = np.max(abs_beta, axis=1)\n",
    "    den = np.sum(abs_beta, axis=1) + eps\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def effective_active_count(beta_samples, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Counts number of 'active' coefficients per draw\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(beta_samples) > threshold, axis=1)\n",
    "\n",
    "\n",
    "def posterior_mean_abs(beta_samples):\n",
    "    \"\"\"\n",
    "    Posterior mean absolute value per coefficient\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(beta_samples), axis=0)\n",
    "\n",
    "\n",
    "def posterior_pairwise_corr(beta_samples):\n",
    "    \"\"\"\n",
    "    Pairwise correlation of coefficients across posterior samples\n",
    "    \"\"\"\n",
    "    return np.corrcoef(beta_samples, rowvar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# beta_gauss = fits[\"Linreg Gaussian\"][\"posterior\"].stan_variable(\"beta\")\n",
    "# beta_RHS = fits[\"Linreg Regularized Horseshoe\"][\"posterior\"].stan_variable(\"beta\")\n",
    "beta_DHS = fits[\"Linreg Dirichlet Horseshoe\"][\"posterior\"].stan_variable(\"beta\")\n",
    "beta_DST = fits[\"Linreg Dirichlet Student T\"][\"posterior\"].stan_variable(\"beta\")\n",
    "beta_BHS = fits[\"Linreg Beta Horseshoe\"][\"posterior\"].stan_variable(\"beta\")\n",
    "beta_BST = fits[\"Linreg Beta Student T\"][\"posterior\"].stan_variable(\"beta\")\n",
    "\n",
    "models = {\n",
    "    # \"Gaussian\": beta_gauss,\n",
    "    # \"Regularized HS\": beta_RHS,\n",
    "    \"Dirichlet HS\": beta_DHS,\n",
    "    \"Dirichlet ST\": beta_DST,\n",
    "    \"Beta HS\": beta_BHS,\n",
    "    \"Beta ST\": beta_BST,\n",
    "}\n",
    "\n",
    "p = beta_DST.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, yhat):\n",
    "    return np.sqrt(np.mean((y - yhat) ** 2))\n",
    "\n",
    "print(\"\\nPosterior mean RMSE:\")\n",
    "for name, beta in models.items():\n",
    "    beta_mean = np.mean(beta, axis=0)\n",
    "    yhat = X_test @ beta_mean\n",
    "    print(f\"{name:15s}: {rmse(y_test, yhat):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentration_ratio(beta_samples, eps=1e-12):\n",
    "    absb = np.abs(beta_samples)\n",
    "    return np.max(absb, axis=1) / (np.sum(absb, axis=1) + eps)\n",
    "\n",
    "print(\"\\nConcentration ratio (max / sum):\")\n",
    "for name, beta in models.items():\n",
    "    C = concentration_ratio(beta)\n",
    "    print(\n",
    "        f\"{name:15s}: \"\n",
    "        f\"mean={np.mean(C):.3f}, \"\n",
    "        f\"median={np.median(C):.3f}, \"\n",
    "        f\"q10={np.quantile(C,0.1):.3f}, \"\n",
    "        f\"q90={np.quantile(C,0.9):.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_active_count(beta_samples, threshold=0.1):\n",
    "    return np.sum(np.abs(beta_samples) > threshold, axis=1)\n",
    "\n",
    "print(\"\\nEffective number of active coefficients:\")\n",
    "for name, beta in models.items():\n",
    "    k_eff = effective_active_count(beta, threshold=0.1)\n",
    "    print(\n",
    "        f\"{name:15s}: \"\n",
    "        f\"mean={np.mean(k_eff):.1f}, \"\n",
    "        f\"median={np.median(k_eff):.0f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 10 posterior mean |beta_j|:\")\n",
    "\n",
    "for name, beta in models.items():\n",
    "    mean_abs = np.mean(np.abs(beta), axis=0)\n",
    "    top = np.sort(mean_abs)[-10:][::-1]\n",
    "    print(f\"{name:15s}: {np.round(top, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_indices(x, k):\n",
    "    return set(np.argsort(np.abs(x))[-k:])\n",
    "\n",
    "beta_true = np.array([0.2] + [0.0]*(p-1))\n",
    "\n",
    "k = np.sum(beta_true != 0)\n",
    "\n",
    "true_support = top_k_indices(beta_true, k)\n",
    "\n",
    "print(\"\\nSupport recovery (top-k overlap):\")\n",
    "for name, beta in models.items():\n",
    "    mean_beta = np.mean(beta, axis=0)\n",
    "    est_support = top_k_indices(mean_beta, k)\n",
    "    overlap = len(true_support & est_support)\n",
    "    print(f\"{name:15s}: {overlap}/{k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offdiag_mean_abs_corr(beta_samples):\n",
    "    C = np.corrcoef(beta_samples, rowvar=False)\n",
    "    mask = ~np.eye(C.shape[0], dtype=bool)\n",
    "    return np.mean(np.abs(C[mask]))\n",
    "\n",
    "print(\"\\nMean absolute off-diagonal posterior correlation:\")\n",
    "for name, beta in models.items():\n",
    "    print(f\"{name:15s}: {offdiag_mean_abs_corr(beta):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups_contiguous(p, m):\n",
    "    assert p % m == 0\n",
    "    G = p // m\n",
    "    groups = [np.arange(g*m, (g+1)*m) for g in range(G)]\n",
    "    return groups\n",
    "\n",
    "# example: p=400, group size m=20 -> G=20 groups\n",
    "groups = make_groups_contiguous(p=400, m=20)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def group_concentration_ratio(beta_samples, groups, eps=1e-12):\n",
    "    \"\"\"\n",
    "    For each posterior draw s and each group g:\n",
    "      C_{s,g} = max_j |beta_{s,j}| / sum_j |beta_{s,j}|\n",
    "    Returns: (S, G)\n",
    "    \"\"\"\n",
    "    S = beta_samples.shape[0]\n",
    "    G = len(groups)\n",
    "    C = np.zeros((S, G))\n",
    "    absb = np.abs(beta_samples)\n",
    "    for gi, idx in enumerate(groups):\n",
    "        num = np.max(absb[:, idx], axis=1)\n",
    "        den = np.sum(absb[:, idx], axis=1) + eps\n",
    "        C[:, gi] = num / den\n",
    "    return C\n",
    "\n",
    "def group_effective_active(beta_samples, groups, threshold=0.1):\n",
    "    \"\"\"\n",
    "    For each draw and group: number of active coeffs in the group.\n",
    "    Returns: (S, G)\n",
    "    \"\"\"\n",
    "    S = beta_samples.shape[0]\n",
    "    G = len(groups)\n",
    "    K = np.zeros((S, G), dtype=int)\n",
    "    for gi, idx in enumerate(groups):\n",
    "        K[:, gi] = np.sum(np.abs(beta_samples[:, idx]) > threshold, axis=1)\n",
    "    return K\n",
    "\n",
    "def group_top1_share_of_global_l1(beta_samples, groups, eps=1e-12):\n",
    "    \"\"\"\n",
    "    For each draw:\n",
    "      - find, within each group, the max |beta|\n",
    "      - sum those maxima across groups (a 'picked representative' L1)\n",
    "      - divide by total L1 across all coefficients\n",
    "    This is a single-number summary per draw.\n",
    "    Returns: (S,)\n",
    "    \"\"\"\n",
    "    absb = np.abs(beta_samples)\n",
    "    total_l1 = np.sum(absb, axis=1) + eps\n",
    "\n",
    "    top1_sum = np.zeros(beta_samples.shape[0])\n",
    "    for idx in groups:\n",
    "        top1_sum += np.max(absb[:, idx], axis=1)\n",
    "\n",
    "    return top1_sum / total_l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(x):\n",
    "    return {\n",
    "        \"mean\": float(np.mean(x)),\n",
    "        \"median\": float(np.median(x)),\n",
    "        \"q10\": float(np.quantile(x, 0.1)),\n",
    "        \"q90\": float(np.quantile(x, 0.9)),\n",
    "    }\n",
    "\n",
    "# choose group size (Design A: e.g. 10, 20, 25)\n",
    "m = 20\n",
    "p = next(iter(models.values())).shape[1]\n",
    "groups = make_groups_contiguous(p=p, m=m)\n",
    "\n",
    "threshold = 0.1  # adjust if needed\n",
    "\n",
    "print(f\"\\nGroup diagnostics with p={p}, m={m}, G={len(groups)}, threshold={threshold}\\n\")\n",
    "\n",
    "for name, beta in models.items():\n",
    "    C = group_concentration_ratio(beta, groups)           # (S, G)\n",
    "    K = group_effective_active(beta, groups, threshold)   # (S, G)\n",
    "    top1share = group_top1_share_of_global_l1(beta, groups)  # (S,)\n",
    "\n",
    "    # aggregate over draws and groups\n",
    "    C_all = C.reshape(-1)\n",
    "    K_all = K.reshape(-1)\n",
    "\n",
    "    print(f\"== {name} ==\")\n",
    "    print(\"Within-group concentration max/sum:\", summarize(C_all))\n",
    "    print(\"Within-group #active coefficients:\", summarize(K_all))\n",
    "    print(\"Top-1-per-group share of global L1:\", summarize(top1share))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_group_correlations(X, groups):\n",
    "    vals = []\n",
    "    for idx in groups:\n",
    "        Xg = X[:, idx]\n",
    "        R = np.corrcoef(Xg, rowvar=False)\n",
    "        mask = ~np.eye(R.shape[0], dtype=bool)\n",
    "        vals.append(np.mean(np.abs(R[mask])))\n",
    "    return np.array(vals)\n",
    "\n",
    "avg_abs_corr = check_group_correlations(X_train, groups)\n",
    "print(\"Mean |corr| within each group (train):\")\n",
    "print(\"  mean:\", avg_abs_corr.mean())\n",
    "print(\"  min :\", avg_abs_corr.min())\n",
    "print(\"  max :\", avg_abs_corr.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
