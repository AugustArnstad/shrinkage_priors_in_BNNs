{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_experimental = \"results/priors/single_layer/experiment\"\n",
    "\n",
    "names_and_configs = {\"Gaussian\": \"gauss_plain\", \"Regularized Horseshoe\": \"reg_hs\", \n",
    "                     \"Dirichlet Horseshoe\": \"dir_hs\", \"Dirichlet Student T\": \"stud_t_df3\"}\n",
    "                     \n",
    "fits = {}\n",
    "    \n",
    "\n",
    "for key, value in names_and_configs.items():\n",
    "    experimental_fit = get_model_fits(\n",
    "        config=value,\n",
    "        results_dir=results_dir_experimental,\n",
    "        models=key,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    print(key)\n",
    "    print(value)\n",
    "    fits[key] = experimental_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose the hidden node index to inspect\n",
    "node_idx = 1  # e.g., first hidden node\n",
    "\n",
    "def extract_W_for_node(cmdstan_mcmc, var_name=\"W_1\", node=0):\n",
    "    \"\"\"Return array shape (n_draws, P) of weights feeding into a given node.\"\"\"\n",
    "    W = cmdstan_mcmc.stan_variable(var_name)   # shape (n_draws, P, H)\n",
    "    return W[:, :, node]                       # (n_draws, P)\n",
    "\n",
    "# Grab arrays for each prior from your dict\n",
    "W_gauss = extract_W_for_node(fits['Gaussian']['Gaussian']['posterior'], node=node_idx)\n",
    "W_reg_hs = extract_W_for_node(fits['Regularized Horseshoe']['Regularized Horseshoe']['posterior'], node=node_idx)\n",
    "W_dir_hs = extract_W_for_node(fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior'], node=node_idx)\n",
    "W_dir_st = extract_W_for_node(fits['Dirichlet Student T']['Dirichlet Student T']['posterior'], node=node_idx)\n",
    "\n",
    "models = {\n",
    "    \"Gaussian\": W_gauss,\n",
    "    \"Reg. Horseshoe\": W_reg_hs,\n",
    "    \"Dirichlet HS\": W_dir_hs,\n",
    "    \"Dirichlet Student-t\": W_dir_st,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_profile(W):\n",
    "    # sort |w| per draw, descending; then average by rank\n",
    "    sorted_abs = np.sort(np.abs(W), axis=1)[:, ::-1]         # (n_draws, P)\n",
    "    mean_rank = sorted_abs.mean(axis=0)\n",
    "    q05 = np.quantile(sorted_abs, 0.05, axis=0)\n",
    "    q95 = np.quantile(sorted_abs, 0.95, axis=0)\n",
    "    return mean_rank, q05, q95\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "for name, W in models.items():\n",
    "    mean_rank, q05, q95 = rank_profile(W)\n",
    "    x = np.arange(1, W.shape[1]+1)\n",
    "    plt.plot(x, mean_rank, marker='o', label=name)\n",
    "plt.xlabel(\"Rank (1 = largest |w| in draw)\")\n",
    "plt.ylabel(\"Average |w|\")\n",
    "plt.title(f\"Avg. sorted |weights| into node {node_idx}\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_curve(W):\n",
    "    sq = W**2\n",
    "    shares = sq / sq.sum(axis=1, keepdims=True)              # per-draw normalization\n",
    "    # Average of top-k shares ≈ cumsum of mean ordered shares\n",
    "    ordered = np.sort(shares, axis=1)[:, ::-1]\n",
    "    return ordered.mean(axis=0).cumsum()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "for name, W in models.items():\n",
    "    c = topk_curve(W)\n",
    "    plt.plot(np.arange(1, len(c)+1), c, marker='.', label = name)\n",
    "plt.axhline(0.9, ls='--', lw=1, label='90%')\n",
    "plt.axhline(0.95, ls='--', lw=1, label='95%')\n",
    "plt.xlabel(\"k (top-k weights)\"); plt.ylabel(\"E[sum of top-k shares]\")\n",
    "plt.title(f\"Top-k coverage of w² shares – node {node_idx}\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner_freq(W):\n",
    "    winners = np.argmax(np.abs(W), axis=1)            # index of largest |w| per draw\n",
    "    P = W.shape[1]\n",
    "    counts = np.bincount(winners, minlength=P)\n",
    "    return counts / counts.sum()\n",
    "\n",
    "freq_df = pd.DataFrame({name: winner_freq(W) for name, W in models.items()})\n",
    "freq_df.index = [f\"input_{i}\" for i in range(freq_df.shape[0])]\n",
    "print(freq_df.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(v):\n",
    "    v = np.sort(v)\n",
    "    n = v.size\n",
    "    return (np.sum((2*np.arange(1, n+1) - n - 1) * v)) / (n * v.sum())\n",
    "\n",
    "def gini_over_draws(W):\n",
    "    sq = W**2\n",
    "    shares = sq / sq.sum(axis=1, keepdims=True)\n",
    "    return np.apply_along_axis(gini, 1, shares)\n",
    "\n",
    "for name, W in models.items():\n",
    "    g = gini_over_draws(W)\n",
    "    print(f\"{name}: mean Gini = {g.mean():.3f}   (0=uniform, 1=one-hot)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "def shares_from_W(W):\n",
    "    \"\"\"Row-normalized squared weights (per draw).\"\"\"\n",
    "    sq = W**2\n",
    "    return sq / (sq.sum(axis=1, keepdims=True) + EPS)\n",
    "\n",
    "# --- Shannon entropy and friends ---\n",
    "def shannon_entropy_over_draws(W):\n",
    "    \"\"\"\n",
    "    Natural-log entropy per draw.\n",
    "    Range: [0, ln P]. 0 if one-hot, ln P if uniform.\n",
    "    \"\"\"\n",
    "    p = shares_from_W(W)\n",
    "    return -(p * np.log(p + EPS)).sum(axis=1)\n",
    "\n",
    "def norm_entropy_over_draws(W):\n",
    "    \"\"\"\n",
    "    Normalized sparsity-style measure in [0,1]:\n",
    "    0=uniform, 1=one-hot.\n",
    "    \"\"\"\n",
    "    H = shannon_entropy_over_draws(W)\n",
    "    P = W.shape[1]\n",
    "    return 1.0 - H / (np.log(P) + EPS)\n",
    "\n",
    "def perplexity_over_draws(W):\n",
    "    \"\"\"\n",
    "    Effective count via entropy: exp(H) in [1, P].\n",
    "    \"\"\"\n",
    "    H = shannon_entropy_over_draws(W)\n",
    "    return np.exp(H)\n",
    "\n",
    "\n",
    "# --- Convenience: summarize per model ---\n",
    "def summarize_entropy_kl(models):\n",
    "    rows = []\n",
    "    for name, W in models.items():\n",
    "        H = shannon_entropy_over_draws(W)\n",
    "        Hn = 1 - H / (np.log(W.shape[1]) + EPS)\n",
    "        PPX = np.exp(H)\n",
    "\n",
    "        def m_ci(x):\n",
    "            return np.mean(x), np.quantile(x, 0.05), np.quantile(x, 0.95)\n",
    "\n",
    "        H_m, H_l, H_u = m_ci(H)\n",
    "        Hn_m, Hn_l, Hn_u = m_ci(Hn)\n",
    "        PPX_m, PPX_l, PPX_u = m_ci(PPX)\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"H (nats) mean\": H_m, \"H p05\": H_l, \"H p95\": H_u,\n",
    "            \"H_norm mean\": Hn_m, \"H_norm p05\": Hn_l, \"H_norm p95\": Hn_u,\n",
    "            \"Perplexity mean\": PPX_m, \"Perplexity p05\": PPX_l, \"Perplexity p95\": PPX_u,\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"model\")\n",
    "\n",
    "# Example: print a compact summary table\n",
    "summary_df = summarize_entropy_kl(models)\n",
    "print(summary_df[[\n",
    "    \"H_norm mean\", \"Perplexity mean\"\n",
    "]].round(3))\n",
    "\n",
    "# Optional: quick visual comparing normalized entropy & KL across models\n",
    "plt.figure(figsize=(6.5, 3.8))\n",
    "x = np.arange(len(models))\n",
    "bar_w = 0.35\n",
    "Hn_means = [norm_entropy_over_draws(W).mean() for W in models.values()]\n",
    "plt.bar(x - bar_w/2, Hn_means, width=bar_w, label=\"1 - H/ln P\")\n",
    "plt.xticks(x, list(models.keys()), rotation=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Normalized (0=uniform, 1=one-hot)\")\n",
    "plt.title(f\"Entropy & KL sparsity — node {node_idx}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# generic: rank→uniform columnwise (works for any matrix A)\n",
    "def empirical_copula_cols(A):\n",
    "    n, P = A.shape\n",
    "    U = np.zeros_like(A, dtype=float)\n",
    "    for j in range(P):\n",
    "        U[:, j] = rankdata(A[:, j], method=\"average\") / (n + 1.0)\n",
    "    return U\n",
    "\n",
    "def tail_dependence_curve_from_matrix(A, i=0, j=1, u_grid=None):\n",
    "    if u_grid is None:\n",
    "        u_grid = np.linspace(0.50, 0.99, 25)\n",
    "    U = empirical_copula_cols(A)\n",
    "    ui, uj = U[:, i], U[:, j]\n",
    "    lam = np.array([np.mean(uj[ui > u] > u) if np.any(ui > u) else np.nan for u in u_grid])\n",
    "    return u_grid, lam\n",
    "\n",
    "def plot_tail_dependence(models, i=0, j=1, u_grid=None):\n",
    "    if u_grid is None:\n",
    "        u_grid = np.linspace(0.50, 0.99, 25)\n",
    "\n",
    "    curves = {}\n",
    "    ymax = 0.0\n",
    "    for name, W in models.items():\n",
    "        A = np.abs(W)  # use |w|\n",
    "        u, lam = tail_dependence_curve_from_matrix(A, i=i, j=j, u_grid=u_grid)\n",
    "        curves[name] = (u, lam)\n",
    "        ymax = max(ymax, np.nanmax(lam))\n",
    "    baseline = 1.0 - u_grid\n",
    "    ymax = max(ymax, baseline.max())\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 9), sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for ax, (name, (u, lam)) in zip(axes, curves.items()):\n",
    "        ax.plot(u, lam, marker='o', ms=3, lw=1, label=name)\n",
    "        ax.plot(u_grid, baseline, linestyle='--', lw=1, label='independent baseline (1 - u)')\n",
    "        ax.set_title(name)\n",
    "        ax.set_ylim(0, min(1.0, ymax * 1.05))\n",
    "        ax.grid(True, linewidth=0.4, alpha=0.4)\n",
    "        ax.set_xlabel(\"u (upper-tail threshold)\")\n",
    "        ax.set_ylabel(r\"$\\lambda_U(u) = P(U_j>u \\mid U_i>u)$\")\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "    fig.suptitle(f\"Upper-tail dependence — |w|, inputs {i} vs {j}\", y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Example:\n",
    "plot_tail_dependence(models, i=0, j=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "# assumes empirical_copula_cols() is already defined above\n",
    "# assumes shares_from_W(W) is already defined in your session\n",
    "\n",
    "def _gaussian_shares_baseline_lambdaU(P, i=0, j=1, u_grid=None, N=200_000, seed=0):\n",
    "    rng = default_rng(seed)\n",
    "    if u_grid is None:\n",
    "        u_grid = np.linspace(0.50, 0.99, 25)\n",
    "    alpha = np.full(P, 0.5, dtype=float)\n",
    "    p_base = rng.dirichlet(alpha, size=N)    # Gaussian-shares baseline\n",
    "    U = empirical_copula_cols(p_base)\n",
    "    ui, uj = U[:, i], U[:, j]\n",
    "    lam_base = np.array([np.mean(uj[ui > u] > u) if np.any(ui > u) else np.nan for u in u_grid])\n",
    "    return u_grid, lam_base\n",
    "\n",
    "def tail_dependence_on_shares_gauss_baseline(models, i=0, j=1, u_grid=None, N=200_000, seed=0):\n",
    "    if u_grid is None:\n",
    "        u_grid = np.linspace(0.50, 0.99, 25)\n",
    "\n",
    "    P = next(iter(models.values())).shape[1]\n",
    "    u_base, lam_base = _gaussian_shares_baseline_lambdaU(P, i=i, j=j, u_grid=u_grid, N=N, seed=seed)\n",
    "\n",
    "    curves = {}\n",
    "    ymax = np.nanmax(lam_base)\n",
    "    for name, W in models.items():\n",
    "        p = shares_from_W(W)           # your existing function\n",
    "        U = empirical_copula_cols(p)\n",
    "        ui, uj = U[:, i], U[:, j]\n",
    "        lam = np.array([np.mean(uj[ui > u] > u) if np.any(ui > u) else np.nan for u in u_grid])\n",
    "        curves[name] = lam\n",
    "        ymax = max(ymax, np.nanmax(lam))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 9), sharex=True, sharey=True)\n",
    "    axes = axes.ravel()\n",
    "    for ax, (name, lam) in zip(axes, curves.items()):\n",
    "        ax.plot(u_grid, lam, marker='o', ms=3, lw=1, label=name)\n",
    "        ax.plot(u_base, lam_base, ls='--', lw=1.2, label='Gaussian baseline: Dir(½)')\n",
    "        ax.set_title(name)\n",
    "        ax.set_ylim(0, min(1.0, ymax * 1.05))\n",
    "        ax.grid(True, linewidth=0.4, alpha=0.4)\n",
    "        ax.set_xlabel(\"u (upper-tail threshold)\")\n",
    "        ax.set_ylabel(r\"$\\lambda_U(u) = P(U_j>u \\mid U_i>u)$\")\n",
    "        ax.legend(fontsize=8, loc='upper right')\n",
    "\n",
    "    fig.suptitle(r\"Upper-tail dependence of $\\frac{w^2}{\\sum_k w_k^2}$ — (baseline = Gaussian ⇒ Dir(½))\", y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Example:\n",
    "tail_dependence_on_shares_gauss_baseline(models, i=0, j=1, N=200_000, seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def winner_mask_col0(W, drop_ties=True):\n",
    "    row_max = W.max(axis=1)\n",
    "    argm = W.argmax(axis=1)\n",
    "    if drop_ties:\n",
    "        tie_counts = (W == row_max[:, None]).sum(axis=1)\n",
    "        return (argm == 0) & (tie_counts == 1)\n",
    "    return (argm == 0)\n",
    "\n",
    "def transform_weights(W, mask=None, transform=\"none\"):\n",
    "    X = W.copy()\n",
    "    if transform == \"none\":\n",
    "        return X\n",
    "    if transform == \"zscore\":\n",
    "        mu = X.mean(axis=0, keepdims=True)\n",
    "        sd = X.std(axis=0, keepdims=True) + 1e-12\n",
    "        return (X - mu)/sd\n",
    "    if transform == \"mad\":\n",
    "        med = np.median(X, axis=0, keepdims=True)\n",
    "        mad = np.median(np.abs(X - med), axis=0, keepdims=True) + 1e-12\n",
    "        return (X - med)/(1.4826*mad)\n",
    "    if transform in (\"relative\", \"abs_relative\"):\n",
    "        if mask is None:\n",
    "            raise ValueError(\"mask required for relative transforms\")\n",
    "        Xw = X[mask].copy()\n",
    "        denom = np.abs(Xw[:, [0]]) + 1e-12\n",
    "        if transform == \"relative\":\n",
    "            Xw = Xw / denom\n",
    "        else:\n",
    "            Xw = np.abs(Xw) / denom\n",
    "        # for non-winning rows, keep original scale (unused i hist-combo hvis du vil)\n",
    "        Xn = X[~mask].copy()\n",
    "        return Xw, Xn\n",
    "    raise ValueError(\"unknown transform\")\n",
    "\n",
    "def plot_conditioned_hist_grid(models, bins=100, qlim=(0.01, 0.99)):\n",
    "    \"\"\"\n",
    "    Plott conditioned histograms med kvantil-klipp på x-aksen.\n",
    "    qlim = (lav, høy) kvantil som beholdes (f.eks. (0.01, 0.99)).\n",
    "    \"\"\"\n",
    "    for name, W in models.items():\n",
    "        mask = winner_mask_col0(W, drop_ties=True)\n",
    "        W_win, W_non = W[mask], W[~mask]\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(12, 9))\n",
    "        axes = axes.flatten()\n",
    "        for j in range(1, 10):\n",
    "            ax = axes[j-1]\n",
    "            data = np.concatenate([W_win[:, j], W_non[:, j]])\n",
    "            lo, hi = np.quantile(data, qlim)\n",
    "            ax.hist(W_win[:, j], bins=bins, density=True, alpha=0.5,\n",
    "                    label=\"winning\", edgecolor='none')\n",
    "            ax.hist(W_non[:, j], bins=bins, density=True, alpha=0.5,\n",
    "                    label=\"non-winning\", edgecolor='none')\n",
    "            ax.set_xlim(lo, hi)\n",
    "            ax.set_title(f\"w{j}\")\n",
    "        fig.suptitle(f\"{name} — conditioned distributions (clipped {qlim})\", fontsize=14)\n",
    "        axes[0].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#plot_conditioned_hist_grid(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_grid(models, s=6, alpha=0.2):\n",
    "    for name, W in models.items():\n",
    "        mask = winner_mask_col0(W, drop_ties=True)\n",
    "        W_win = W[mask]\n",
    "        if W_win.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(12, 9))\n",
    "        axes = axes.flatten()\n",
    "        for j in range(1, 10):\n",
    "            ax = axes[j-1]\n",
    "            ax.scatter(W_win[:, 0], W_win[:, j], s=s, alpha=alpha)\n",
    "            ax.axhline(0, linewidth=0.8, color=\"k\")\n",
    "            ax.axvline(0, linewidth=0.8, color=\"k\")\n",
    "            ax.set_title(f\"w0 vs w{j}\")\n",
    "        fig.suptitle(f\"{name} — winning rows\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example:\n",
    "#plot_scatter_grid(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPS = 1e-12\n",
    "\n",
    "def stddev_from_draws(phi_draws, lambda_draws):\n",
    "    \"\"\"\n",
    "    Inputs are draws for phi_tilde_data[j][i], lambda_tilde_data[j][i]\n",
    "    shapes: (draws, J, I). Returns stddev with shape (draws, I, J)\n",
    "    for the weights W_1[i,j] built as stddev * W1_raw[i,j].\n",
    "    \"\"\"\n",
    "    std_j_i = np.sqrt(np.maximum(lambda_draws, 0.0)) * phi_draws\n",
    "    std_j_i = np.maximum(std_j_i, EPS)\n",
    "    return np.swapaxes(std_j_i, 1, 2)  # -> (draws, I, J)\n",
    "\n",
    "phi_GAUSS = 1\n",
    "lam_GAUSS = np.ones((8000, 10, 16))\n",
    "std_GAUSS = stddev_from_draws(phi_GAUSS, lam_GAUSS)  # (draws, I, J)\n",
    "\n",
    "phi_RHS = 1\n",
    "lam_RHS = fits['Regularized Horseshoe']['Regularized Horseshoe']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "std_RHS = stddev_from_draws(phi_RHS, lam_RHS)  # (draws, I, J)\n",
    "\n",
    "# Example: Dirichlet-Horseshoe (adjust keys to your structure)\n",
    "phi_DHS = fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior'].stan_variable(\"phi_tilde_data\")\n",
    "lam_DHS = fits['Dirichlet Horseshoe']['Dirichlet Horseshoe']['posterior'].stan_variable(\"lambda_tilde_data\")\n",
    "std_DHS = stddev_from_draws(phi_DHS, lam_DHS)  # (draws, I, J)\n",
    "\n",
    "phi_DST = fits['Dirichlet Student T']['Dirichlet Student T']['posterior'].stan_variable(\"phi_tilde_data\")\n",
    "lam_DST = fits['Dirichlet Student T']['Dirichlet Student T']['posterior'].stan_variable(\"lambda_tilde\")\n",
    "std_DST = stddev_from_draws(phi_DST, lam_DST)  # (draws, I, J)\n",
    "\n",
    "\n",
    "models_std = {\n",
    "    \"Dir-HS\": std_DHS,\n",
    "    \"Gaussian\": std_GAUSS,\n",
    "    \"RHS\": std_RHS,\n",
    "    \"Dir-ST\": std_DST,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(x):\n",
    "    x = np.sort(x)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return x, y\n",
    "\n",
    "def plot_std_ecdf(models_std, log=True, qclip=(0.001, 0.999)):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for name, std in models_std.items():\n",
    "        vals = std.reshape(-1)               # pool over (draws, I, J)\n",
    "        vals = np.maximum(vals, EPS)\n",
    "        if log:\n",
    "            vals = np.log(vals)\n",
    "        lo, hi = np.quantile(vals, qclip)\n",
    "        vals = vals[(vals>=lo)&(vals<=hi)]\n",
    "        x, y = ecdf(vals)\n",
    "        plt.plot(x, y, label=name, linewidth=1.8)\n",
    "    plt.xlabel(\"log stddev\" if log else \"stddev\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.title(\"Stddev distribution (pooled across weights)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example:\n",
    "plot_std_ecdf(models_std, log=True, qclip=(0.001, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "res = stats.chatterjeexi(W_gauss[:, 0], W_gauss[:, 1])\n",
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chatterjeexi(W_reg_hs[:, 0], W_reg_hs[:, 1])\n",
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chatterjeexi(W_dir_hs[:, 0], W_dir_hs[:, 1])\n",
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.chatterjeexi(W_dir_st[:, 0], W_dir_st[:, 1])\n",
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covercorr import coverage_correlation\n",
    "\n",
    "kappa, pval = coverage_correlation(W_gauss[:, 0], W_gauss[:, 1])\n",
    "print(f\"Coverage correlation: {kappa}, p-value: {pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covercorr import coverage_correlation\n",
    "\n",
    "kappa, pval = coverage_correlation(W_reg_hs[:, 0], W_reg_hs[:, 1])\n",
    "print(f\"Coverage correlation: {kappa}, p-value: {pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covercorr import coverage_correlation\n",
    "\n",
    "kappa, pval = coverage_correlation(W_dir_hs[:, 0], W_dir_hs[:, 1])\n",
    "print(f\"Coverage correlation: {kappa}, p-value: {pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covercorr import coverage_correlation\n",
    "\n",
    "kappa, pval = coverage_correlation(W_dir_st[:, 1], W_dir_st[:, 2])\n",
    "print(f\"Coverage correlation: {kappa}, p-value: {pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
