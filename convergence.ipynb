{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__) if '__file__' in globals() else os.getcwd(), '..')))\n",
    "#import os; os.chdir(os.path.dirname(os.getcwd()))\n",
    "from utils.model_loader import get_model_fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"datasets/friedman\"\n",
    "results_dir_relu = \"results/regression/single_layer/relu/friedman/convergence\"\n",
    "results_dir_tanh = \"results/regression/single_layer/tanh/friedman/convergence\"\n",
    "model_names_relu = [\"Gaussian\", \"Regularized Horseshoe\", \"Dirichlet Horseshoe\", \"Dirichlet Student T\"]\n",
    "model_names_tanh = [\"Gaussian tanh\", \"Regularized Horseshoe tanh\", \"Dirichlet Horseshoe tanh\", \"Dirichlet Student T tanh\"]\n",
    "\n",
    "relu_fits = {}\n",
    "tanh_fits = {}\n",
    "\n",
    "files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".npz\"))\n",
    "for fname in files:\n",
    "    base_config_name = fname.replace(\".npz\", \"\")  # e.g., \"GAM_N100_p8_sigma1.00_seed1\"\n",
    "    full_config_path = f\"{base_config_name}\"  # â†’ \"type_1/GAM_N100_p8_sigma1.00_seed1\"\n",
    "    relu_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_relu,\n",
    "        models=model_names_relu,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "    tanh_fit = get_model_fits(\n",
    "        config=full_config_path,\n",
    "        results_dir=results_dir_tanh,\n",
    "        models=model_names_tanh,\n",
    "        include_prior=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "    relu_fits[base_config_name] = relu_fit  # use clean key\n",
    "    tanh_fits[base_config_name] = tanh_fit  # use clean key\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "seeds = [1, 2, 11]\n",
    "\n",
    "def get_N_sigma(seed):\n",
    "    if seed == 1:\n",
    "        N=100\n",
    "    elif seed == 2:\n",
    "        N=200\n",
    "    else:\n",
    "        N=500\n",
    "    sigma = 1\n",
    "    return N, sigma\n",
    "\n",
    "def get_all_convergence_diagnostics(all_fits):\n",
    "    diagnostics = []\n",
    "    rhats = {}\n",
    "    for config_name, model_fits in all_fits.items():\n",
    "        for model_name, fit in model_fits.items():\n",
    "            try:\n",
    "                idata = az.from_cmdstanpy(fit['posterior'])\n",
    "                y_pred = fit['posterior'].stan_variable('output_test')\n",
    "                \n",
    "                path = f'datasets/friedman/{config_name}.npz'\n",
    "                try:\n",
    "                    data = np.load(path)\n",
    "                    y_test = data[\"y_test\"]\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"[SKIP] File not found: {path}\")\n",
    "                    continue\n",
    "                \n",
    "                divergent = idata.sample_stats[\"diverging\"].values  # shape: (n_chains, n_draws)\n",
    "                divergent_flat = divergent.flatten()  # shape: (8000,)\n",
    "                divergences = np.sum(divergent_flat)\n",
    "                y_pred_no_div = y_pred[~divergent_flat]\n",
    "                S = y_pred.shape[0]\n",
    "                rmses = np.zeros(S)\n",
    "                rmses_no_div = np.zeros(S - np.sum(divergent_flat))\n",
    "                \n",
    "                for i in range(S):\n",
    "                   rmses[i] = np.sqrt(np.mean((y_pred[i].squeeze() - y_test.squeeze()) ** 2))\n",
    "                \n",
    "                for i in range(S - np.sum(divergent_flat)):\n",
    "                    rmses_no_div[i] = np.sqrt(np.mean((y_pred_no_div[i].squeeze() - y_test.squeeze()) ** 2))\n",
    "\n",
    "                summary = az.summary(idata, var_names=[\"output\"], round_to=3)\n",
    "                \n",
    "                rhat = summary[\"r_hat\"]\n",
    "                \n",
    "                rhats[model_name] = rhat\n",
    "\n",
    "                ess_bulk = summary[\"ess_bulk\"]\n",
    "                ess_tail = summary[\"ess_tail\"]\n",
    "                \n",
    "                try:\n",
    "                    seed = int(config_name.split(\"_seed\")[-1])\n",
    "                    N, sigma = get_N_sigma(seed)\n",
    "                except:\n",
    "                    N, sigma = np.nan, np.nan\n",
    "\n",
    "                diagnostics.append({\n",
    "                    \"model\": model_name,\n",
    "                    \"max_rhat\": rhat.max(),\n",
    "                    \"median_rhat\": rhat.median(),\n",
    "                    \"prop_divergent\": divergences/S,\n",
    "                    \"rmse\": np.mean(rmses, axis=0),\n",
    "                    \"rmse_no_div\": np.mean(rmses_no_div, axis=0),\n",
    "                    \"median_ess_tail\": ess_tail.median()/S,\n",
    "                    \"N\": N,\n",
    "                    \"sigma\": sigma,\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                diagnostics.append({\n",
    "                    #\"config\": config_name,\n",
    "                    \"model\": model_name,\n",
    "                    \"max_rhat\": np.nan,\n",
    "                    \"median_rhat\": np.nan,\n",
    "                    \"p95_rhat\": np.nan,\n",
    "                    \"min_ess_bulk\": np.nan,\n",
    "                    \"min_ess_tail\": np.nan,\n",
    "                    #\"n_divergent\": np.nan,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(diagnostics), rhats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_diagostic, rhats_relu = get_all_convergence_diagnostics(relu_fits)\n",
    "tanh_diagostic, rhats_tanh = get_all_convergence_diagnostics(tanh_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grouped = relu_diagostic.assign(row_index=lambda df: df.index) \\\n",
    "    .sort_values([\"model\", \"row_index\"]) \\\n",
    "    .drop(columns=\"row_index\") \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "tanh_grouped = tanh_diagostic.assign(row_index=lambda df: df.index) \\\n",
    "    .sort_values([\"model\", \"row_index\"]) \\\n",
    "    .drop(columns=\"row_index\") \\\n",
    "    .reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relu_grouped.to_latex(index=False))\n",
    "print(tanh_grouped.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, remove \"tanh\" from model names in both DataFrames\n",
    "relu_diagostic = relu_diagostic.copy()\n",
    "relu_diagostic[\"model\"] = relu_diagostic[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "tanh_diagostic = tanh_diagostic.copy()\n",
    "tanh_diagostic[\"model\"] = tanh_diagostic[\"model\"].str.replace(\" tanh\", \"\", regex=False)\n",
    "\n",
    "# Create shared-axes figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# Plot ReLU\n",
    "sns.scatterplot(\n",
    "    data=relu_diagostic,\n",
    "    x=\"max_rhat\", y=\"rmse\",\n",
    "    hue=\"model\",\n",
    "    style=\"sigma\",\n",
    "    size=\"N\", sizes=(100, 300),\n",
    "    ax=axes[0],\n",
    "    legend=False\n",
    ")\n",
    "axes[0].set_title(\"ReLU\")\n",
    "axes[0].set_xlabel(r\"Max $\\hat{R}$\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot tanh and keep legend\n",
    "plot_obj = sns.scatterplot(\n",
    "    data=tanh_diagostic,\n",
    "    x=\"max_rhat\", y=\"rmse\",\n",
    "    hue=\"model\",\n",
    "    style=\"sigma\",\n",
    "    size=\"N\", sizes=(100, 300),\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(r\"$\\tanh$\")\n",
    "axes[1].set_xlabel(r\"Max $\\hat{R}$\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Extract and filter legend\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "axes[1].legend_.remove()\n",
    "\n",
    "exclude_labels = {\"model\", \"N\", \"sigma\"}\n",
    "filtered = [(h, l) for h, l in zip(handles, labels) if l not in exclude_labels]\n",
    "if filtered:\n",
    "    filtered_handles, filtered_labels = zip(*filtered)\n",
    "    filtered_handles = filtered_handles[:-1]\n",
    "    filtered_labels = filtered_labels[:-1]\n",
    "    fig.legend(\n",
    "        filtered_handles,\n",
    "        filtered_labels,\n",
    "        title=\"\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.9, 0.8),\n",
    "        ncol=2,\n",
    "    )\n",
    "\n",
    "# Layout adjustments\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERGENCE vs ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# --- First panel: N=100 ---\n",
    "dataset_path = \"datasets/friedman/Friedman_N100_p10_sigma1.00_seed1.npz\"\n",
    "data = np.load(dataset_path)\n",
    "y_test = data[\"y_test\"]\n",
    "models_dict = relu_fits['Friedman_N100_p10_sigma1.00_seed1']\n",
    "\n",
    "for model_name, model_dict in models_dict.items():\n",
    "    model = model_dict['posterior']\n",
    "    idata = az.from_cmdstanpy(model)\n",
    "    rhat = az.summary(idata, var_names=[\"output_test\"], round_to=3)[\"r_hat\"].values\n",
    "    y_pred = np.mean(model.stan_variable(\"output_test\"), axis=0).squeeze(-1)\n",
    "    rmse = np.sqrt((y_test - y_pred) ** 2)\n",
    "    axes[0].scatter(rhat, rmse, label=model_name, alpha=0.7)\n",
    "\n",
    "axes[0].set_title(\"N = 100\")\n",
    "axes[0].set_xlabel(r\"$\\hat{R}$\")\n",
    "axes[0].set_ylabel(\"RMSE per test point\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Second panel: N=200 ---\n",
    "dataset_path = \"datasets/friedman/Friedman_N200_p10_sigma1.00_seed2.npz\"\n",
    "data = np.load(dataset_path)\n",
    "y_test = data[\"y_test\"]\n",
    "models_dict = relu_fits['Friedman_N200_p10_sigma1.00_seed2']\n",
    "\n",
    "for model_name, model_dict in models_dict.items():\n",
    "    model = model_dict['posterior']\n",
    "    idata = az.from_cmdstanpy(model)\n",
    "    rhat = az.summary(idata, var_names=[\"output_test\"], round_to=3)[\"r_hat\"].values\n",
    "    y_pred = np.mean(model.stan_variable(\"output_test\"), axis=0).squeeze(-1)\n",
    "    rmse = np.sqrt((y_test - y_pred) ** 2)\n",
    "    axes[1].scatter(rhat, rmse, label=model_name, alpha=0.7)\n",
    "\n",
    "axes[1].set_title(\"N = 200\")\n",
    "axes[1].set_xlabel(r\"$\\hat{R}$\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Shared legend\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper center\", ncol=len(labels))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# --- First panel: N=100 ---\n",
    "dataset_path = \"datasets/friedman/Friedman_N100_p10_sigma1.00_seed1.npz\"\n",
    "data = np.load(dataset_path)\n",
    "y_test = data[\"y_test\"]\n",
    "models_dict = tanh_fits['Friedman_N100_p10_sigma1.00_seed1']\n",
    "\n",
    "for model_name, model_dict in models_dict.items():\n",
    "    model = model_dict['posterior']\n",
    "    idata = az.from_cmdstanpy(model)\n",
    "    rhat = az.summary(idata, var_names=[\"output_test\"], round_to=3)[\"r_hat\"].values\n",
    "    y_pred = np.mean(model.stan_variable(\"output_test\"), axis=0).squeeze(-1)\n",
    "    rmse = np.sqrt((y_test - y_pred) ** 2)\n",
    "    axes[0].scatter(rhat, rmse, label=model_name, alpha=0.7)\n",
    "\n",
    "axes[0].set_title(\"N = 100\")\n",
    "axes[0].set_xlabel(r\"$\\hat{R}$\")\n",
    "axes[0].set_ylabel(\"RMSE per test point\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Second panel: N=200 ---\n",
    "dataset_path = \"datasets/friedman/Friedman_N200_p10_sigma1.00_seed2.npz\"\n",
    "data = np.load(dataset_path)\n",
    "y_test = data[\"y_test\"]\n",
    "models_dict = tanh_fits['Friedman_N200_p10_sigma1.00_seed2']\n",
    "\n",
    "for model_name, model_dict in models_dict.items():\n",
    "    model = model_dict['posterior']\n",
    "    idata = az.from_cmdstanpy(model)\n",
    "    rhat = az.summary(idata, var_names=[\"output_test\"], round_to=3)[\"r_hat\"].values\n",
    "    y_pred = np.mean(model.stan_variable(\"output_test\"), axis=0).squeeze(-1)\n",
    "    rmse = np.sqrt((y_test - y_pred) ** 2)\n",
    "    axes[1].scatter(rhat, rmse, label=model_name, alpha=0.7)\n",
    "\n",
    "axes[1].set_title(\"N = 200\")\n",
    "axes[1].set_xlabel(r\"$\\hat{R}$\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Shared legend\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper center\", ncol=len(labels))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRACEPLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "gauss_fit = tanh_fits['Friedman_N100_p10_sigma1.00_seed1']['Gaussian tanh']['posterior']\n",
    "idata = az.from_cmdstanpy(gauss_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent gaussian transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "# Plot trace for output[0,0] through output[4,0]\n",
    "\n",
    "indices = [1, 3, 4, 12]\n",
    "az.plot_trace(\n",
    "    idata,\n",
    "    var_names=[\"output\"],\n",
    "    coords={\"output_dim_0\": indices, \"output_dim_1\": [0]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs_fit = tanh_fits['Friedman_N100_p10_sigma1.00_seed1']['Regularized Horseshoe tanh']['posterior']\n",
    "idata = az.from_cmdstanpy(rhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent RHS transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "indices = [1, 3, 4, 12]\n",
    "az.plot_trace(\n",
    "    idata,\n",
    "    var_names=[\"output\"],\n",
    "    coords={\"output_dim_0\": indices, \"output_dim_1\": [0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_fit = tanh_fits['Friedman_N100_p10_sigma1.00_seed1']['Dirichlet Horseshoe tanh']['posterior']\n",
    "idata = az.from_cmdstanpy(dhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent DHS transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "indices = [1, 3, 4, 12]\n",
    "az.plot_trace(\n",
    "    idata,\n",
    "    var_names=[\"output\"],\n",
    "    coords={\"output_dim_0\": indices, \"output_dim_1\": [0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_fit = tanh_fits['Friedman_N100_p10_sigma1.00_seed1']['Dirichlet Student T tanh']['posterior']\n",
    "idata = az.from_cmdstanpy(dhs_fit)\n",
    "divergent = idata.sample_stats[\"diverging\"].values  # shape (n_chains, n_draws)\n",
    "print(\"Divergent DHS transitions:\", np.sum(divergent))\n",
    "print(divergent.shape)\n",
    "indices = [1, 3, 4, 12]\n",
    "az.plot_trace(\n",
    "    idata,\n",
    "    var_names=[\"output\"],\n",
    "    coords={\"output_dim_0\": indices, \"output_dim_1\": [0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RHAT PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _plot_rhat_dict(axs, rhats_dict, row_title=None, bins=60, log_y=True):\n",
    "    \"\"\"Plot one histogram per model from a {model -> Series} dict on a row of axes.\"\"\"\n",
    "    for ax, (model, s) in zip(axs, rhats_dict.items()):\n",
    "        x = np.asarray(s.values, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        # Clip extreme tails so the bulk is visible (optional)\n",
    "        xmax = np.quantile(x, 0.999) if x.size else 1.1\n",
    "        ax.hist(x, bins=bins, range=(1.0, xmax if xmax > 1.0 else 1.1))\n",
    "        if log_y: ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(r\"$\\hat{R}$\")\n",
    "        ax.set_title(model)\n",
    "        ax.grid(True, which=\"both\", axis=\"y\", alpha=0.3)\n",
    "    axs[0].set_ylabel(\"count\")\n",
    "    if row_title:\n",
    "        axs[0].annotate(row_title, xy=(0, 1.02), xycoords=\"axes fraction\",\n",
    "                        fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "def plot_output_rhats_two_rows(rhats_relu, rhats_tanh, bins=60, log_y=True, figsize_per_plot=(3.6, 2.8)):\n",
    "    \"\"\"Make a 2-row panel: top=ReLU models, bottom=tanh models.\"\"\"\n",
    "    ncols = max(len(rhats_relu), len(rhats_tanh))\n",
    "    fig, axes = plt.subplots(2, ncols, figsize=(figsize_per_plot[0]*ncols, figsize_per_plot[1]*2),\n",
    "                             sharey='row', sharex='row')\n",
    "    # Ensure axes are iterable even if ncols==1\n",
    "    axes_relu = axes[0] if ncols > 1 else [axes[0]]\n",
    "    axes_tanh = axes[1] if ncols > 1 else [axes[1]]\n",
    "\n",
    "    # Fill missing axes if dicts have fewer models than ncols\n",
    "    def pad_axes(ax_list, needed):\n",
    "        if len(ax_list) < needed:\n",
    "            ax_list += [ax_list[-1].figure.add_subplot(ax_list[-1].get_subplotspec())]*(needed-len(ax_list))\n",
    "        return ax_list\n",
    "\n",
    "    # Plot rows\n",
    "    _plot_rhat_dict(axes_relu[:len(rhats_relu)], rhats_relu, row_title=\"ReLU\", bins=bins, log_y=log_y)\n",
    "    _plot_rhat_dict(axes_tanh[:len(rhats_tanh)], rhats_tanh, row_title=\"tanh\", bins=bins, log_y=log_y)\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for row_axes, rhats in zip([axes_relu, axes_tanh], [rhats_relu, rhats_tanh]):\n",
    "        for ax in row_axes[len(rhats):]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# --- Use it ---\n",
    "plot_output_rhats_two_rows(rhats_relu, rhats_tanh, bins=60, log_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
